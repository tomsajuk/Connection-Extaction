{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting XML to CSV file\n",
    "Problem given is to find if given sentence has a connection between any two brain regions specified in the sentence.\n",
    "\n",
    "The Brain regions have already been given along with the sentences in an xml file. To work on it, it is converted to a DataFrame and stored in a csv file format for further manipulation.\n",
    "\n",
    "## Reading XML file\n",
    "First step is to read the xml file. The xml files that are given are - \n",
    "1. WhiteText.xml - This is the initial data\n",
    "2. WhiteTextUnseen.xml - This is the test data that will be used later for testing and evaluating the model\n",
    "\n",
    "The format given in the file is in xml tags. The sentence is under the \"sentence\" tag and the entities in \"entity\" tag and the interaction is given in \"pair\" tag. If there is interaction the argument interaction is 'True' else 'False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"WhiteText_re\" #Specify the xml file to be read\n",
    "# fileName = \"WhiteTextUnseen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('data/'+fileName+'.xml')\n",
    "root = tree.getroot()\n",
    "print root.tag #Checking the tag of the root to see if file was read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the WhiteTextNeg.xml file has extra tags that are not being used and to decrease the memory usage the unwanted 'sentenceanalyses' tags are deleted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root:\n",
    "    for c in child:\n",
    "        for se in c:\n",
    "            if se.tag == 'sentenceanalyses':\n",
    "                c.remove(se) # removing the tag\n",
    "tree.write('data/'+fileName+'_re.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing and counting the number of sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of sentences in the xml document =  4334\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for elem in root.iter('sentence'):\n",
    "    #print elem.attrib['text']\n",
    "    count += 1\n",
    "print \"\\nThe number of sentences in the xml document = \",count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DataFrame\n",
    "Now that we have seen the data in the xml file, we are going to looking at all the connections and storing it in a Pandas DataFrame structure\n",
    "\n",
    "The DataFrame structure that we are following has following columns - [Entity-1, Entity-2. Connection, Sentence]\n",
    "\n",
    "The sentences are read one by one taking 2 brain region mentions at a time. If there are more than 2 brain region mentions then a particular sentence then, is looked into again taking the other 2 brain region combination.\n",
    "\n",
    "The brain region taken into consideration are denoted in the sentence by 'BR1' and 'BR2'. All other mentions of brain regions are denoted by 'BR'. Then it is stored in a Pandas variable.\n",
    "\n",
    "Following are the different methods that were used denoted by numbers. Each method has an additional process before storing into xml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "In the beginning the sentence was not tounched during the creation of csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading xml file\n",
      "Finished...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(columns = ['connection','entity1','entity2','sentence'])\n",
    "print 'Reading xml file'\n",
    "for corpus in root:\n",
    "    for document in corpus:\n",
    "        sentence = document.attrib['text']  #the text was in the argument 'text' of sentence tag\n",
    "        entity = []                         #to store all the entities included in the sentence\n",
    "        br1 = \"\"\n",
    "        br2 = \"\"\n",
    "        direction = -1\n",
    "        for connection in document:\n",
    "            if connection.tag == 'entity':\n",
    "                entity.append(connection.attrib['text'])\n",
    "            if connection.tag == 'pair':                 #Whenever an pair tag encountered\n",
    "                if connection.attrib['interaction'] == 'False':\n",
    "                    direction = 0\n",
    "                elif connection.attrib['interaction'] == 'True' :\n",
    "                    direction = 1\n",
    "                    \n",
    "                br1 = entity[int(connection.attrib['e1'][-1])]   #the number after e denoted index of entity\n",
    "                br2 = entity[int(connection.attrib['e2'][-1])]\n",
    "                data.loc[len(data)] = [direction,br1,br2,sentence]  #storing into the DataFrame\n",
    "\n",
    "print 'Finished...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After storing all the connection sentences in DataFrame, we look at the count of entries in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in DataFrame =  22561\n",
      "Number of sentences with no connection =  19464\n",
      "Number of sentences with connection =  3097\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum opticum</td>\n",
       "      <td>stratum griseum intermedium</td>\n",
       "      <td>For this study, we examined the optic (stratum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum opticum</td>\n",
       "      <td>stratum griseum profundum</td>\n",
       "      <td>For this study, we examined the optic (stratum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum griseum intermedium</td>\n",
       "      <td>stratum griseum profundum</td>\n",
       "      <td>For this study, we examined the optic (stratum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum album intermedium</td>\n",
       "      <td>stratum opticum</td>\n",
       "      <td>For this study, we examined the optic (stratum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum album intermedium</td>\n",
       "      <td>stratum griseum intermedium</td>\n",
       "      <td>For this study, we examined the optic (stratum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  connection                      entity1                      entity2  \\\n",
       "0          0              stratum opticum  stratum griseum intermedium   \n",
       "1          0              stratum opticum    stratum griseum profundum   \n",
       "2          0  stratum griseum intermedium    stratum griseum profundum   \n",
       "3          0    stratum album intermedium              stratum opticum   \n",
       "4          0    stratum album intermedium  stratum griseum intermedium   \n",
       "\n",
       "                                            sentence  \n",
       "0  For this study, we examined the optic (stratum...  \n",
       "1  For this study, we examined the optic (stratum...  \n",
       "2  For this study, we examined the optic (stratum...  \n",
       "3  For this study, we examined the optic (stratum...  \n",
       "4  For this study, we examined the optic (stratum...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Number of entries in DataFrame = \", len(data)\n",
    "count = 0\n",
    "for i in data['connection']:\n",
    "    if i == 0:\n",
    "        count += 1\n",
    "print \"Number of sentences with no connection = \", count\n",
    "print \"Number of sentences with connection = \", len(data) - count\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After storing the data in DataFrame, we are going to store it in a CSV file for use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/'+fileName+'(1).csv',sep='|') #fileName is the name of the file going to be created. sep denoted the delimiter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "After some thinking before creating the csv file, replaced the brain region mentions with associated BR. The brain region was replaced looking at the attribute \"charOffset\" of the \"entity\" tag. This is done because in a sentence there may be multiple mentions of the same BR but the sentence may not show any relation with the other BR. So for better understanding it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading xml file..\n",
      "Finished reading...\n",
      "Number of entries in DataFrame =  22561\n",
      "Number of sentences with no connection =  19464\n",
      "Number of sentences with connection =  3097\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum opticum</td>\n",
       "      <td>stratum griseum intermedium</td>\n",
       "      <td>For this study, we examined the optic (BR1, SO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum opticum</td>\n",
       "      <td>stratum griseum profundum</td>\n",
       "      <td>For this study, we examined the optic (BR1, SO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum griseum intermedium</td>\n",
       "      <td>stratum griseum profundum</td>\n",
       "      <td>For this study, we examined the optic (BR, SO)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum opticum</td>\n",
       "      <td>stratum album intermedium</td>\n",
       "      <td>For this study, we examined the optic (BR1, SO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>stratum griseum intermedium</td>\n",
       "      <td>stratum album intermedium</td>\n",
       "      <td>For this study, we examined the optic (BR, SO)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  connection                      entity1                      entity2  \\\n",
       "0          0              stratum opticum  stratum griseum intermedium   \n",
       "1          0              stratum opticum    stratum griseum profundum   \n",
       "2          0  stratum griseum intermedium    stratum griseum profundum   \n",
       "3          0              stratum opticum    stratum album intermedium   \n",
       "4          0  stratum griseum intermedium    stratum album intermedium   \n",
       "\n",
       "                                            sentence  \n",
       "0  For this study, we examined the optic (BR1, SO...  \n",
       "1  For this study, we examined the optic (BR1, SO...  \n",
       "2  For this study, we examined the optic (BR, SO)...  \n",
       "3  For this study, we examined the optic (BR1, SO...  \n",
       "4  For this study, we examined the optic (BR, SO)...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(columns = ['connection','entity1','entity2','sentence'])\n",
    "\n",
    "print 'Reading xml file..'\n",
    "for corpus in root:\n",
    "    for document in corpus:\n",
    "        sentence = document.attrib['text']\n",
    "        entityStart = []\n",
    "        entityEnd = []\n",
    "        br1 = \"\"\n",
    "        br2 = \"\"\n",
    "        direction = -1\n",
    "        for connection in document:\n",
    "            if connection.tag == 'entity':\n",
    "                sep = connection.attrib['charOffset'].index('-')  #to get the charOffset index\n",
    "                entityStart.append(int(connection.attrib['charOffset'][:sep]))\n",
    "                entityEnd.append(int(connection.attrib['charOffset'][sep+1:])+1)\n",
    "            \n",
    "            if connection.tag == 'pair':           #If tag is pair tag make entry\n",
    "                if connection.attrib['interaction'] == 'False':\n",
    "                    direction = 0\n",
    "                elif connection.attrib['interaction'] == 'True' :\n",
    "                    direction = 1\n",
    "                \n",
    "                ind1 = int(connection.attrib['e1'][connection.attrib['e1'].index('e',20)+1:])\n",
    "                ind2 = int(connection.attrib['e2'][connection.attrib['e2'].index('e',20)+1:])\n",
    "                if ind1 > ind2:         #BR1 is the first encountered mention. Checking if assumed is true.\n",
    "                    temp = ind1\n",
    "                    ind1 = ind2\n",
    "                    ind2 = temp\n",
    "                br1 = sentence[entityStart[ind1]:entityEnd[ind1]]\n",
    "                br2 = sentence[entityStart[ind2]:entityEnd[ind2]]\n",
    "                \n",
    "                if ind1 == 0:\n",
    "                    s = sentence[:entityStart[0]] + \"BR1\"\n",
    "                else :\n",
    "                    s = sentence[:entityStart[0]] + \"BR\"\n",
    "                for i in range(1,len(entityStart)):\n",
    "                    if i == ind1:\n",
    "                        s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR1\"\n",
    "                        continue\n",
    "                    if i == ind2:\n",
    "                        s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR2\"\n",
    "                        continue\n",
    "                    s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR\"\n",
    "                s += sentence[entityEnd[-1]:]\n",
    "                \n",
    "                data.loc[len(data)] = [direction,br1,br2,s]\n",
    "\n",
    "print 'Finished reading...'\n",
    "\n",
    "print \"Number of entries in DataFrame = \", len(data)\n",
    "count = 0\n",
    "for i in data['connection']:\n",
    "    if i == 0:\n",
    "        count += 1\n",
    "print \"Number of sentences with no connection = \", count\n",
    "print \"Number of sentences with connection = \", len(data) - count\n",
    "\n",
    "data.to_csv('data/'+fileName+'(2).csv',sep='|') #fileName is the name of the file going to be created\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "Another type of corpus was built straight from xml file itself. The way of thinking was that the other methods had sentences with same structure with different BR1 and BR2 tags. So from the xml file each sentence is taken and all brain regions are denoted as BR only. As only the connection is being looked into, denoting the region differently should not effect it. \n",
    "\n",
    "The file being generated is only to be used for building the word2vec vector model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading xml file..\n",
      "Finished reading...\n",
      "Number of entries in DataFrame =  4334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For this study, we examined the optic (BR, SO)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connections of the BR with BR in the rat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The present study was undertaken to establish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The anterograde tracer Phaseolus vulgaris-leuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The results of these tracing experiments confi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  For this study, we examined the optic (BR, SO)...\n",
       "1          Connections of the BR with BR in the rat.\n",
       "2  The present study was undertaken to establish ...\n",
       "3  The anterograde tracer Phaseolus vulgaris-leuc...\n",
       "4  The results of these tracing experiments confi..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(columns = ['sentence'])\n",
    "\n",
    "print 'Reading xml file..'\n",
    "for corpus in root:\n",
    "    for document in corpus:\n",
    "        sentence = document.attrib['text']\n",
    "        entityStart = []\n",
    "        entityEnd = []\n",
    "        \n",
    "        for connection in document:\n",
    "            if connection.tag == 'entity':\n",
    "                sep = connection.attrib['charOffset'].index('-')  #to get the charOffset index\n",
    "                entityStart.append(int(connection.attrib['charOffset'][:sep]))\n",
    "                entityEnd.append(int(connection.attrib['charOffset'][sep+1:])+1)\n",
    "                \n",
    "        s = sentence[:entityStart[0]] + \"BR\"\n",
    "        for i in range(1,len(entityStart)):\n",
    "            s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR\"\n",
    "        s += sentence[entityEnd[-1]:]\n",
    "\n",
    "        data.loc[len(data)] = [s]\n",
    "\n",
    "print 'Finished reading...'\n",
    "\n",
    "print \"Number of entries in DataFrame = \", len(data)\n",
    "\n",
    "data.to_csv('data/'+fileName+'(3).csv',sep='|') #fileName is the name of the file going to be created\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \n",
    "Just as above but with BR1 and BR2 denoted. So multiple sentences. There were occurence of duplicates i.e., sentences with same structure of sentence. These sentences were mostly comma seperated list. So these duplicates were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading xml file..\n",
      "Finished reading...\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "result = []\n",
    "print 'Reading xml file..'\n",
    "for corpus in root:\n",
    "    for document in corpus:\n",
    "        sentence = document.attrib['text']\n",
    "        entityStart = []\n",
    "        entityEnd = []\n",
    "        direction = \"\"\n",
    "        \n",
    "        for connection in document:\n",
    "            if connection.tag == 'entity':\n",
    "                sep = connection.attrib['charOffset'].index('-')\n",
    "                entityStart.append(int(connection.attrib['charOffset'][:sep]))\n",
    "                entityEnd.append(int(connection.attrib['charOffset'][sep+1:])+1)\n",
    "            \n",
    "            if connection.tag == 'pair':\n",
    "                if connection.attrib['interaction'] == 'False':\n",
    "                    direction = \"0\"\n",
    "                elif connection.attrib['interaction'] == 'True' :\n",
    "                    direction = \"1\"\n",
    "                \n",
    "                ind1 = int(connection.attrib['e1'][connection.attrib['e1'].index('e',20)+1:])\n",
    "                ind2 = int(connection.attrib['e2'][connection.attrib['e2'].index('e',20)+1:])\n",
    "                if ind1 > ind2:\n",
    "                    temp = ind1\n",
    "                    ind1 = ind2\n",
    "                    ind2 = temp\n",
    "               \n",
    "                if ind1 == 0:\n",
    "                    s = sentence[:entityStart[0]] + \"BR1\"\n",
    "                else :\n",
    "                    s = sentence[:entityStart[0]] + \"BR\"\n",
    "                for i in range(1,len(entityStart)):\n",
    "                    if i == ind1:\n",
    "                        s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR1\"\n",
    "                        continue\n",
    "                    if i == ind2:\n",
    "                        s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR2\"\n",
    "                        continue\n",
    "                    s += sentence[entityEnd[i-1]:entityStart[i]] + \"BR\"\n",
    "                s += sentence[entityEnd[-1]:]\n",
    "                \n",
    "                sentences.append(s)\n",
    "                result.append(direction)\n",
    "\n",
    "print 'Finished reading...'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After denoting of all the BR's we will now remove the duplicates after tokenization of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595 The areas which had only efferent connections from BR1 ( MP ) were BR2 and BR among which BR and BR were previously reported .\n",
      "1142 Among layer 5 pyramidal cells , approximately 27.4 % in infralimbic ( IL ) / BR ( PL ) / BR1 projected to BR2 ( LH ) , 22.9 % in infralimbic ( IL ) /BR ( PL ) to BR , 18.3 % in BR/BR ( PL ) to BR , and 8.1 % in areas infralimbic ( IL ) / BR ( PL ) to BR ( BLA ) ; and 37 % of layer 6 pyramidal cells in infralimbic ( IL ) / BR ( PL ) /BR projected to BR ( MD ) .\n",
      "2656 The BR1 ( EP ) is a major outflow nucleus of BR and innervates BR2 ( VL ) , BR ( VM ) , and BR .\n",
      "3624 Nearly every BR1 site received a projection from BR2 and BR .\n",
      "3710 Most BR1 were also innervated by unique combinations of BR such as BR and BR ; BR2 and BR ; and , BR .\n",
      "4040 The results are as follows : 1 ) part of BR located around BR ( BR1 ) receives its main input from BR and PEip ( BR2 of Pandya and Seltzer , [ 1982 ] J . Comp . )\n",
      "4221 The nuclei composing BR1 ( BR and BR ) displayed differential projections to BR2 and BR reptilian BR and BR .\n",
      "5498 These large ( 20-30 micrometers perikaryon diameter ) multipolar neurons were found scattered through a number of BR1 cell groups : BR2 and BR .\n",
      "6344 The most anterior root associated with BR1 is composed of lateral line afferents that terminate in BR2 .\n",
      "9284 At level of BR1 efferents are BR2 and BR .\n",
      "9286 At level of BR1 efferents are BR and BR2 .\n",
      "9753 In BR1 projections remained in BR2 .\n",
      "15564 The account provides a direct anatomical demonstration of a BR1 input from BR2 and BR .\n",
      "15971 In BR1 ( VCN ) projects to contralateral but not ipsilateral BR2 ( MNTB ) .\n",
      "17233 The following projection pattern was found : BR1 innervates BR2 innervates BR , a BR innervates BR , and a BR innervates BR .\n",
      "17234 The following projection pattern was found : BR innervates BR1 innervates BR2 a BR innervates BR , and a BR innervates BR .\n",
      "17699 Combination of anterograde and retrograde fiber system tracing experiments discloses following crossed topography of olivocerebellar projections : BR projects mainly to BR , whereas its BR1 projects to BR2 and BR .\n",
      "18237 BR1 neurons transported radioactive label preferentially and abundantly to BR ; localized isotope was found in parts of three BR2 ( VLm ) , BR ( VAmc ) , and BR ( DMpl ) 9 Lateral neurons in BR ( SN ) transmitted radioactive label to same BR as BR neuron .\n",
      "18259 BR neurons transported radioactive label preferentially and abundantly to BR ; localized isotope was found in parts of three BR1 ( VLm ) , BR ( VAmc ) , and BR ( DMpl ) 9 Lateral neurons in BR2 ( SN ) transmitted radioactive label to same BR as BR neuron .\n",
      "18699 While vast majority of BR1 cholinergic input seems to come from upper BR2 and especially medially situated patches within BR also appear to receive substantial cholinergic innervation from BR .\n",
      "18702 While vast majority of BR cholinergic input seems to come from upper BR1 and especially medially situated patches within BR also appear to receive substantial cholinergic innervation from BR2 .\n",
      "19809 A rostrocaudal topography exists in BR projection ; BR1 projects to BR2 to more BR , and BR ( although sparsely ) to further caudal areas .\n",
      "19810 A rostrocaudal topography exists in BR projection ; BR projects to BR1 to more BR2 and BR ( although sparsely ) to further caudal areas .\n",
      "21894 In contrast to many other BR1 input to BR2 arrives via two distinctive synaptic pathways , one terminating extraglomerularly and other terminating within synaptic glomeruli .\n",
      "24\n",
      "Number of entries in DataFrame =  16541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>For this study , we examined optic ( BR1 SO ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>For this study , we examined optic ( BR1 SO ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>For this study , we examined optic ( BR , SO )...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>For this study , we examined optic ( BR1 SO ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>For this study , we examined optic ( BR , SO )...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  connection                                           sentence\n",
       "0          0  For this study , we examined optic ( BR1 SO ) ...\n",
       "1          0  For this study , we examined optic ( BR1 SO ) ...\n",
       "2          0  For this study , we examined optic ( BR , SO )...\n",
       "3          0  For this study , we examined optic ( BR1 SO ) ...\n",
       "4          0  For this study , we examined optic ( BR , SO )..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "uniqueSent = []\n",
    "for sentence in sentences:\n",
    "    sentence = re.sub(\"\\s(the|The)\\s\",\" \",sentence)\n",
    "    sentence = re.sub(\"[, ]*(BR)([, ]*(BR[, ]))+\",\" BR \",sentence)\n",
    "    sentence = re.sub(\"[, ]*(BR[, ]+)*(BR1[, ]*)(BR[, ])*\",\" BR1 \",sentence)\n",
    "    sentence = re.sub(\"[, ]*(BR[, ]+)*(BR2[, ]*)(BR[, ])*\",\" BR2 \",sentence)\n",
    "    sentence = word_tokenize(sentence)\n",
    "    uniqueSent.append(' '.join(sentence))\n",
    "uniqueSent\n",
    "\n",
    "data = pd.DataFrame(columns = ['connection','sentence'])\n",
    "count = 0\n",
    "for i,isent in enumerate(uniqueSent):\n",
    "    flag = 0\n",
    "    for j,jsent in enumerate(uniqueSent[:i]): #Checking if the sentence occurred anywhere before\n",
    "        if isent == jsent:\n",
    "            if result[i] == result[j]:     #Sentence same, but to be sure ground truth also checked\n",
    "                flag = 1\n",
    "                break\n",
    "            else:\n",
    "                flag = 2\n",
    "    if flag == 2:\n",
    "        print i,isent\n",
    "        count += 1\n",
    "    if flag == 0:\n",
    "        data.loc[len(data)] = [result[i],isent]\n",
    "print count\n",
    "len(data)\n",
    "\n",
    "\n",
    "print \"Number of entries in DataFrame = \", len(data)\n",
    "\n",
    "data.to_csv('data/'+fileName+'(Fin).csv',sep='|') #fileName is the name of the file going to be created\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
