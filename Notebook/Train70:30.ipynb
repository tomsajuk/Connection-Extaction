{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models for predicting labels\n",
    "\n",
    "## Train and Test Data\n",
    "Before going forward, the first and foremost step is to divide the data into training and test data in 70:30 ration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fileName = \"WhiteText(1).csv\"\n",
    "data = pd.read_csv('data/'+fileName,delimiter=\"|\")\n",
    "\n",
    "trainSet, testSet = train_test_split(data, test_size=0.3, random_state=3)\n",
    "\n",
    "trainSet.to_csv('Train(1)',sep=\"|\")\n",
    "testSet.to_csv('Test(1)',sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have divided the data into Train and Test data we are now going to build models\n",
    "\n",
    "-----------\n",
    "\n",
    "### Sentence preprocessing\n",
    "At the start the Brain region mentions that were being looked into were tagged into BR1 and BR2 using replace function. Some more preprocessing were also done, which will be added on as we go on.\n",
    "\n",
    "So first reading the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15792\n",
      "6769\n"
     ]
    }
   ],
   "source": [
    "trainData = pd.read_csv('Train(1)',delimiter='|')\n",
    "trainSen = trainData['sentence']\n",
    "trainEn1 = trainData['entity1']\n",
    "trainEn2 = trainData['entity2']\n",
    "trainLab = trainData['connection']\n",
    "trainLen = len(trainSen)\n",
    "print trainLen\n",
    "\n",
    "testData = pd.read_csv('Test(1)',delimiter='|')\n",
    "testSen = testData['sentence']\n",
    "testEn1 = testData['entity1']\n",
    "testEn2 = testData['entity2']\n",
    "testLab = testData['connection']\n",
    "testLen = len(testSen)\n",
    "print testLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be replacing every instance of the occurence of Entity1 and Entity2 in a sentence. After that removing of words inside brackets, and removing all characters other than alphabets and lowering the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replaceBR(s, en1, en2):\n",
    "    s = s.replace(en1,\" BR1 \")\n",
    "    s = s.replace(en2,\" BR2 \")\n",
    "    return s\n",
    "\n",
    "def formatSen(x):\n",
    "    x = re.sub(\"\\((.*?)\\)\",\" \",x.lower())\n",
    "    x = re.sub(\"^[ ]*([a-z])\",r\"\\1\",x)\n",
    "    return re.sub(\"[^a-z0-9]\",\" \",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFSen = []\n",
    "for i in range(0,trainLen):\n",
    "    trainFSen.append(replaceBR(trainSen[i], trainEn1[i], trainEn2[i]))\n",
    "    trainFSen[i] = formatSen(trainFSen[i])\n",
    "    \n",
    "testFSen = []\n",
    "for i in range(0,testLen):\n",
    "    testFSen.append(replaceBR(testSen[i], testEn1[i], testEn2[i]))\n",
    "    testFSen[i] = formatSen(testFSen[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After formatting all the sentences we come to a way to represent sentences as numbers as classfication models accept numbers only.\n",
    "\n",
    "## Word Embedding\n",
    "The input for all models that have been created till date take numbers as input. They donot accept words or letters. So we need to convert these words into corresponding numbers that would identity that word. This process is called word embedding.\n",
    "\n",
    "There are different word embedding techniques.\n",
    "1. Count Vectorization\n",
    "2. Tf-idf Vectorization\n",
    "3. Word2Vec Embedding\n",
    "4. FastText\n",
    "\n",
    "CountVectorization take each count of a particular word in a sentence. The whole array formed later is used as the representation basis. This is not being used as this would create a pattern based classifier and also perform bad.\n",
    "\n",
    "#### Tf-idf Vec\n",
    "Tf-idf Vectorization takes term frequency and inverse document frequency into consideration for denoting a value for a word. Common words that appear repeatedly in a sentence are given lesser value than rare words. We will be implementing this.\n",
    "\n",
    "\n",
    "#### Word2Vec\n",
    "Word2Vec Embedding is a model that is trained on set of sentences. The hidden layer weight after training is used a the representation of a word. Model training is already done on both train and test data together.\n",
    "\n",
    "To represent a sentence using word2vec here we are going to be taking the mean of all the word vectors present in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def convertTfidf(train, test):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,3))               #Calling tfidf Vectorizer\n",
    "    train_vect = vectorizer.fit_transform(train) #Fitting the training data for getting tfidf values\n",
    "    test_vect = vectorizer.transform(test)       #Transforming test sentences to their respective tfidf vector\n",
    "    return train_vect, test_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Models\n",
    "The different classifier algorithms that are going to be used are - \n",
    "1. Bernoulli Navies Bayes\n",
    "2. Bagging Classifier\n",
    "3. Decision Tree Classifier\n",
    "4. Random Forest Classifier\n",
    "5. Extra Trees Classifier\n",
    "6. Calibrated Classifier\n",
    "7. SGD Classifier\n",
    "8. K-Neighbours Classifier\n",
    "9. MLP Classifier\n",
    "Each have their own speciality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.neural_network import *\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "classifiers = [BernoulliNB(), \n",
    "               RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "               BaggingClassifier(n_estimators=100, n_jobs=-1), \n",
    "               ExtraTreesClassifier(n_jobs=-1),\n",
    "               DecisionTreeClassifier(criterion='gini',splitter='random'), \n",
    "               CalibratedClassifierCV(),\n",
    "               SGDClassifier(n_jobs=-1), \n",
    "               KNeighborsClassifier(n_neighbors=1,weights='distance',n_jobs=-1,algorithm='kd_tree'),\n",
    "               MLPClassifier(hidden_layer_sizes=(100,100,),verbose=True)]\n",
    "\n",
    "def classify(train_vect,trainLab,test_vect,testLab):\n",
    "    tableRep = PrettyTable(['Name','Precision','Recall','F1 Score','Accuracy'])\n",
    "    #tableSent = []\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "\n",
    "        print \"Training \",classifier.__class__.__name__\n",
    "        classifier.fit(train_vect, trainLab)\n",
    "\n",
    "        score = classifier.predict(test_vect)\n",
    "        \n",
    "        mat = confusion_matrix(testLab, score)\n",
    "\n",
    "        print mat\n",
    "        tp = mat[1][1]\n",
    "        fp = mat[0][1]\n",
    "        fn = mat[1][0]\n",
    "        tn = mat[0][0]\n",
    "        if tp == 0 :\n",
    "            recall = 0.0\n",
    "            precision = 0.0\n",
    "            f1 = 0.0\n",
    "        else :\n",
    "            recall = float(tp)/float((tp+fn))\n",
    "            precision = float(tp)/float((tp+fp))\n",
    "            f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "        accuracy = float(tp+tn)/float(len(testLab))\n",
    "        print precision,recall,f1\n",
    "        tableRep.add_row([classifier.__class__.__name__,precision,recall,f1,accuracy])\n",
    "    return tableRep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[3543 2319]\n",
      " [ 190  717]]\n",
      "0.236166007905 0.790518191841 0.363682475273\n",
      "Training  RandomForestClassifier\n",
      "[[5564  298]\n",
      " [ 694  213]]\n",
      "0.416829745597 0.234840132304 0.300423131171\n",
      "Training  BaggingClassifier\n",
      "[[5512  350]\n",
      " [ 644  263]]\n",
      "0.429037520392 0.289966923925 0.346052631579\n",
      "Training  ExtraTreesClassifier\n",
      "[[5522  340]\n",
      " [ 698  209]]\n",
      "0.380692167577 0.230429988975 0.287087912088\n",
      "Training  DecisionTreeClassifier\n",
      "[[5354  508]\n",
      " [ 593  314]]\n",
      "0.38199513382 0.346196251378 0.363215731637\n",
      "Training  CalibratedClassifierCV\n",
      "[[5781   81]\n",
      " [ 821   86]]\n",
      "0.51497005988 0.0948180815877 0.160148975791\n",
      "Training  SGDClassifier\n",
      "[[5846   16]\n",
      " [ 894   13]]\n",
      "0.448275862069 0.0143329658214 0.0277777777778\n",
      "Training  KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsk/tensorflow/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/tsk/tensorflow/local/lib/python2.7/site-packages/sklearn/neighbors/base.py:212: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5197  665]\n",
      " [ 548  359]]\n",
      "0.3505859375 0.395810363837 0.371828068358\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.45372467\n",
      "Iteration 2, loss = 0.32724173\n",
      "Iteration 3, loss = 0.28322503\n",
      "Iteration 4, loss = 0.25340585\n",
      "Iteration 5, loss = 0.23047133\n",
      "Iteration 6, loss = 0.20991659\n",
      "Iteration 7, loss = 0.19354485\n",
      "Iteration 8, loss = 0.17821918\n",
      "Iteration 9, loss = 0.16480716\n",
      "Iteration 10, loss = 0.15450122\n",
      "Iteration 11, loss = 0.14341708\n",
      "Iteration 12, loss = 0.13663411\n",
      "Iteration 13, loss = 0.12929221\n",
      "Iteration 14, loss = 0.12174132\n",
      "Iteration 15, loss = 0.11587072\n",
      "Iteration 16, loss = 0.11092697\n",
      "Iteration 17, loss = 0.10739457\n",
      "Iteration 18, loss = 0.10189406\n",
      "Iteration 19, loss = 0.10012151\n",
      "Iteration 20, loss = 0.09569567\n",
      "Iteration 21, loss = 0.09365734\n",
      "Iteration 22, loss = 0.09021999\n",
      "Iteration 23, loss = 0.09009115\n",
      "Iteration 24, loss = 0.08721443\n",
      "Iteration 25, loss = 0.08474139\n",
      "Iteration 26, loss = 0.08319176\n",
      "Iteration 27, loss = 0.08179760\n",
      "Iteration 28, loss = 0.07954279\n",
      "Iteration 29, loss = 0.07947525\n",
      "Iteration 30, loss = 0.07762097\n",
      "Iteration 31, loss = 0.07547323\n",
      "Iteration 32, loss = 0.07495359\n",
      "Iteration 33, loss = 0.07594062\n",
      "Iteration 34, loss = 0.07161663\n",
      "Iteration 35, loss = 0.07238688\n",
      "Iteration 36, loss = 0.07094471\n",
      "Iteration 37, loss = 0.07108588\n",
      "Iteration 38, loss = 0.06946397\n",
      "Iteration 39, loss = 0.06888411\n",
      "Iteration 40, loss = 0.06806587\n",
      "Iteration 41, loss = 0.06661706\n",
      "Iteration 42, loss = 0.06729790\n",
      "Iteration 43, loss = 0.06663410\n",
      "Iteration 44, loss = 0.06540345\n",
      "Iteration 45, loss = 0.06382147\n",
      "Iteration 46, loss = 0.06302667\n",
      "Iteration 47, loss = 0.06404621\n",
      "Iteration 48, loss = 0.06346595\n",
      "Iteration 49, loss = 0.06303805\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5461  401]\n",
      " [ 549  358]]\n",
      "0.471673254282 0.394707828004 0.429771908764\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.236166007905 |  0.790518191841 |  0.363682475273 | 0.629339636579 |\n",
      "| RandomForestClassifier | 0.416829745597 |  0.234840132304 |  0.300423131171 | 0.853449549416 |\n",
      "|   BaggingClassifier    | 0.429037520392 |  0.289966923925 |  0.346052631579 | 0.853154084798 |\n",
      "|  ExtraTreesClassifier  | 0.380692167577 |  0.230429988975 |  0.287087912088 |  0.8466538632  |\n",
      "| DecisionTreeClassifier | 0.38199513382  |  0.346196251378 |  0.363215731637 | 0.837346727729 |\n",
      "| CalibratedClassifierCV | 0.51497005988  | 0.0948180815877 |  0.160148975791 | 0.866745457231 |\n",
      "|     SGDClassifier      | 0.448275862069 | 0.0143329658214 | 0.0277777777778 | 0.865563598759 |\n",
      "|  KNeighborsClassifier  |  0.3505859375  |  0.395810363837 |  0.371828068358 | 0.820800709115 |\n",
      "|     MLPClassifier      | 0.471673254282 |  0.394707828004 |  0.429771908764 | 0.859654306397 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idf has a argument called n_gram where the words are taken together according to the argument value. So here we are going to be taking n_gram=(1,3) as this had better classifier report than other n_grams. From here on Tf-IDF Vectorizer will be taking n_grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[4418 1444]\n",
      " [ 338  569]]\n",
      "0.282662692499 0.627342888644 0.389726027397\n",
      "Training  RandomForestClassifier\n",
      "[[5616  246]\n",
      " [ 688  219]]\n",
      "0.470967741935 0.241455347299 0.319241982507\n",
      "Training  BaggingClassifier\n",
      "[[5549  313]\n",
      " [ 590  317]]\n",
      "0.503174603175 0.349503858875 0.412491867274\n",
      "Training  ExtraTreesClassifier\n",
      "[[5591  271]\n",
      " [ 688  219]]\n",
      "0.44693877551 0.241455347299 0.313528990694\n",
      "Training  DecisionTreeClassifier\n",
      "[[5382  480]\n",
      " [ 548  359]]\n",
      "0.42789034565 0.395810363837 0.411225658648\n",
      "Training  CalibratedClassifierCV\n",
      "[[5715  147]\n",
      " [ 688  219]]\n",
      "0.598360655738 0.241455347299 0.344069128044\n",
      "Training  SGDClassifier\n",
      "[[5809   53]\n",
      " [ 832   75]]\n",
      "0.5859375 0.0826901874311 0.144927536232\n",
      "Training  KNeighborsClassifier\n",
      "[[5263  599]\n",
      " [ 551  356]]\n",
      "0.37277486911 0.39250275634 0.38238453276\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.41399153\n",
      "Iteration 2, loss = 0.25059892\n",
      "Iteration 3, loss = 0.17640629\n",
      "Iteration 4, loss = 0.13491671\n",
      "Iteration 5, loss = 0.11339382\n",
      "Iteration 6, loss = 0.09768307\n",
      "Iteration 7, loss = 0.08806963\n",
      "Iteration 8, loss = 0.08011509\n",
      "Iteration 9, loss = 0.07680276\n",
      "Iteration 10, loss = 0.07164775\n",
      "Iteration 11, loss = 0.06758210\n",
      "Iteration 12, loss = 0.06424027\n",
      "Iteration 13, loss = 0.06192552\n",
      "Iteration 14, loss = 0.06003477\n",
      "Iteration 15, loss = 0.05657959\n",
      "Iteration 16, loss = 0.05456733\n",
      "Iteration 17, loss = 0.05310727\n",
      "Iteration 18, loss = 0.05112951\n",
      "Iteration 19, loss = 0.05010989\n",
      "Iteration 20, loss = 0.04884725\n",
      "Iteration 21, loss = 0.04781503\n",
      "Iteration 22, loss = 0.04567609\n",
      "Iteration 23, loss = 0.04450959\n",
      "Iteration 24, loss = 0.04502668\n",
      "Iteration 25, loss = 0.04357804\n",
      "Iteration 26, loss = 0.04347721\n",
      "Iteration 27, loss = 0.04231433\n",
      "Iteration 28, loss = 0.04076572\n",
      "Iteration 29, loss = 0.04077704\n",
      "Iteration 30, loss = 0.04042136\n",
      "Iteration 31, loss = 0.03876444\n",
      "Iteration 32, loss = 0.03828725\n",
      "Iteration 33, loss = 0.03811239\n",
      "Iteration 34, loss = 0.03881233\n",
      "Iteration 35, loss = 0.03819961\n",
      "Iteration 36, loss = 0.03700815\n",
      "Iteration 37, loss = 0.03630305\n",
      "Iteration 38, loss = 0.03637707\n",
      "Iteration 39, loss = 0.03546469\n",
      "Iteration 40, loss = 0.03695106\n",
      "Iteration 41, loss = 0.03579121\n",
      "Iteration 42, loss = 0.03596932\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5497  365]\n",
      " [ 489  418]]\n",
      "0.533844189017 0.460859977949 0.494674556213\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.282662692499 |  0.627342888644 | 0.389726027397 | 0.736741025262 |\n",
      "| RandomForestClassifier | 0.470967741935 |  0.241455347299 | 0.319241982507 | 0.862018023342 |\n",
      "|   BaggingClassifier    | 0.503174603175 |  0.349503858875 | 0.412491867274 | 0.866597724922 |\n",
      "|  ExtraTreesClassifier  | 0.44693877551  |  0.241455347299 | 0.313528990694 | 0.858324715615 |\n",
      "| DecisionTreeClassifier | 0.42789034565  |  0.395810363837 | 0.411225658648 | 0.84813118629  |\n",
      "| CalibratedClassifierCV | 0.598360655738 |  0.241455347299 | 0.344069128044 | 0.876643521938 |\n",
      "|     SGDClassifier      |   0.5859375    | 0.0826901874311 | 0.144927536232 | 0.869256906485 |\n",
      "|  KNeighborsClassifier  | 0.37277486911  |  0.39250275634  | 0.38238453276  | 0.830107844586 |\n",
      "|     MLPClassifier      | 0.533844189017 |  0.460859977949 | 0.494674556213 | 0.873836608066 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using word2vec embedding we need to first load the model here for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def loadW2V(modelName):\n",
    "    model = word2vec.Word2Vec.load(modelName)\n",
    "    return dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "\n",
    "def convertW2V(data,w2v):\n",
    "    wholeM = []\n",
    "    count = 0\n",
    "    le = 0\n",
    "    print 'Embedding...',len(data)\n",
    "    for sentence in data:\n",
    "        le += 1\n",
    "        arr = []    \n",
    "        for word in sentence.split():\n",
    "            if word in w2v:\n",
    "                arr.append(np.array(w2v[word],copy=True))  \n",
    "                                #Each word is checked if it is there in the word2vec vocabulary. If there then\n",
    "                                #the vector space for the word is taken and then the mean is calculated.\n",
    "\n",
    "        mean = np.zeros(100)\n",
    "        for mat in arr:\n",
    "            for j in range(len(mat)):\n",
    "                mean[j] += mat[j]\n",
    "        if len(arr) != 0:\n",
    "            mean = np.array(mean/len(arr))\n",
    "        else:\n",
    "            count +=1\n",
    "        wholeM.append(mean)\n",
    "    print count,le\n",
    "    return wholeM\n",
    "\n",
    "def buildW2V(modelName, train, test):\n",
    "    w2v = loadW2V(\"w2v_models/\"+modelName)\n",
    "    train_vect = convertW2V(train,w2v)\n",
    "    test_vect = convertW2V(test,w2v)\n",
    "    return train_vect, test_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4663 1199]\n",
      " [ 539  368]]\n",
      "0.234843650287 0.405733186329 0.297493936944\n",
      "Training  RandomForestClassifier\n",
      "[[5678  184]\n",
      " [ 782  125]]\n",
      "0.404530744337 0.137816979052 0.205592105263\n",
      "Training  BaggingClassifier\n",
      "[[5639  223]\n",
      " [ 765  142]]\n",
      "0.38904109589 0.156560088203 0.223270440252\n",
      "Training  ExtraTreesClassifier\n",
      "[[5624  238]\n",
      " [ 759  148]]\n",
      "0.383419689119 0.163175303197 0.228924980665\n",
      "Training  DecisionTreeClassifier\n",
      "[[5277  585]\n",
      " [ 636  271]]\n",
      "0.316588785047 0.298787210584 0.307430516166\n",
      "Training  CalibratedClassifierCV\n",
      "[[5801   61]\n",
      " [ 850   57]]\n",
      "0.483050847458 0.0628445424476 0.111219512195\n",
      "Training  SGDClassifier\n",
      "[[5817   45]\n",
      " [ 873   34]]\n",
      "0.430379746835 0.0374862183021 0.0689655172414\n",
      "Training  KNeighborsClassifier\n",
      "[[5303  559]\n",
      " [ 590  317]]\n",
      "0.361872146119 0.349503858875 0.355580482333\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.42508162\n",
      "Iteration 2, loss = 0.34804531\n",
      "Iteration 3, loss = 0.33855452\n",
      "Iteration 4, loss = 0.33037543\n",
      "Iteration 5, loss = 0.32400628\n",
      "Iteration 6, loss = 0.31666187\n",
      "Iteration 7, loss = 0.31063258\n",
      "Iteration 8, loss = 0.30345357\n",
      "Iteration 9, loss = 0.29758846\n",
      "Iteration 10, loss = 0.29242361\n",
      "Iteration 11, loss = 0.28703904\n",
      "Iteration 12, loss = 0.28110304\n",
      "Iteration 13, loss = 0.27520188\n",
      "Iteration 14, loss = 0.26968163\n",
      "Iteration 15, loss = 0.26588961\n",
      "Iteration 16, loss = 0.26152886\n",
      "Iteration 17, loss = 0.25659903\n",
      "Iteration 18, loss = 0.25185285\n",
      "Iteration 19, loss = 0.24749875\n",
      "Iteration 20, loss = 0.24416969\n",
      "Iteration 21, loss = 0.24107580\n",
      "Iteration 22, loss = 0.23678883\n",
      "Iteration 23, loss = 0.23372925\n",
      "Iteration 24, loss = 0.23146119\n",
      "Iteration 25, loss = 0.22668258\n",
      "Iteration 26, loss = 0.22461098\n",
      "Iteration 27, loss = 0.22076766\n",
      "Iteration 28, loss = 0.21703571\n",
      "Iteration 29, loss = 0.21500476\n",
      "Iteration 30, loss = 0.21343335\n",
      "Iteration 31, loss = 0.20836913\n",
      "Iteration 32, loss = 0.20578287\n",
      "Iteration 33, loss = 0.20340315\n",
      "Iteration 34, loss = 0.19898391\n",
      "Iteration 35, loss = 0.19506762\n",
      "Iteration 36, loss = 0.19587410\n",
      "Iteration 37, loss = 0.19130732\n",
      "Iteration 38, loss = 0.18900153\n",
      "Iteration 39, loss = 0.19135251\n",
      "Iteration 40, loss = 0.18544558\n",
      "Iteration 41, loss = 0.18310674\n",
      "Iteration 42, loss = 0.18323655\n",
      "Iteration 43, loss = 0.17954145\n",
      "Iteration 44, loss = 0.17726409\n",
      "Iteration 45, loss = 0.17694781\n",
      "Iteration 46, loss = 0.17309202\n",
      "Iteration 47, loss = 0.17268616\n",
      "Iteration 48, loss = 0.16906431\n",
      "Iteration 49, loss = 0.16747552\n",
      "Iteration 50, loss = 0.16577001\n",
      "Iteration 51, loss = 0.16551640\n",
      "Iteration 52, loss = 0.16664306\n",
      "Iteration 53, loss = 0.16185846\n",
      "Iteration 54, loss = 0.16295602\n",
      "Iteration 55, loss = 0.16181648\n",
      "Iteration 56, loss = 0.16090225\n",
      "Iteration 57, loss = 0.15405084\n",
      "Iteration 58, loss = 0.15530488\n",
      "Iteration 59, loss = 0.15301228\n",
      "Iteration 60, loss = 0.15064338\n",
      "Iteration 61, loss = 0.15205434\n",
      "Iteration 62, loss = 0.14930435\n",
      "Iteration 63, loss = 0.14954642\n",
      "Iteration 64, loss = 0.14917393\n",
      "Iteration 65, loss = 0.14701597\n",
      "Iteration 66, loss = 0.14507283\n",
      "Iteration 67, loss = 0.14553504\n",
      "Iteration 68, loss = 0.14453600\n",
      "Iteration 69, loss = 0.14724495\n",
      "Iteration 70, loss = 0.14220504\n",
      "Iteration 71, loss = 0.14120269\n",
      "Iteration 72, loss = 0.14370053\n",
      "Iteration 73, loss = 0.14025808\n",
      "Iteration 74, loss = 0.14111448\n",
      "Iteration 75, loss = 0.13661756\n",
      "Iteration 76, loss = 0.13409407\n",
      "Iteration 77, loss = 0.13359350\n",
      "Iteration 78, loss = 0.13561672\n",
      "Iteration 79, loss = 0.13660363\n",
      "Iteration 80, loss = 0.13368343\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5466  396]\n",
      " [ 604  303]]\n",
      "0.43347639485 0.334068357222 0.377334993773\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.234843650287 |  0.405733186329 |  0.297493936944 | 0.743241246861 |\n",
      "| RandomForestClassifier | 0.404530744337 |  0.137816979052 |  0.205592105263 | 0.857290589452 |\n",
      "|   BaggingClassifier    | 0.38904109589  |  0.156560088203 |  0.223270440252 | 0.854040478653 |\n",
      "|  ExtraTreesClassifier  | 0.383419689119 |  0.163175303197 |  0.228924980665 | 0.852710887871 |\n",
      "| DecisionTreeClassifier | 0.316588785047 |  0.298787210584 |  0.307430516166 | 0.819618850643 |\n",
      "| CalibratedClassifierCV | 0.483050847458 | 0.0628445424476 |  0.111219512195 | 0.86541586645  |\n",
      "|     SGDClassifier      | 0.430379746835 | 0.0374862183021 | 0.0689655172414 | 0.864381740287 |\n",
      "|  KNeighborsClassifier  | 0.361872146119 |  0.349503858875 |  0.355580482333 | 0.830255576895 |\n",
      "|     MLPClassifier      | 0.43347639485  |  0.334068357222 |  0.377334993773 | 0.852267690944 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4886  976]\n",
      " [ 551  356]]\n",
      "0.267267267267 0.39250275634 0.317999106744\n",
      "Training  RandomForestClassifier\n",
      "[[5606  256]\n",
      " [ 742  165]]\n",
      "0.391923990499 0.181918412348 0.248493975904\n",
      "Training  BaggingClassifier\n",
      "[[5579  283]\n",
      " [ 717  190]]\n",
      "0.401691331924 0.209481808159 0.275362318841\n",
      "Training  ExtraTreesClassifier\n",
      "[[5562  300]\n",
      " [ 721  186]]\n",
      "0.382716049383 0.205071664829 0.267049533381\n",
      "Training  DecisionTreeClassifier\n",
      "[[5300  562]\n",
      " [ 644  263]]\n",
      "0.318787878788 0.289966923925 0.303695150115\n",
      "Training  CalibratedClassifierCV\n",
      "[[5806   56]\n",
      " [ 852   55]]\n",
      "0.495495495495 0.0606394707828 0.108055009823\n",
      "Training  SGDClassifier\n",
      "[[5832   30]\n",
      " [ 882   25]]\n",
      "0.454545454545 0.0275633958104 0.0519750519751\n",
      "Training  KNeighborsClassifier\n",
      "[[5307  555]\n",
      " [ 606  301]]\n",
      "0.351635514019 0.331863285557 0.341463414634\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.41875534\n",
      "Iteration 2, loss = 0.35524657\n",
      "Iteration 3, loss = 0.34697990\n",
      "Iteration 4, loss = 0.33860186\n",
      "Iteration 5, loss = 0.33161801\n",
      "Iteration 6, loss = 0.32549909\n",
      "Iteration 7, loss = 0.31977398\n",
      "Iteration 8, loss = 0.31437691\n",
      "Iteration 9, loss = 0.31036175\n",
      "Iteration 10, loss = 0.30618203\n",
      "Iteration 11, loss = 0.30167207\n",
      "Iteration 12, loss = 0.29915390\n",
      "Iteration 13, loss = 0.29306612\n",
      "Iteration 14, loss = 0.28903491\n",
      "Iteration 15, loss = 0.28559820\n",
      "Iteration 16, loss = 0.28172035\n",
      "Iteration 17, loss = 0.27867863\n",
      "Iteration 18, loss = 0.27654905\n",
      "Iteration 19, loss = 0.27178684\n",
      "Iteration 20, loss = 0.27040192\n",
      "Iteration 21, loss = 0.26739239\n",
      "Iteration 22, loss = 0.26490219\n",
      "Iteration 23, loss = 0.26008074\n",
      "Iteration 24, loss = 0.25880481\n",
      "Iteration 25, loss = 0.25752647\n",
      "Iteration 26, loss = 0.25385131\n",
      "Iteration 27, loss = 0.25186008\n",
      "Iteration 28, loss = 0.25026468\n",
      "Iteration 29, loss = 0.24820258\n",
      "Iteration 30, loss = 0.24541019\n",
      "Iteration 31, loss = 0.24443333\n",
      "Iteration 32, loss = 0.24163418\n",
      "Iteration 33, loss = 0.24219798\n",
      "Iteration 34, loss = 0.23830109\n",
      "Iteration 35, loss = 0.23722403\n",
      "Iteration 36, loss = 0.23699178\n",
      "Iteration 37, loss = 0.23253564\n",
      "Iteration 38, loss = 0.23083588\n",
      "Iteration 39, loss = 0.22917858\n",
      "Iteration 40, loss = 0.22851209\n",
      "Iteration 41, loss = 0.22759223\n",
      "Iteration 42, loss = 0.22554456\n",
      "Iteration 43, loss = 0.22484954\n",
      "Iteration 44, loss = 0.22380902\n",
      "Iteration 45, loss = 0.22323216\n",
      "Iteration 46, loss = 0.22006184\n",
      "Iteration 47, loss = 0.21810439\n",
      "Iteration 48, loss = 0.21589416\n",
      "Iteration 49, loss = 0.21289924\n",
      "Iteration 50, loss = 0.21291558\n",
      "Iteration 51, loss = 0.21092777\n",
      "Iteration 52, loss = 0.21158746\n",
      "Iteration 53, loss = 0.21092055\n",
      "Iteration 54, loss = 0.20769496\n",
      "Iteration 55, loss = 0.20980907\n",
      "Iteration 56, loss = 0.20809430\n",
      "Iteration 57, loss = 0.20699419\n",
      "Iteration 58, loss = 0.20486337\n",
      "Iteration 59, loss = 0.20411232\n",
      "Iteration 60, loss = 0.20196305\n",
      "Iteration 61, loss = 0.20081194\n",
      "Iteration 62, loss = 0.19917165\n",
      "Iteration 63, loss = 0.20069769\n",
      "Iteration 64, loss = 0.19858106\n",
      "Iteration 65, loss = 0.19681276\n",
      "Iteration 66, loss = 0.19629959\n",
      "Iteration 67, loss = 0.19830387\n",
      "Iteration 68, loss = 0.19662311\n",
      "Iteration 69, loss = 0.19617521\n",
      "Iteration 70, loss = 0.19658858\n",
      "Iteration 71, loss = 0.19480709\n",
      "Iteration 72, loss = 0.19376053\n",
      "Iteration 73, loss = 0.19240610\n",
      "Iteration 74, loss = 0.19083539\n",
      "Iteration 75, loss = 0.19036288\n",
      "Iteration 76, loss = 0.18797524\n",
      "Iteration 77, loss = 0.18561900\n",
      "Iteration 78, loss = 0.18869536\n",
      "Iteration 79, loss = 0.18579696\n",
      "Iteration 80, loss = 0.18509697\n",
      "Iteration 81, loss = 0.18444574\n",
      "Iteration 82, loss = 0.18346811\n",
      "Iteration 83, loss = 0.18549809\n",
      "Iteration 84, loss = 0.18461883\n",
      "Iteration 85, loss = 0.18369598\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5523  339]\n",
      " [ 661  246]]\n",
      "0.420512820513 0.271223814774 0.329758713137\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.267267267267 |  0.39250275634  |  0.317999106744 | 0.774412764072 |\n",
      "| RandomForestClassifier | 0.391923990499 |  0.181918412348 |  0.248493975904 | 0.852563155562 |\n",
      "|   BaggingClassifier    | 0.401691331924 |  0.209481808159 |  0.275362318841 | 0.852267690944 |\n",
      "|  ExtraTreesClassifier  | 0.382716049383 |  0.205071664829 |  0.267049533381 | 0.849165312454 |\n",
      "| DecisionTreeClassifier | 0.318787878788 |  0.289966923925 |  0.303695150115 | 0.821834835278 |\n",
      "| CalibratedClassifierCV | 0.495495495495 | 0.0606394707828 |  0.108055009823 | 0.865859063377 |\n",
      "|     SGDClassifier      | 0.454545454545 | 0.0275633958104 | 0.0519750519751 | 0.865268134141 |\n",
      "|  KNeighborsClassifier  | 0.351635514019 |  0.331863285557 |  0.341463414634 | 0.828482789186 |\n",
      "|     MLPClassifier      | 0.420512820513 |  0.271223814774 |  0.329758713137 | 0.852267690944 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4328 1534]\n",
      " [ 480  427]]\n",
      "0.217746047935 0.470782800441 0.297768479777\n",
      "Training  RandomForestClassifier\n",
      "[[5692  170]\n",
      " [ 805  102]]\n",
      "0.375 0.112458654906 0.173027989822\n",
      "Training  BaggingClassifier\n",
      "[[5661  201]\n",
      " [ 786  121]]\n",
      "0.375776397516 0.133406835722 0.19690805533\n",
      "Training  ExtraTreesClassifier\n",
      "[[5648  214]\n",
      " [ 780  127]]\n",
      "0.372434017595 0.140022050717 0.203525641026\n",
      "Training  DecisionTreeClassifier\n",
      "[[5299  563]\n",
      " [ 667  240]]\n",
      "0.298879202989 0.264608599779 0.280701754386\n",
      "Training  CalibratedClassifierCV\n",
      "[[5797   65]\n",
      " [ 843   64]]\n",
      "0.496124031008 0.0705622932745 0.123552123552\n",
      "Training  SGDClassifier\n",
      "[[5524  338]\n",
      " [ 753  154]]\n",
      "0.313008130081 0.169790518192 0.220157255182\n",
      "Training  KNeighborsClassifier\n",
      "[[5284  578]\n",
      " [ 597  310]]\n",
      "0.349099099099 0.341786108049 0.345403899721\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.41251046\n",
      "Iteration 2, loss = 0.34756342\n",
      "Iteration 3, loss = 0.33361988\n",
      "Iteration 4, loss = 0.32395314\n",
      "Iteration 5, loss = 0.31441758\n",
      "Iteration 6, loss = 0.30773064\n",
      "Iteration 7, loss = 0.29953615\n",
      "Iteration 8, loss = 0.29162589\n",
      "Iteration 9, loss = 0.28537859\n",
      "Iteration 10, loss = 0.27798219\n",
      "Iteration 11, loss = 0.27113022\n",
      "Iteration 12, loss = 0.26615345\n",
      "Iteration 13, loss = 0.25485559\n",
      "Iteration 14, loss = 0.24852961\n",
      "Iteration 15, loss = 0.24218952\n",
      "Iteration 16, loss = 0.23605476\n",
      "Iteration 17, loss = 0.23006963\n",
      "Iteration 18, loss = 0.22502246\n",
      "Iteration 19, loss = 0.22223731\n",
      "Iteration 20, loss = 0.21482101\n",
      "Iteration 21, loss = 0.20947431\n",
      "Iteration 22, loss = 0.20684546\n",
      "Iteration 23, loss = 0.20243066\n",
      "Iteration 24, loss = 0.19767197\n",
      "Iteration 25, loss = 0.19484428\n",
      "Iteration 26, loss = 0.19153948\n",
      "Iteration 27, loss = 0.18334619\n",
      "Iteration 28, loss = 0.18515668\n",
      "Iteration 29, loss = 0.18128682\n",
      "Iteration 30, loss = 0.17709724\n",
      "Iteration 31, loss = 0.17265249\n",
      "Iteration 32, loss = 0.17628937\n",
      "Iteration 33, loss = 0.16806348\n",
      "Iteration 34, loss = 0.16496002\n",
      "Iteration 35, loss = 0.16210674\n",
      "Iteration 36, loss = 0.16088840\n",
      "Iteration 37, loss = 0.16003205\n",
      "Iteration 38, loss = 0.16013094\n",
      "Iteration 39, loss = 0.16079505\n",
      "Iteration 40, loss = 0.15180931\n",
      "Iteration 41, loss = 0.15174136\n",
      "Iteration 42, loss = 0.14728576\n",
      "Iteration 43, loss = 0.14864368\n",
      "Iteration 44, loss = 0.14661957\n",
      "Iteration 45, loss = 0.14438517\n",
      "Iteration 46, loss = 0.14523057\n",
      "Iteration 47, loss = 0.14334428\n",
      "Iteration 48, loss = 0.14093712\n",
      "Iteration 49, loss = 0.13903067\n",
      "Iteration 50, loss = 0.13616766\n",
      "Iteration 51, loss = 0.13516846\n",
      "Iteration 52, loss = 0.13563031\n",
      "Iteration 53, loss = 0.13287724\n",
      "Iteration 54, loss = 0.13059271\n",
      "Iteration 55, loss = 0.13101518\n",
      "Iteration 56, loss = 0.12790710\n",
      "Iteration 57, loss = 0.12677120\n",
      "Iteration 58, loss = 0.12598732\n",
      "Iteration 59, loss = 0.12676443\n",
      "Iteration 60, loss = 0.12496339\n",
      "Iteration 61, loss = 0.12695820\n",
      "Iteration 62, loss = 0.12358208\n",
      "Iteration 63, loss = 0.12192152\n",
      "Iteration 64, loss = 0.12325167\n",
      "Iteration 65, loss = 0.12103239\n",
      "Iteration 66, loss = 0.12211926\n",
      "Iteration 67, loss = 0.11961975\n",
      "Iteration 68, loss = 0.11927826\n",
      "Iteration 69, loss = 0.11830235\n",
      "Iteration 70, loss = 0.11899808\n",
      "Iteration 71, loss = 0.12044515\n",
      "Iteration 72, loss = 0.11514919\n",
      "Iteration 73, loss = 0.11649976\n",
      "Iteration 74, loss = 0.11411661\n",
      "Iteration 75, loss = 0.11474245\n",
      "Iteration 76, loss = 0.11338087\n",
      "Iteration 77, loss = 0.11083813\n",
      "Iteration 78, loss = 0.11121719\n",
      "Iteration 79, loss = 0.11246127\n",
      "Iteration 80, loss = 0.11082235\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5466  396]\n",
      " [ 599  308]]\n",
      "0.4375 0.339581036384 0.382371198014\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.217746047935 |  0.470782800441 | 0.297768479777 | 0.702467129561 |\n",
      "| RandomForestClassifier |     0.375      |  0.112458654906 | 0.173027989822 | 0.85596099867  |\n",
      "|   BaggingClassifier    | 0.375776397516 |  0.133406835722 | 0.19690805533  | 0.854188210962 |\n",
      "|  ExtraTreesClassifier  | 0.372434017595 |  0.140022050717 | 0.203525641026 | 0.853154084798 |\n",
      "| DecisionTreeClassifier | 0.298879202989 |  0.264608599779 | 0.280701754386 | 0.818289259861 |\n",
      "| CalibratedClassifierCV | 0.496124031008 | 0.0705622932745 | 0.123552123552 | 0.865859063377 |\n",
      "|     SGDClassifier      | 0.313008130081 |  0.169790518192 | 0.220157255182 | 0.83882405082  |\n",
      "|  KNeighborsClassifier  | 0.349099099099 |  0.341786108049 | 0.345403899721 | 0.826414536859 |\n",
      "|     MLPClassifier      |     0.4375     |  0.339581036384 | 0.382371198014 | 0.853006352489 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'csvReplaceBR12'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. next word2vec model taken where it was trained with phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsk/tensorflow/local/lib/python2.7/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4747 1115]\n",
      " [ 501  406]]\n",
      "0.266929651545 0.44762954796 0.334431630972\n",
      "Training  RandomForestClassifier\n",
      "[[5613  249]\n",
      " [ 757  150]]\n",
      "0.375939849624 0.165380374862 0.229709035222\n",
      "Training  BaggingClassifier\n",
      "[[5576  286]\n",
      " [ 724  183]]\n",
      "0.390191897655 0.201764057332 0.265988372093\n",
      "Training  ExtraTreesClassifier\n",
      "[[5568  294]\n",
      " [ 713  194]]\n",
      "0.397540983607 0.213891951488 0.278136200717\n",
      "Training  DecisionTreeClassifier\n",
      "[[5352  510]\n",
      " [ 649  258]]\n",
      "0.3359375 0.284454244763 0.308059701493\n",
      "Training  CalibratedClassifierCV\n",
      "[[5820   42]\n",
      " [ 855   52]]\n",
      "0.553191489362 0.0573318632856 0.103896103896\n",
      "Training  SGDClassifier\n",
      "[[5783   79]\n",
      " [ 863   44]]\n",
      "0.357723577236 0.0485115766262 0.0854368932039\n",
      "Training  KNeighborsClassifier\n",
      "[[5261  601]\n",
      " [ 593  314]]\n",
      "0.343169398907 0.346196251378 0.344676180022\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.40471328\n",
      "Iteration 2, loss = 0.35736895\n",
      "Iteration 3, loss = 0.34956691\n",
      "Iteration 4, loss = 0.34418098\n",
      "Iteration 5, loss = 0.33975744\n",
      "Iteration 6, loss = 0.33530166\n",
      "Iteration 7, loss = 0.33186860\n",
      "Iteration 8, loss = 0.32638353\n",
      "Iteration 9, loss = 0.32317198\n",
      "Iteration 10, loss = 0.31968950\n",
      "Iteration 11, loss = 0.31536737\n",
      "Iteration 12, loss = 0.31040629\n",
      "Iteration 13, loss = 0.30794842\n",
      "Iteration 14, loss = 0.30247226\n",
      "Iteration 15, loss = 0.30003546\n",
      "Iteration 16, loss = 0.29629894\n",
      "Iteration 17, loss = 0.29191026\n",
      "Iteration 18, loss = 0.28996443\n",
      "Iteration 19, loss = 0.28636092\n",
      "Iteration 20, loss = 0.28526439\n",
      "Iteration 21, loss = 0.28193229\n",
      "Iteration 22, loss = 0.28217874\n",
      "Iteration 23, loss = 0.27620865\n",
      "Iteration 24, loss = 0.27511935\n",
      "Iteration 25, loss = 0.27188661\n",
      "Iteration 26, loss = 0.27264158\n",
      "Iteration 27, loss = 0.26623578\n",
      "Iteration 28, loss = 0.26701148\n",
      "Iteration 29, loss = 0.26190873\n",
      "Iteration 30, loss = 0.26224790\n",
      "Iteration 31, loss = 0.25972448\n",
      "Iteration 32, loss = 0.25960611\n",
      "Iteration 33, loss = 0.25638040\n",
      "Iteration 34, loss = 0.25562794\n",
      "Iteration 35, loss = 0.25315549\n",
      "Iteration 36, loss = 0.25177300\n",
      "Iteration 37, loss = 0.25021430\n",
      "Iteration 38, loss = 0.24865702\n",
      "Iteration 39, loss = 0.24729296\n",
      "Iteration 40, loss = 0.24417973\n",
      "Iteration 41, loss = 0.24260480\n",
      "Iteration 42, loss = 0.24304363\n",
      "Iteration 43, loss = 0.24051852\n",
      "Iteration 44, loss = 0.24139471\n",
      "Iteration 45, loss = 0.23935586\n",
      "Iteration 46, loss = 0.24033248\n",
      "Iteration 47, loss = 0.23502599\n",
      "Iteration 48, loss = 0.23419633\n",
      "Iteration 49, loss = 0.23542846\n",
      "Iteration 50, loss = 0.23691309\n",
      "Iteration 51, loss = 0.23009003\n",
      "Iteration 52, loss = 0.22825146\n",
      "Iteration 53, loss = 0.22667636\n",
      "Iteration 54, loss = 0.22618949\n",
      "Iteration 55, loss = 0.22513275\n",
      "Iteration 56, loss = 0.22637101\n",
      "Iteration 57, loss = 0.22385955\n",
      "Iteration 58, loss = 0.22357115\n",
      "Iteration 59, loss = 0.22171472\n",
      "Iteration 60, loss = 0.22366391\n",
      "Iteration 61, loss = 0.22079957\n",
      "Iteration 62, loss = 0.21745256\n",
      "Iteration 63, loss = 0.21589606\n",
      "Iteration 64, loss = 0.21685853\n",
      "Iteration 65, loss = 0.21666878\n",
      "Iteration 66, loss = 0.22146973\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5593  269]\n",
      " [ 710  197]]\n",
      "0.422746781116 0.217199558986 0.286962855062\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.266929651545 |  0.44762954796  |  0.334431630972 | 0.761264588566 |\n",
      "| RandomForestClassifier | 0.375939849624 |  0.165380374862 |  0.229709035222 | 0.85138129709  |\n",
      "|   BaggingClassifier    | 0.390191897655 |  0.201764057332 |  0.265988372093 | 0.850790367853 |\n",
      "|  ExtraTreesClassifier  | 0.397540983607 |  0.213891951488 |  0.278136200717 | 0.851233564781 |\n",
      "| DecisionTreeClassifier |   0.3359375    |  0.284454244763 |  0.308059701493 | 0.828778253804 |\n",
      "| CalibratedClassifierCV | 0.553191489362 | 0.0573318632856 |  0.103896103896 | 0.867484118777 |\n",
      "|     SGDClassifier      | 0.357723577236 | 0.0485115766262 | 0.0854368932039 | 0.860836164869 |\n",
      "|  KNeighborsClassifier  | 0.343169398907 |  0.346196251378 |  0.344676180022 | 0.823607622987 |\n",
      "|     MLPClassifier      | 0.422746781116 |  0.217199558986 |  0.286962855062 | 0.855370069434 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_3_ReplaceBR_bigram'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainFSen], bigram_trans[testFSen])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Middle Sentences\n",
    "Until now we were taking into consideration the whole sentence. But on closer inspection most the connection related words appear near of BR1 and BR2, mostly in-between them and just before and just after. So this time we will be only considering words in between the entities taken into consideration and some words before and after the occurence of it say a window of size 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def breakSen(sentences):\n",
    "    middleSen = []\n",
    "    for sentence in sentences:\n",
    "        s = sentence.split()\n",
    "\n",
    "        ind1 = -1\n",
    "        ind2 = -1\n",
    "        for j in range(0,len(s)):\n",
    "            if s[j].__contains__('br'):\n",
    "                if ind1 == -1:\n",
    "                    ind1 = j\n",
    "                else:\n",
    "                    ind2 = j\n",
    "        for j in range(0,len(s)):\n",
    "            if s[j].__contains__('br'):\n",
    "                if j > ind2:\n",
    "                    ind2 = j\n",
    "\n",
    "        if ind1-3 < 0:\n",
    "            ind1 = 0\n",
    "        else: ind1 -= 3\n",
    "\n",
    "        if ind2+3 > len(s):\n",
    "            ind2 = len(s)\n",
    "        else: ind2 += 3\n",
    "\n",
    "        middleSen.append(' '.join(s[ind1:ind2]))\n",
    "    return middleSen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['divisions of the br1 br br and br2',\n",
       " 'the br therefore resembles other areas of primate br1 such as the br2 where a',\n",
       " 'almost all br including the br br br1 br br2 br and br displayed peak',\n",
       " 'suggest that the br1 input to the br may be directed toward specific subpopulation of br neurons and may influence not only cells in the br2 but also in the br',\n",
       " 'implants in the br1 many retrogradely labeled cells were observed mainly in the br the br br2 br and br']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMid = breakSen(trainFSen)\n",
    "testMid = breakSen(testFSen)\n",
    "trainMid[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[5135  727]\n",
      " [ 526  381]]\n",
      "0.343862815884 0.42006615215 0.378163771712\n",
      "Training  RandomForestClassifier\n",
      "[[5740  122]\n",
      " [ 656  251]]\n",
      "0.672922252011 0.276736493936 0.3921875\n",
      "Training  BaggingClassifier\n",
      "[[5626  236]\n",
      " [ 539  368]]\n",
      "0.609271523179 0.405733186329 0.487094639312\n",
      "Training  ExtraTreesClassifier\n",
      "[[5704  158]\n",
      " [ 606  301]]\n",
      "0.655773420479 0.331863285557 0.440702781845\n",
      "Training  DecisionTreeClassifier\n",
      "[[5495  367]\n",
      " [ 490  417]]\n",
      "0.531887755102 0.459757442117 0.493199290361\n",
      "Training  CalibratedClassifierCV\n",
      "[[5703  159]\n",
      " [ 553  354]]\n",
      "0.690058479532 0.390297684675 0.498591549296\n",
      "Training  SGDClassifier\n",
      "[[5805   57]\n",
      " [ 737  170]]\n",
      "0.748898678414 0.18743109151 0.299823633157\n",
      "Training  KNeighborsClassifier\n",
      "[[5369  493]\n",
      " [ 468  439]]\n",
      "0.471030042918 0.48401323043 0.477433387711\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.42751735\n",
      "Iteration 2, loss = 0.22667112\n",
      "Iteration 3, loss = 0.13298977\n",
      "Iteration 4, loss = 0.09406474\n",
      "Iteration 5, loss = 0.07573491\n",
      "Iteration 6, loss = 0.06553600\n",
      "Iteration 7, loss = 0.05725881\n",
      "Iteration 8, loss = 0.05346000\n",
      "Iteration 9, loss = 0.04959039\n",
      "Iteration 10, loss = 0.04686212\n",
      "Iteration 11, loss = 0.04495464\n",
      "Iteration 12, loss = 0.04247096\n",
      "Iteration 13, loss = 0.04129689\n",
      "Iteration 14, loss = 0.03979620\n",
      "Iteration 15, loss = 0.03888095\n",
      "Iteration 16, loss = 0.03759260\n",
      "Iteration 17, loss = 0.03663656\n",
      "Iteration 18, loss = 0.03598440\n",
      "Iteration 19, loss = 0.03558446\n",
      "Iteration 20, loss = 0.03486611\n",
      "Iteration 21, loss = 0.03484945\n",
      "Iteration 22, loss = 0.03417013\n",
      "Iteration 23, loss = 0.03383840\n",
      "Iteration 24, loss = 0.03298501\n",
      "Iteration 25, loss = 0.03253584\n",
      "Iteration 26, loss = 0.03343938\n",
      "Iteration 27, loss = 0.03256341\n",
      "Iteration 28, loss = 0.03162540\n",
      "Iteration 29, loss = 0.03154528\n",
      "Iteration 30, loss = 0.03164830\n",
      "Iteration 31, loss = 0.03141990\n",
      "Iteration 32, loss = 0.03170751\n",
      "Iteration 33, loss = 0.03124964\n",
      "Iteration 34, loss = 0.03100480\n",
      "Iteration 35, loss = 0.03102788\n",
      "Iteration 36, loss = 0.03062658\n",
      "Iteration 37, loss = 0.03039722\n",
      "Iteration 38, loss = 0.03021748\n",
      "Iteration 39, loss = 0.02999633\n",
      "Iteration 40, loss = 0.03025326\n",
      "Iteration 41, loss = 0.03006438\n",
      "Iteration 42, loss = 0.03008433\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5555  307]\n",
      " [ 472  435]]\n",
      "0.586253369272 0.4796030871 0.527592480291\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.343862815884 | 0.42006615215  | 0.378163771712 | 0.814891416753 |\n",
      "| RandomForestClassifier | 0.672922252011 | 0.276736493936 |   0.3921875    | 0.885064263554 |\n",
      "|   BaggingClassifier    | 0.609271523179 | 0.405733186329 | 0.487094639312 | 0.885507460482 |\n",
      "|  ExtraTreesClassifier  | 0.655773420479 | 0.331863285557 | 0.440702781845 | 0.887132515881 |\n",
      "| DecisionTreeClassifier | 0.531887755102 | 0.459757442117 | 0.493199290361 | 0.873393411139 |\n",
      "| CalibratedClassifierCV | 0.690058479532 | 0.390297684675 | 0.498591549296 | 0.894814595952 |\n",
      "|     SGDClassifier      | 0.748898678414 | 0.18743109151  | 0.299823633157 | 0.88270054661  |\n",
      "|  KNeighborsClassifier  | 0.471030042918 | 0.48401323043  | 0.477433387711 | 0.858029250997 |\n",
      "|     MLPClassifier      | 0.586253369272 |  0.4796030871  | 0.527592480291 | 0.884916531245 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4771 1091]\n",
      " [ 492  415]]\n",
      "0.275564409031 0.457552370452 0.343970161625\n",
      "Training  RandomForestClassifier\n",
      "[[5742  120]\n",
      " [ 780  127]]\n",
      "0.514170040486 0.140022050717 0.220103986135\n",
      "Training  BaggingClassifier\n",
      "[[5729  133]\n",
      " [ 766  141]]\n",
      "0.514598540146 0.15545755237 0.238780694327\n",
      "Training  ExtraTreesClassifier\n",
      "[[5705  157]\n",
      " [ 735  172]]\n",
      "0.522796352584 0.189636163175 0.278317152104\n",
      "Training  DecisionTreeClassifier\n",
      "[[5266  596]\n",
      " [ 631  276]]\n",
      "0.316513761468 0.304299889746 0.310286677909\n",
      "Training  CalibratedClassifierCV\n",
      "[[5771   91]\n",
      " [ 838   69]]\n",
      "0.43125 0.0760749724366 0.129334582943\n",
      "Training  SGDClassifier\n",
      "[[5546  316]\n",
      " [ 779  128]]\n",
      "0.288288288288 0.141124586549 0.189489267209\n",
      "Training  KNeighborsClassifier\n",
      "[[5395  467]\n",
      " [ 487  420]]\n",
      "0.473506200676 0.463065049614 0.468227424749\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37051210\n",
      "Iteration 2, loss = 0.32808467\n",
      "Iteration 3, loss = 0.31497449\n",
      "Iteration 4, loss = 0.30384293\n",
      "Iteration 5, loss = 0.29430789\n",
      "Iteration 6, loss = 0.28419541\n",
      "Iteration 7, loss = 0.27518324\n",
      "Iteration 8, loss = 0.26663970\n",
      "Iteration 9, loss = 0.25887821\n",
      "Iteration 10, loss = 0.25144821\n",
      "Iteration 11, loss = 0.24790595\n",
      "Iteration 12, loss = 0.23947053\n",
      "Iteration 13, loss = 0.23491065\n",
      "Iteration 14, loss = 0.22649023\n",
      "Iteration 15, loss = 0.22087857\n",
      "Iteration 16, loss = 0.21441179\n",
      "Iteration 17, loss = 0.20985574\n",
      "Iteration 18, loss = 0.20329011\n",
      "Iteration 19, loss = 0.20318754\n",
      "Iteration 20, loss = 0.19639462\n",
      "Iteration 21, loss = 0.18957909\n",
      "Iteration 22, loss = 0.18617887\n",
      "Iteration 23, loss = 0.18097272\n",
      "Iteration 24, loss = 0.17988358\n",
      "Iteration 25, loss = 0.17514352\n",
      "Iteration 26, loss = 0.17064830\n",
      "Iteration 27, loss = 0.16770314\n",
      "Iteration 28, loss = 0.16499846\n",
      "Iteration 29, loss = 0.16085958\n",
      "Iteration 30, loss = 0.15312861\n",
      "Iteration 31, loss = 0.15109132\n",
      "Iteration 32, loss = 0.14832728\n",
      "Iteration 33, loss = 0.14647281\n",
      "Iteration 34, loss = 0.14349160\n",
      "Iteration 35, loss = 0.13842564\n",
      "Iteration 36, loss = 0.13974470\n",
      "Iteration 37, loss = 0.13409994\n",
      "Iteration 38, loss = 0.13207404\n",
      "Iteration 39, loss = 0.13024156\n",
      "Iteration 40, loss = 0.12632070\n",
      "Iteration 41, loss = 0.12472946\n",
      "Iteration 42, loss = 0.12523772\n",
      "Iteration 43, loss = 0.11926465\n",
      "Iteration 44, loss = 0.11976977\n",
      "Iteration 45, loss = 0.11820016\n",
      "Iteration 46, loss = 0.11490285\n",
      "Iteration 47, loss = 0.11155347\n",
      "Iteration 48, loss = 0.11176287\n",
      "Iteration 49, loss = 0.11083968\n",
      "Iteration 50, loss = 0.11099094\n",
      "Iteration 51, loss = 0.10937964\n",
      "Iteration 52, loss = 0.10595081\n",
      "Iteration 53, loss = 0.10732123\n",
      "Iteration 54, loss = 0.10373988\n",
      "Iteration 55, loss = 0.10013668\n",
      "Iteration 56, loss = 0.10008273\n",
      "Iteration 57, loss = 0.09950824\n",
      "Iteration 58, loss = 0.09697079\n",
      "Iteration 59, loss = 0.09547349\n",
      "Iteration 60, loss = 0.09802595\n",
      "Iteration 61, loss = 0.09395325\n",
      "Iteration 62, loss = 0.09198731\n",
      "Iteration 63, loss = 0.09560752\n",
      "Iteration 64, loss = 0.09452926\n",
      "Iteration 65, loss = 0.09357147\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5419  443]\n",
      " [ 450  457]]\n",
      "0.507777777778 0.503858875413 0.505810736027\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.275564409031 |  0.457552370452 | 0.343970161625 | 0.766139754764 |\n",
      "| RandomForestClassifier | 0.514170040486 |  0.140022050717 | 0.220103986135 | 0.86704092185  |\n",
      "|   BaggingClassifier    | 0.514598540146 |  0.15545755237  | 0.238780694327 | 0.867188654159 |\n",
      "|  ExtraTreesClassifier  | 0.522796352584 |  0.189636163175 | 0.278317152104 | 0.868222780322 |\n",
      "| DecisionTreeClassifier | 0.316513761468 |  0.304299889746 | 0.310286677909 | 0.818732456788 |\n",
      "| CalibratedClassifierCV |    0.43125     | 0.0760749724366 | 0.129334582943 | 0.862756684887 |\n",
      "|     SGDClassifier      | 0.288288288288 |  0.141124586549 | 0.189489267209 | 0.838233121584 |\n",
      "|  KNeighborsClassifier  | 0.473506200676 |  0.463065049614 | 0.468227424749 | 0.859063377161 |\n",
      "|     MLPClassifier      | 0.507777777778 |  0.503858875413 | 0.505810736027 | 0.868075048013 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4939  923]\n",
      " [ 517  390]]\n",
      "0.29702970297 0.429988974642 0.351351351351\n",
      "Training  RandomForestClassifier\n",
      "[[5736  126]\n",
      " [ 745  162]]\n",
      "0.5625 0.178610804851 0.271129707113\n",
      "Training  BaggingClassifier\n",
      "[[5711  151]\n",
      " [ 713  194]]\n",
      "0.56231884058 0.213891951488 0.309904153355\n",
      "Training  ExtraTreesClassifier\n",
      "[[5701  161]\n",
      " [ 688  219]]\n",
      "0.576315789474 0.241455347299 0.340326340326\n",
      "Training  DecisionTreeClassifier\n",
      "[[5356  506]\n",
      " [ 607  300]]\n",
      "0.372208436725 0.330760749724 0.350262697023\n",
      "Training  CalibratedClassifierCV\n",
      "[[5761  101]\n",
      " [ 849   58]]\n",
      "0.364779874214 0.06394707828 0.108818011257\n",
      "Training  SGDClassifier\n",
      "[[5747  115]\n",
      " [ 845   62]]\n",
      "0.350282485876 0.0683572216097 0.114391143911\n",
      "Training  KNeighborsClassifier\n",
      "[[5412  450]\n",
      " [ 474  433]]\n",
      "0.490373725934 0.477398015436 0.483798882682\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.39236779\n",
      "Iteration 2, loss = 0.33815081\n",
      "Iteration 3, loss = 0.32479392\n",
      "Iteration 4, loss = 0.31462323\n",
      "Iteration 5, loss = 0.30695307\n",
      "Iteration 6, loss = 0.29974649\n",
      "Iteration 7, loss = 0.29166406\n",
      "Iteration 8, loss = 0.28400108\n",
      "Iteration 9, loss = 0.27850770\n",
      "Iteration 10, loss = 0.27334128\n",
      "Iteration 11, loss = 0.26649972\n",
      "Iteration 12, loss = 0.26057310\n",
      "Iteration 13, loss = 0.25728450\n",
      "Iteration 14, loss = 0.25024114\n",
      "Iteration 15, loss = 0.24580360\n",
      "Iteration 16, loss = 0.24208204\n",
      "Iteration 17, loss = 0.23542889\n",
      "Iteration 18, loss = 0.22993300\n",
      "Iteration 19, loss = 0.22757596\n",
      "Iteration 20, loss = 0.22367552\n",
      "Iteration 21, loss = 0.21964809\n",
      "Iteration 22, loss = 0.21589009\n",
      "Iteration 23, loss = 0.21262438\n",
      "Iteration 24, loss = 0.20654625\n",
      "Iteration 25, loss = 0.20569660\n",
      "Iteration 26, loss = 0.19966457\n",
      "Iteration 27, loss = 0.19807530\n",
      "Iteration 28, loss = 0.19318511\n",
      "Iteration 29, loss = 0.19234625\n",
      "Iteration 30, loss = 0.18809122\n",
      "Iteration 31, loss = 0.18437433\n",
      "Iteration 32, loss = 0.18055468\n",
      "Iteration 33, loss = 0.18100941\n",
      "Iteration 34, loss = 0.17592548\n",
      "Iteration 35, loss = 0.17395601\n",
      "Iteration 36, loss = 0.17244491\n",
      "Iteration 37, loss = 0.16714168\n",
      "Iteration 38, loss = 0.16560381\n",
      "Iteration 39, loss = 0.16444959\n",
      "Iteration 40, loss = 0.16337695\n",
      "Iteration 41, loss = 0.16122231\n",
      "Iteration 42, loss = 0.15731372\n",
      "Iteration 43, loss = 0.15636566\n",
      "Iteration 44, loss = 0.15305854\n",
      "Iteration 45, loss = 0.15192872\n",
      "Iteration 46, loss = 0.15111384\n",
      "Iteration 47, loss = 0.14857977\n",
      "Iteration 48, loss = 0.14602031\n",
      "Iteration 49, loss = 0.14424064\n",
      "Iteration 50, loss = 0.14319618\n",
      "Iteration 51, loss = 0.14071683\n",
      "Iteration 52, loss = 0.14438521\n",
      "Iteration 53, loss = 0.14052222\n",
      "Iteration 54, loss = 0.13762955\n",
      "Iteration 55, loss = 0.13467149\n",
      "Iteration 56, loss = 0.13361360\n",
      "Iteration 57, loss = 0.13213896\n",
      "Iteration 58, loss = 0.13239132\n",
      "Iteration 59, loss = 0.12989628\n",
      "Iteration 60, loss = 0.12917681\n",
      "Iteration 61, loss = 0.12815669\n",
      "Iteration 62, loss = 0.12520977\n",
      "Iteration 63, loss = 0.12369389\n",
      "Iteration 64, loss = 0.12559905\n",
      "Iteration 65, loss = 0.12364257\n",
      "Iteration 66, loss = 0.12338146\n",
      "Iteration 67, loss = 0.12103664\n",
      "Iteration 68, loss = 0.12041157\n",
      "Iteration 69, loss = 0.12042820\n",
      "Iteration 70, loss = 0.11996913\n",
      "Iteration 71, loss = 0.11828448\n",
      "Iteration 72, loss = 0.12055289\n",
      "Iteration 73, loss = 0.11948355\n",
      "Iteration 74, loss = 0.11409354\n",
      "Iteration 75, loss = 0.11386547\n",
      "Iteration 76, loss = 0.11201331\n",
      "Iteration 77, loss = 0.11365453\n",
      "Iteration 78, loss = 0.10967626\n",
      "Iteration 79, loss = 0.10967575\n",
      "Iteration 80, loss = 0.10770488\n",
      "Iteration 81, loss = 0.10936842\n",
      "Iteration 82, loss = 0.11227858\n",
      "Iteration 83, loss = 0.10662089\n",
      "Iteration 84, loss = 0.10663213\n",
      "Iteration 85, loss = 0.10535485\n",
      "Iteration 86, loss = 0.10933748\n",
      "Iteration 87, loss = 0.10561127\n",
      "Iteration 88, loss = 0.10735550\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5617  245]\n",
      " [ 574  333]]\n",
      "0.576124567474 0.367144432194 0.448484848485\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.29702970297  |  0.429988974642 | 0.351351351351 | 0.787265474959 |\n",
      "| RandomForestClassifier |     0.5625     |  0.178610804851 | 0.271129707113 | 0.871325158812 |\n",
      "|   BaggingClassifier    | 0.56231884058  |  0.213891951488 | 0.309904153355 | 0.872359284976 |\n",
      "|  ExtraTreesClassifier  | 0.576315789474 |  0.241455347299 | 0.340326340326 | 0.874575269611 |\n",
      "| DecisionTreeClassifier | 0.372208436725 |  0.330760749724 | 0.350262697023 | 0.835573940021 |\n",
      "| CalibratedClassifierCV | 0.364779874214 |  0.06394707828  | 0.108818011257 | 0.859654306397 |\n",
      "|     SGDClassifier      | 0.350282485876 | 0.0683572216097 | 0.114391143911 | 0.858176983306 |\n",
      "|  KNeighborsClassifier  | 0.490373725934 |  0.477398015436 | 0.483798882682 | 0.863495346432 |\n",
      "|     MLPClassifier      | 0.576124567474 |  0.367144432194 | 0.448484848485 | 0.879007238883 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4175 1687]\n",
      " [ 416  491]]\n",
      "0.225436179982 0.541345093716 0.318314424635\n",
      "Training  RandomForestClassifier\n",
      "[[5749  113]\n",
      " [ 799  108]]\n",
      "0.488687782805 0.119073869901 0.191489361702\n",
      "Training  BaggingClassifier\n",
      "[[5712  150]\n",
      " [ 788  119]]\n",
      "0.442379182156 0.131201764057 0.202380952381\n",
      "Training  ExtraTreesClassifier\n",
      "[[5702  160]\n",
      " [ 768  139]]\n",
      "0.464882943144 0.153252480706 0.230514096186\n",
      "Training  DecisionTreeClassifier\n",
      "[[5229  633]\n",
      " [ 605  302]]\n",
      "0.322994652406 0.332965821389 0.327904451683\n",
      "Training  CalibratedClassifierCV\n",
      "[[5769   93]\n",
      " [ 840   67]]\n",
      "0.41875 0.0738699007718 0.125585754452\n",
      "Training  SGDClassifier\n",
      "[[5487  375]\n",
      " [ 813   94]]\n",
      "0.200426439232 0.103638368247 0.136627906977\n",
      "Training  KNeighborsClassifier\n",
      "[[5373  489]\n",
      " [ 461  446]]\n",
      "0.477005347594 0.491730981257 0.484256243214\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.40640677\n",
      "Iteration 2, loss = 0.33248189\n",
      "Iteration 3, loss = 0.31839432\n",
      "Iteration 4, loss = 0.30695360\n",
      "Iteration 5, loss = 0.29685195\n",
      "Iteration 6, loss = 0.28678695\n",
      "Iteration 7, loss = 0.27449444\n",
      "Iteration 8, loss = 0.26489530\n",
      "Iteration 9, loss = 0.25379411\n",
      "Iteration 10, loss = 0.24421631\n",
      "Iteration 11, loss = 0.23482070\n",
      "Iteration 12, loss = 0.22711417\n",
      "Iteration 13, loss = 0.21726132\n",
      "Iteration 14, loss = 0.20859560\n",
      "Iteration 15, loss = 0.20300700\n",
      "Iteration 16, loss = 0.19410838\n",
      "Iteration 17, loss = 0.18897250\n",
      "Iteration 18, loss = 0.18306512\n",
      "Iteration 19, loss = 0.17483582\n",
      "Iteration 20, loss = 0.16719349\n",
      "Iteration 21, loss = 0.16293677\n",
      "Iteration 22, loss = 0.15984468\n",
      "Iteration 23, loss = 0.15363835\n",
      "Iteration 24, loss = 0.14844319\n",
      "Iteration 25, loss = 0.14404479\n",
      "Iteration 26, loss = 0.13637869\n",
      "Iteration 27, loss = 0.13396028\n",
      "Iteration 28, loss = 0.13358777\n",
      "Iteration 29, loss = 0.12885775\n",
      "Iteration 30, loss = 0.12661512\n",
      "Iteration 31, loss = 0.12209052\n",
      "Iteration 32, loss = 0.12035085\n",
      "Iteration 33, loss = 0.11877946\n",
      "Iteration 34, loss = 0.11513315\n",
      "Iteration 35, loss = 0.11163275\n",
      "Iteration 36, loss = 0.10980260\n",
      "Iteration 37, loss = 0.10445515\n",
      "Iteration 38, loss = 0.10585637\n",
      "Iteration 39, loss = 0.10192681\n",
      "Iteration 40, loss = 0.10018024\n",
      "Iteration 41, loss = 0.09917926\n",
      "Iteration 42, loss = 0.09716385\n",
      "Iteration 43, loss = 0.09652009\n",
      "Iteration 44, loss = 0.09480165\n",
      "Iteration 45, loss = 0.09273546\n",
      "Iteration 46, loss = 0.09320421\n",
      "Iteration 47, loss = 0.08688010\n",
      "Iteration 48, loss = 0.08879887\n",
      "Iteration 49, loss = 0.08837590\n",
      "Iteration 50, loss = 0.08998621\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5483  379]\n",
      " [ 485  422]]\n",
      "0.52684144819 0.465270121279 0.494145199063\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.225436179982 |  0.541345093716 | 0.318314424635 | 0.689318954055 |\n",
      "| RandomForestClassifier | 0.488687782805 |  0.119073869901 | 0.191489361702 | 0.865268134141 |\n",
      "|   BaggingClassifier    | 0.442379182156 |  0.131201764057 | 0.202380952381 | 0.861427094105 |\n",
      "|  ExtraTreesClassifier  | 0.464882943144 |  0.153252480706 | 0.230514096186 | 0.862904417196 |\n",
      "| DecisionTreeClassifier | 0.322994652406 |  0.332965821389 | 0.327904451683 | 0.817107401389 |\n",
      "| CalibratedClassifierCV |    0.41875     | 0.0738699007718 | 0.125585754452 | 0.862165755651 |\n",
      "|     SGDClassifier      | 0.200426439232 |  0.103638368247 | 0.136627906977 | 0.824494016841 |\n",
      "|  KNeighborsClassifier  | 0.477005347594 |  0.491730981257 | 0.484256243214 | 0.859654306397 |\n",
      "|     MLPClassifier      | 0.52684144819  |  0.465270121279 | 0.494145199063 | 0.872359284976 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'csvReplaceBR12'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. next word2vec model taken where it was trained with phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4807 1055]\n",
      " [ 489  418]]\n",
      "0.28377460964 0.460859977949 0.351260504202\n",
      "Training  RandomForestClassifier\n",
      "[[5727  135]\n",
      " [ 736  171]]\n",
      "0.558823529412 0.188533627343 0.281945589448\n",
      "Training  BaggingClassifier\n",
      "[[5686  176]\n",
      " [ 696  211]]\n",
      "0.545219638243 0.232635060639 0.326120556414\n",
      "Training  ExtraTreesClassifier\n",
      "[[5668  194]\n",
      " [ 688  219]]\n",
      "0.530266343826 0.241455347299 0.331818181818\n",
      "Training  DecisionTreeClassifier\n",
      "[[5308  554]\n",
      " [ 585  322]]\n",
      "0.367579908676 0.355016538037 0.361189007291\n",
      "Training  CalibratedClassifierCV\n",
      "[[5772   90]\n",
      " [ 845   62]]\n",
      "0.407894736842 0.0683572216097 0.117091595845\n",
      "Training  SGDClassifier\n",
      "[[5308  554]\n",
      " [ 675  232]]\n",
      "0.295165394402 0.25578831312 0.27406969876\n",
      "Training  KNeighborsClassifier\n",
      "[[5401  461]\n",
      " [ 475  432]]\n",
      "0.483762597984 0.476295479603 0.48\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37498792\n",
      "Iteration 2, loss = 0.34110363\n",
      "Iteration 3, loss = 0.33099838\n",
      "Iteration 4, loss = 0.32309451\n",
      "Iteration 5, loss = 0.31530084\n",
      "Iteration 6, loss = 0.30885596\n",
      "Iteration 7, loss = 0.30290868\n",
      "Iteration 8, loss = 0.29757347\n",
      "Iteration 9, loss = 0.29130502\n",
      "Iteration 10, loss = 0.28556566\n",
      "Iteration 11, loss = 0.27950528\n",
      "Iteration 12, loss = 0.27713343\n",
      "Iteration 13, loss = 0.27263296\n",
      "Iteration 14, loss = 0.26492784\n",
      "Iteration 15, loss = 0.26224473\n",
      "Iteration 16, loss = 0.25754436\n",
      "Iteration 17, loss = 0.25478801\n",
      "Iteration 18, loss = 0.24894767\n",
      "Iteration 19, loss = 0.24606979\n",
      "Iteration 20, loss = 0.24147659\n",
      "Iteration 21, loss = 0.23809173\n",
      "Iteration 22, loss = 0.23486890\n",
      "Iteration 23, loss = 0.23390293\n",
      "Iteration 24, loss = 0.22780517\n",
      "Iteration 25, loss = 0.22723270\n",
      "Iteration 26, loss = 0.22198652\n",
      "Iteration 27, loss = 0.21957226\n",
      "Iteration 28, loss = 0.21791670\n",
      "Iteration 29, loss = 0.21376835\n",
      "Iteration 30, loss = 0.21305756\n",
      "Iteration 31, loss = 0.20799543\n",
      "Iteration 32, loss = 0.20565266\n",
      "Iteration 33, loss = 0.20452413\n",
      "Iteration 34, loss = 0.20136104\n",
      "Iteration 35, loss = 0.19767915\n",
      "Iteration 36, loss = 0.19387955\n",
      "Iteration 37, loss = 0.19357991\n",
      "Iteration 38, loss = 0.19415640\n",
      "Iteration 39, loss = 0.18883909\n",
      "Iteration 40, loss = 0.18981047\n",
      "Iteration 41, loss = 0.18453599\n",
      "Iteration 42, loss = 0.18319956\n",
      "Iteration 43, loss = 0.18424774\n",
      "Iteration 44, loss = 0.18445844\n",
      "Iteration 45, loss = 0.17766555\n",
      "Iteration 46, loss = 0.17608622\n",
      "Iteration 47, loss = 0.17437615\n",
      "Iteration 48, loss = 0.17197980\n",
      "Iteration 49, loss = 0.17071545\n",
      "Iteration 50, loss = 0.17136842\n",
      "Iteration 51, loss = 0.16960077\n",
      "Iteration 52, loss = 0.16846110\n",
      "Iteration 53, loss = 0.16264433\n",
      "Iteration 54, loss = 0.16320745\n",
      "Iteration 55, loss = 0.16299571\n",
      "Iteration 56, loss = 0.15753518\n",
      "Iteration 57, loss = 0.15962978\n",
      "Iteration 58, loss = 0.15822323\n",
      "Iteration 59, loss = 0.15190592\n",
      "Iteration 60, loss = 0.15456933\n",
      "Iteration 61, loss = 0.15476004\n",
      "Iteration 62, loss = 0.15079240\n",
      "Iteration 63, loss = 0.14952250\n",
      "Iteration 64, loss = 0.15015072\n",
      "Iteration 65, loss = 0.14639035\n",
      "Iteration 66, loss = 0.14654374\n",
      "Iteration 67, loss = 0.14488275\n",
      "Iteration 68, loss = 0.14396283\n",
      "Iteration 69, loss = 0.14126764\n",
      "Iteration 70, loss = 0.14038818\n",
      "Iteration 71, loss = 0.14080282\n",
      "Iteration 72, loss = 0.13823258\n",
      "Iteration 73, loss = 0.13818146\n",
      "Iteration 74, loss = 0.13744257\n",
      "Iteration 75, loss = 0.14051518\n",
      "Iteration 76, loss = 0.13430230\n",
      "Iteration 77, loss = 0.13877600\n",
      "Iteration 78, loss = 0.13172436\n",
      "Iteration 79, loss = 0.13643156\n",
      "Iteration 80, loss = 0.13245276\n",
      "Iteration 81, loss = 0.13259545\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5546  316]\n",
      " [ 548  359]]\n",
      "0.531851851852 0.395810363837 0.453855878635\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.28377460964  |  0.460859977949 | 0.351260504202 | 0.771901314818 |\n",
      "| RandomForestClassifier | 0.558823529412 |  0.188533627343 | 0.281945589448 | 0.871325158812 |\n",
      "|   BaggingClassifier    | 0.545219638243 |  0.232635060639 | 0.326120556414 | 0.871177426503 |\n",
      "|  ExtraTreesClassifier  | 0.530266343826 |  0.241455347299 | 0.331818181818 | 0.869700103413 |\n",
      "| DecisionTreeClassifier | 0.367579908676 |  0.355016538037 | 0.361189007291 | 0.831732899985 |\n",
      "| CalibratedClassifierCV | 0.407894736842 | 0.0683572216097 | 0.117091595845 | 0.861870291033 |\n",
      "|     SGDClassifier      | 0.295165394402 |  0.25578831312  | 0.27406969876  | 0.81843699217  |\n",
      "|  KNeighborsClassifier  | 0.483762597984 |  0.476295479603 |      0.48      | 0.861722558724 |\n",
      "|     MLPClassifier      | 0.531851851852 |  0.395810363837 | 0.453855878635 | 0.872359284976 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_3_ReplaceBR_bigram'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainMid], bigram_trans[testMid])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "## BR1 BR2 tags re-tagging\n",
    "There appeared to be many replacement of BR1 or BR2 in a single sentence itself but the other BR tag didn't signify any relation. So using CharOffset BR1 and BR2 was tagged. (2)csv file used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fileName = \"WhiteText(2).csv\"\n",
    "data = pd.read_csv('data/'+fileName,delimiter=\"|\")\n",
    "\n",
    "trainSet, testSet = train_test_split(data, test_size=0.3, random_state=3)\n",
    "\n",
    "trainSet.to_csv('Train(2)',sep=\"|\")\n",
    "testSet.to_csv('Test(2)',sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15792\n",
      "6769\n"
     ]
    }
   ],
   "source": [
    "trainData = pd.read_csv('Train(2)',delimiter='|')\n",
    "trainSen = trainData['sentence']\n",
    "trainLab = trainData['connection']\n",
    "trainLen = len(trainSen)\n",
    "print trainLen\n",
    "\n",
    "testData = pd.read_csv('Test(2)',delimiter='|')\n",
    "testSen = testData['sentence']\n",
    "testLab = testData['connection']\n",
    "testLen = len(testSen)\n",
    "print testLen\n",
    "\n",
    "\n",
    "def formatSen(x):\n",
    "    x = re.sub(\"\\((.*?)\\)\",\" \",x.lower())\n",
    "    x = re.sub(\"^[ ]*([a-z])\",r\"\\1\",x)\n",
    "    return re.sub(\"[^a-z0-9]\",\" \",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFSen = []\n",
    "for i in range(0,trainLen):\n",
    "    trainFSen.append(formatSen(trainSen[i]))\n",
    "    \n",
    "testFSen = []\n",
    "for i in range(0,testLen):\n",
    "    testFSen.append(formatSen(testSen[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[5134  728]\n",
      " [ 609  298]]\n",
      "0.29044834308 0.32855567806 0.308329022245\n",
      "Training  RandomForestClassifier\n",
      "[[5704  158]\n",
      " [ 566  341]]\n",
      "0.683366733467 0.375964718853 0.48506401138\n",
      "Training  BaggingClassifier\n",
      "[[5568  294]\n",
      " [ 358  549]]\n",
      "0.651245551601 0.605292171996 0.627428571429\n",
      "Training  ExtraTreesClassifier\n",
      "[[5680  182]\n",
      " [ 537  370]]\n",
      "0.670289855072 0.407938257993 0.507196710075\n",
      "Training  DecisionTreeClassifier\n",
      "[[5452  410]\n",
      " [ 355  552]]\n",
      "0.573804573805 0.608599779493 0.590690208668\n",
      "Training  CalibratedClassifierCV\n",
      "[[5690  172]\n",
      " [ 433  474]]\n",
      "0.733746130031 0.522601984564 0.610431423052\n",
      "Training  SGDClassifier\n",
      "[[5805   57]\n",
      " [ 670  237]]\n",
      "0.80612244898 0.261300992282 0.39467110741\n",
      "Training  KNeighborsClassifier\n",
      "[[5432  430]\n",
      " [ 378  529]]\n",
      "0.551616266945 0.583241455347 0.566988210075\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.42037182\n",
      "Iteration 2, loss = 0.25157603\n",
      "Iteration 3, loss = 0.16215516\n",
      "Iteration 4, loss = 0.11806090\n",
      "Iteration 5, loss = 0.09596060\n",
      "Iteration 6, loss = 0.08031408\n",
      "Iteration 7, loss = 0.07030909\n",
      "Iteration 8, loss = 0.06425960\n",
      "Iteration 9, loss = 0.05796558\n",
      "Iteration 10, loss = 0.05433868\n",
      "Iteration 11, loss = 0.05030528\n",
      "Iteration 12, loss = 0.04771960\n",
      "Iteration 13, loss = 0.04410929\n",
      "Iteration 14, loss = 0.04195493\n",
      "Iteration 15, loss = 0.03901161\n",
      "Iteration 16, loss = 0.03744162\n",
      "Iteration 17, loss = 0.03544275\n",
      "Iteration 18, loss = 0.03419655\n",
      "Iteration 19, loss = 0.03135791\n",
      "Iteration 20, loss = 0.03120288\n",
      "Iteration 21, loss = 0.02936008\n",
      "Iteration 22, loss = 0.02841606\n",
      "Iteration 23, loss = 0.02740313\n",
      "Iteration 24, loss = 0.02580266\n",
      "Iteration 25, loss = 0.02591827\n",
      "Iteration 26, loss = 0.02645585\n",
      "Iteration 27, loss = 0.02334024\n",
      "Iteration 28, loss = 0.02203927\n",
      "Iteration 29, loss = 0.02384489\n",
      "Iteration 30, loss = 0.02225174\n",
      "Iteration 31, loss = 0.02077832\n",
      "Iteration 32, loss = 0.02256285\n",
      "Iteration 33, loss = 0.02065562\n",
      "Iteration 34, loss = 0.02218302\n",
      "Iteration 35, loss = 0.02059607\n",
      "Iteration 36, loss = 0.02105739\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5561  301]\n",
      " [ 307  600]]\n",
      "0.665926748058 0.661521499449 0.663716814159\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.29044834308  | 0.32855567806  | 0.308329022245 | 0.802481902792 |\n",
      "| RandomForestClassifier | 0.683366733467 | 0.375964718853 | 0.48506401138  | 0.893041808243 |\n",
      "|   BaggingClassifier    | 0.651245551601 | 0.605292171996 | 0.627428571429 | 0.903678534495 |\n",
      "|  ExtraTreesClassifier  | 0.670289855072 | 0.407938257993 | 0.507196710075 | 0.893780469789 |\n",
      "| DecisionTreeClassifier | 0.573804573805 | 0.608599779493 | 0.590690208668 | 0.886984783572 |\n",
      "| CalibratedClassifierCV | 0.733746130031 | 0.522601984564 | 0.610431423052 | 0.910621953021 |\n",
      "|     SGDClassifier      | 0.80612244898  | 0.261300992282 | 0.39467110741  | 0.892598611316 |\n",
      "|  KNeighborsClassifier  | 0.551616266945 | 0.583241455347 | 0.566988210075 | 0.880632294283 |\n",
      "|     MLPClassifier      | 0.665926748058 | 0.661521499449 | 0.663716814159 | 0.910178756094 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4387 1475]\n",
      " [ 454  453]]\n",
      "0.234958506224 0.499448732084 0.319576719577\n",
      "Training  RandomForestClassifier\n",
      "[[5623  239]\n",
      " [ 806  101]]\n",
      "0.297058823529 0.111356119074 0.161988773055\n",
      "Training  BaggingClassifier\n",
      "[[5639  223]\n",
      " [ 811   96]]\n",
      "0.300940438871 0.105843439912 0.15660685155\n",
      "Training  ExtraTreesClassifier\n",
      "[[5687  175]\n",
      " [ 832   75]]\n",
      "0.3 0.0826901874311 0.129645635264\n",
      "Training  DecisionTreeClassifier\n",
      "[[5620  242]\n",
      " [ 812   95]]\n",
      "0.281899109792 0.104740904079 0.152733118971\n",
      "Training  CalibratedClassifierCV\n",
      "[[5806   56]\n",
      " [ 863   44]]\n",
      "0.44 0.0485115766262 0.0873882820258\n",
      "Training  SGDClassifier\n",
      "[[4488 1374]\n",
      " [ 423  484]]\n",
      "0.260495156082 0.533627342889 0.350090415913\n",
      "Training  KNeighborsClassifier\n",
      "[[5206  656]\n",
      " [ 634  273]]\n",
      "0.293864370291 0.300992282249 0.297385620915\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.39915115\n",
      "Iteration 2, loss = 0.35121816\n",
      "Iteration 3, loss = 0.33976074\n",
      "Iteration 4, loss = 0.33113768\n",
      "Iteration 5, loss = 0.32305589\n",
      "Iteration 6, loss = 0.31599232\n",
      "Iteration 7, loss = 0.31079537\n",
      "Iteration 8, loss = 0.30695701\n",
      "Iteration 9, loss = 0.30117456\n",
      "Iteration 10, loss = 0.29911641\n",
      "Iteration 11, loss = 0.29455258\n",
      "Iteration 12, loss = 0.29216614\n",
      "Iteration 13, loss = 0.28801548\n",
      "Iteration 14, loss = 0.28583518\n",
      "Iteration 15, loss = 0.28261222\n",
      "Iteration 16, loss = 0.27931031\n",
      "Iteration 17, loss = 0.27783453\n",
      "Iteration 18, loss = 0.27519984\n",
      "Iteration 19, loss = 0.27247332\n",
      "Iteration 20, loss = 0.26953602\n",
      "Iteration 21, loss = 0.26866632\n",
      "Iteration 22, loss = 0.26616273\n",
      "Iteration 23, loss = 0.26477580\n",
      "Iteration 24, loss = 0.26332735\n",
      "Iteration 25, loss = 0.26110503\n",
      "Iteration 26, loss = 0.25875929\n",
      "Iteration 27, loss = 0.26023120\n",
      "Iteration 28, loss = 0.25706829\n",
      "Iteration 29, loss = 0.25749896\n",
      "Iteration 30, loss = 0.25542306\n",
      "Iteration 31, loss = 0.25267459\n",
      "Iteration 32, loss = 0.25378177\n",
      "Iteration 33, loss = 0.25140626\n",
      "Iteration 34, loss = 0.25172099\n",
      "Iteration 35, loss = 0.25150906\n",
      "Iteration 36, loss = 0.24852820\n",
      "Iteration 37, loss = 0.24727951\n",
      "Iteration 38, loss = 0.24683895\n",
      "Iteration 39, loss = 0.24667480\n",
      "Iteration 40, loss = 0.24405621\n",
      "Iteration 41, loss = 0.24538455\n",
      "Iteration 42, loss = 0.24378204\n",
      "Iteration 43, loss = 0.24283155\n",
      "Iteration 44, loss = 0.24247288\n",
      "Iteration 45, loss = 0.24207744\n",
      "Iteration 46, loss = 0.24555412\n",
      "Iteration 47, loss = 0.24019110\n",
      "Iteration 48, loss = 0.23959911\n",
      "Iteration 49, loss = 0.23947567\n",
      "Iteration 50, loss = 0.23824566\n",
      "Iteration 51, loss = 0.23938307\n",
      "Iteration 52, loss = 0.23700843\n",
      "Iteration 53, loss = 0.23660639\n",
      "Iteration 54, loss = 0.23659781\n",
      "Iteration 55, loss = 0.23648998\n",
      "Iteration 56, loss = 0.23623671\n",
      "Iteration 57, loss = 0.23654474\n",
      "Iteration 58, loss = 0.23547976\n",
      "Iteration 59, loss = 0.23515666\n",
      "Iteration 60, loss = 0.23684887\n",
      "Iteration 61, loss = 0.23603328\n",
      "Iteration 62, loss = 0.23505971\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5569  293]\n",
      " [ 769  138]]\n",
      "0.320185614849 0.152149944873 0.206278026906\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.234958506224 |  0.499448732084 |  0.319576719577 | 0.715024375831 |\n",
      "| RandomForestClassifier | 0.297058823529 |  0.111356119074 |  0.161988773055 | 0.845619737036 |\n",
      "|   BaggingClassifier    | 0.300940438871 |  0.105843439912 |  0.15660685155  | 0.847244792436 |\n",
      "|  ExtraTreesClassifier  |      0.3       | 0.0826901874311 |  0.129645635264 | 0.851233564781 |\n",
      "| DecisionTreeClassifier | 0.281899109792 |  0.104740904079 |  0.152733118971 | 0.844290146255 |\n",
      "| CalibratedClassifierCV |      0.44      | 0.0485115766262 | 0.0873882820258 | 0.864234007978 |\n",
      "|     SGDClassifier      | 0.260495156082 |  0.533627342889 |  0.350090415913 | 0.734525040626 |\n",
      "|  KNeighborsClassifier  | 0.293864370291 |  0.300992282249 |  0.297385620915 | 0.809425321318 |\n",
      "|     MLPClassifier      | 0.320185614849 |  0.152149944873 |  0.206278026906 | 0.843108287783 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4403 1459]\n",
      " [ 452  455]]\n",
      "0.237722048067 0.501653803749 0.322580645161\n",
      "Training  RandomForestClassifier\n",
      "[[5634  228]\n",
      " [ 803  104]]\n",
      "0.313253012048 0.114663726571 0.16787732042\n",
      "Training  BaggingClassifier\n",
      "[[5629  233]\n",
      " [ 793  114]]\n",
      "0.328530259366 0.125689084895 0.181818181818\n",
      "Training  ExtraTreesClassifier\n",
      "[[5682  180]\n",
      " [ 836   71]]\n",
      "0.282868525896 0.0782800441014 0.122625215889\n",
      "Training  DecisionTreeClassifier\n",
      "[[5645  217]\n",
      " [ 803  104]]\n",
      "0.323987538941 0.114663726571 0.169381107492\n",
      "Training  CalibratedClassifierCV\n",
      "[[5814   48]\n",
      " [ 861   46]]\n",
      "0.489361702128 0.0507166482911 0.0919080919081\n",
      "Training  SGDClassifier\n",
      "[[5167  695]\n",
      " [ 638  269]]\n",
      "0.279045643154 0.29658213892 0.287546766435\n",
      "Training  KNeighborsClassifier\n",
      "[[5259  603]\n",
      " [ 667  240]]\n",
      "0.284697508897 0.264608599779 0.274285714286\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.40861922\n",
      "Iteration 2, loss = 0.35540155\n",
      "Iteration 3, loss = 0.34405066\n",
      "Iteration 4, loss = 0.33609945\n",
      "Iteration 5, loss = 0.32950807\n",
      "Iteration 6, loss = 0.32420809\n",
      "Iteration 7, loss = 0.31954116\n",
      "Iteration 8, loss = 0.31452370\n",
      "Iteration 9, loss = 0.31037276\n",
      "Iteration 10, loss = 0.30748441\n",
      "Iteration 11, loss = 0.30254253\n",
      "Iteration 12, loss = 0.30100522\n",
      "Iteration 13, loss = 0.29726236\n",
      "Iteration 14, loss = 0.29363664\n",
      "Iteration 15, loss = 0.29276833\n",
      "Iteration 16, loss = 0.28933635\n",
      "Iteration 17, loss = 0.28589805\n",
      "Iteration 18, loss = 0.28448963\n",
      "Iteration 19, loss = 0.28121576\n",
      "Iteration 20, loss = 0.28005498\n",
      "Iteration 21, loss = 0.27863408\n",
      "Iteration 22, loss = 0.27559137\n",
      "Iteration 23, loss = 0.27363467\n",
      "Iteration 24, loss = 0.27202397\n",
      "Iteration 25, loss = 0.27012479\n",
      "Iteration 26, loss = 0.26999851\n",
      "Iteration 27, loss = 0.26808595\n",
      "Iteration 28, loss = 0.26665750\n",
      "Iteration 29, loss = 0.26321346\n",
      "Iteration 30, loss = 0.26404569\n",
      "Iteration 31, loss = 0.26167198\n",
      "Iteration 32, loss = 0.26178984\n",
      "Iteration 33, loss = 0.25972695\n",
      "Iteration 34, loss = 0.25887411\n",
      "Iteration 35, loss = 0.25963453\n",
      "Iteration 36, loss = 0.25833559\n",
      "Iteration 37, loss = 0.25537380\n",
      "Iteration 38, loss = 0.25600283\n",
      "Iteration 39, loss = 0.25467850\n",
      "Iteration 40, loss = 0.25354384\n",
      "Iteration 41, loss = 0.25073974\n",
      "Iteration 42, loss = 0.25127012\n",
      "Iteration 43, loss = 0.25187852\n",
      "Iteration 44, loss = 0.24988578\n",
      "Iteration 45, loss = 0.24778077\n",
      "Iteration 46, loss = 0.24897806\n",
      "Iteration 47, loss = 0.24791828\n",
      "Iteration 48, loss = 0.24688165\n",
      "Iteration 49, loss = 0.24654525\n",
      "Iteration 50, loss = 0.24526809\n",
      "Iteration 51, loss = 0.24464551\n",
      "Iteration 52, loss = 0.24443769\n",
      "Iteration 53, loss = 0.24314426\n",
      "Iteration 54, loss = 0.24546819\n",
      "Iteration 55, loss = 0.24358044\n",
      "Iteration 56, loss = 0.24233393\n",
      "Iteration 57, loss = 0.24174054\n",
      "Iteration 58, loss = 0.24309704\n",
      "Iteration 59, loss = 0.24007826\n",
      "Iteration 60, loss = 0.24063953\n",
      "Iteration 61, loss = 0.24088996\n",
      "Iteration 62, loss = 0.24099380\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5627  235]\n",
      " [ 751  156]]\n",
      "0.398976982097 0.171995589857 0.240369799692\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.237722048067 |  0.501653803749 |  0.322580645161 | 0.717683557394 |\n",
      "| RandomForestClassifier | 0.313253012048 |  0.114663726571 |  0.16787732042  | 0.847687989363 |\n",
      "|   BaggingClassifier    | 0.328530259366 |  0.125689084895 |  0.181818181818 | 0.848426650909 |\n",
      "|  ExtraTreesClassifier  | 0.282868525896 | 0.0782800441014 |  0.122625215889 | 0.849903973999 |\n",
      "| DecisionTreeClassifier | 0.323987538941 |  0.114663726571 |  0.169381107492 | 0.849313044763 |\n",
      "| CalibratedClassifierCV | 0.489361702128 | 0.0507166482911 | 0.0919080919081 | 0.865711331068 |\n",
      "|     SGDClassifier      | 0.279045643154 |  0.29658213892  |  0.287546766435 | 0.803072832028 |\n",
      "|  KNeighborsClassifier  | 0.284697508897 |  0.264608599779 |  0.274285714286 | 0.812379967499 |\n",
      "|     MLPClassifier      | 0.398976982097 |  0.171995589857 |  0.240369799692 | 0.854335943271 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4853 1009]\n",
      " [ 541  366]]\n",
      "0.266181818182 0.403528114664 0.320771253287\n",
      "Training  RandomForestClassifier\n",
      "[[5620  242]\n",
      " [ 812   95]]\n",
      "0.281899109792 0.104740904079 0.152733118971\n",
      "Training  BaggingClassifier\n",
      "[[5625  237]\n",
      " [ 804  103]]\n",
      "0.302941176471 0.113561190739 0.165196471532\n",
      "Training  ExtraTreesClassifier\n",
      "[[5689  173]\n",
      " [ 835   72]]\n",
      "0.29387755102 0.0793825799338 0.125\n",
      "Training  DecisionTreeClassifier\n",
      "[[5639  223]\n",
      " [ 803  104]]\n",
      "0.318042813456 0.114663726571 0.168557536467\n",
      "Training  CalibratedClassifierCV\n",
      "[[5815   47]\n",
      " [ 868   39]]\n",
      "0.453488372093 0.0429988974642 0.0785498489426\n",
      "Training  SGDClassifier\n",
      "[[5546  316]\n",
      " [ 733  174]]\n",
      "0.355102040816 0.19184123484 0.249105225483\n",
      "Training  KNeighborsClassifier\n",
      "[[5302  560]\n",
      " [ 632  275]]\n",
      "0.329341317365 0.303197353914 0.315729047072\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37046787\n",
      "Iteration 2, loss = 0.33599634\n",
      "Iteration 3, loss = 0.32424094\n",
      "Iteration 4, loss = 0.31612397\n",
      "Iteration 5, loss = 0.30927414\n",
      "Iteration 6, loss = 0.30328936\n",
      "Iteration 7, loss = 0.29816270\n",
      "Iteration 8, loss = 0.29493328\n",
      "Iteration 9, loss = 0.28939025\n",
      "Iteration 10, loss = 0.28487835\n",
      "Iteration 11, loss = 0.28082193\n",
      "Iteration 12, loss = 0.27837330\n",
      "Iteration 13, loss = 0.27592500\n",
      "Iteration 14, loss = 0.27045723\n",
      "Iteration 15, loss = 0.27114255\n",
      "Iteration 16, loss = 0.26738646\n",
      "Iteration 17, loss = 0.26245129\n",
      "Iteration 18, loss = 0.26115857\n",
      "Iteration 19, loss = 0.25985808\n",
      "Iteration 20, loss = 0.25645796\n",
      "Iteration 21, loss = 0.25547844\n",
      "Iteration 22, loss = 0.25542451\n",
      "Iteration 23, loss = 0.25338829\n",
      "Iteration 24, loss = 0.25050540\n",
      "Iteration 25, loss = 0.25138921\n",
      "Iteration 26, loss = 0.24796196\n",
      "Iteration 27, loss = 0.24787803\n",
      "Iteration 28, loss = 0.24573828\n",
      "Iteration 29, loss = 0.24487920\n",
      "Iteration 30, loss = 0.24465565\n",
      "Iteration 31, loss = 0.24211959\n",
      "Iteration 32, loss = 0.24268861\n",
      "Iteration 33, loss = 0.24043151\n",
      "Iteration 34, loss = 0.23988309\n",
      "Iteration 35, loss = 0.24031799\n",
      "Iteration 36, loss = 0.24081174\n",
      "Iteration 37, loss = 0.23963141\n",
      "Iteration 38, loss = 0.23993525\n",
      "Iteration 39, loss = 0.23807894\n",
      "Iteration 40, loss = 0.23703420\n",
      "Iteration 41, loss = 0.23635186\n",
      "Iteration 42, loss = 0.23589295\n",
      "Iteration 43, loss = 0.23506293\n",
      "Iteration 44, loss = 0.23490377\n",
      "Iteration 45, loss = 0.23507271\n",
      "Iteration 46, loss = 0.23357684\n",
      "Iteration 47, loss = 0.23297754\n",
      "Iteration 48, loss = 0.23274018\n",
      "Iteration 49, loss = 0.23206354\n",
      "Iteration 50, loss = 0.23131082\n",
      "Iteration 51, loss = 0.23146562\n",
      "Iteration 52, loss = 0.23144644\n",
      "Iteration 53, loss = 0.23244835\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5614  248]\n",
      " [ 777  130]]\n",
      "0.343915343915 0.143329658214 0.20233463035\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.266181818182 |  0.403528114664 |  0.320771253287 | 0.771014920963 |\n",
      "| RandomForestClassifier | 0.281899109792 |  0.104740904079 |  0.152733118971 | 0.844290146255 |\n",
      "|   BaggingClassifier    | 0.302941176471 |  0.113561190739 |  0.165196471532 | 0.846210666273 |\n",
      "|  ExtraTreesClassifier  | 0.29387755102  | 0.0793825799338 |      0.125      | 0.851085832472 |\n",
      "| DecisionTreeClassifier | 0.318042813456 |  0.114663726571 |  0.168557536467 | 0.848426650909 |\n",
      "| CalibratedClassifierCV | 0.453488372093 | 0.0429988974642 | 0.0785498489426 | 0.864824937214 |\n",
      "|     SGDClassifier      | 0.355102040816 |  0.19184123484  |  0.249105225483 |  0.8450288078  |\n",
      "|  KNeighborsClassifier  | 0.329341317365 |  0.303197353914 |  0.315729047072 | 0.823903087605 |\n",
      "|     MLPClassifier      | 0.343915343915 |  0.143329658214 |  0.20233463035  | 0.848574383218 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'csv_2_ReplaceBR12'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4707 1155]\n",
      " [ 542  365]]\n",
      "0.240131578947 0.402425578831 0.300782859497\n",
      "Training  RandomForestClassifier\n",
      "[[5629  233]\n",
      " [ 815   92]]\n",
      "0.283076923077 0.101433296582 0.149350649351\n",
      "Training  BaggingClassifier\n",
      "[[5631  231]\n",
      " [ 787  120]]\n",
      "0.34188034188 0.13230429989 0.190779014308\n",
      "Training  ExtraTreesClassifier\n",
      "[[5685  177]\n",
      " [ 839   68]]\n",
      "0.277551020408 0.0749724366042 0.118055555556\n",
      "Training  DecisionTreeClassifier\n",
      "[[5623  239]\n",
      " [ 814   93]]\n",
      "0.280120481928 0.102535832415 0.150121065375\n",
      "Training  CalibratedClassifierCV\n",
      "[[5816   46]\n",
      " [ 865   42]]\n",
      "0.477272727273 0.0463065049614 0.0844221105528\n",
      "Training  SGDClassifier\n",
      "[[5619  243]\n",
      " [ 798  109]]\n",
      "0.309659090909 0.120176405733 0.173153296267\n",
      "Training  KNeighborsClassifier\n",
      "[[5367  495]\n",
      " [ 660  247]]\n",
      "0.332884097035 0.272326350606 0.299575500303\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37736587\n",
      "Iteration 2, loss = 0.34384498\n",
      "Iteration 3, loss = 0.33059085\n",
      "Iteration 4, loss = 0.32021666\n",
      "Iteration 5, loss = 0.31261415\n",
      "Iteration 6, loss = 0.30610277\n",
      "Iteration 7, loss = 0.29929365\n",
      "Iteration 8, loss = 0.29422753\n",
      "Iteration 9, loss = 0.29090919\n",
      "Iteration 10, loss = 0.28863773\n",
      "Iteration 11, loss = 0.28453432\n",
      "Iteration 12, loss = 0.28063896\n",
      "Iteration 13, loss = 0.27765188\n",
      "Iteration 14, loss = 0.27470428\n",
      "Iteration 15, loss = 0.27279216\n",
      "Iteration 16, loss = 0.27184172\n",
      "Iteration 17, loss = 0.26640939\n",
      "Iteration 18, loss = 0.26566861\n",
      "Iteration 19, loss = 0.26367862\n",
      "Iteration 20, loss = 0.26326726\n",
      "Iteration 21, loss = 0.26046587\n",
      "Iteration 22, loss = 0.25715462\n",
      "Iteration 23, loss = 0.25811549\n",
      "Iteration 24, loss = 0.25638843\n",
      "Iteration 25, loss = 0.25647320\n",
      "Iteration 26, loss = 0.25412962\n",
      "Iteration 27, loss = 0.25142696\n",
      "Iteration 28, loss = 0.25094382\n",
      "Iteration 29, loss = 0.24916287\n",
      "Iteration 30, loss = 0.24827646\n",
      "Iteration 31, loss = 0.24823673\n",
      "Iteration 32, loss = 0.24584198\n",
      "Iteration 33, loss = 0.24442844\n",
      "Iteration 34, loss = 0.24567337\n",
      "Iteration 35, loss = 0.24345958\n",
      "Iteration 36, loss = 0.24310877\n",
      "Iteration 37, loss = 0.24188707\n",
      "Iteration 38, loss = 0.24196397\n",
      "Iteration 39, loss = 0.24074545\n",
      "Iteration 40, loss = 0.24030217\n",
      "Iteration 41, loss = 0.23879580\n",
      "Iteration 42, loss = 0.23971782\n",
      "Iteration 43, loss = 0.23876250\n",
      "Iteration 44, loss = 0.23776864\n",
      "Iteration 45, loss = 0.23674404\n",
      "Iteration 46, loss = 0.23960434\n",
      "Iteration 47, loss = 0.23886927\n",
      "Iteration 48, loss = 0.23749945\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5647  215]\n",
      " [ 789  118]]\n",
      "0.354354354354 0.130099228225 0.190322580645\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.240131578947 |  0.402425578831 |  0.300782859497 | 0.749298271532 |\n",
      "| RandomForestClassifier | 0.283076923077 |  0.101433296582 |  0.149350649351 | 0.845176540109 |\n",
      "|   BaggingClassifier    | 0.34188034188  |  0.13230429989  |  0.190779014308 | 0.849608509381 |\n",
      "|  ExtraTreesClassifier  | 0.277551020408 | 0.0749724366042 |  0.118055555556 | 0.849903973999 |\n",
      "| DecisionTreeClassifier | 0.280120481928 |  0.102535832415 |  0.150121065375 | 0.844437878564 |\n",
      "| CalibratedClassifierCV | 0.477272727273 | 0.0463065049614 | 0.0844221105528 | 0.86541586645  |\n",
      "|     SGDClassifier      | 0.309659090909 |  0.120176405733 |  0.173153296267 | 0.846210666273 |\n",
      "|  KNeighborsClassifier  | 0.332884097035 |  0.272326350606 |  0.299575500303 | 0.82936918304  |\n",
      "|     MLPClassifier      | 0.354354354354 |  0.130099228225 |  0.190322580645 | 0.851676761708 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_2_ReplaceBR12_bigram'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainFSen], bigram_trans[testFSen])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle Sentences taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def breakSen(sentences):\n",
    "    middleSen = []\n",
    "    for sentence in sentences:\n",
    "        s = word_tokenize(sentence)\n",
    "\n",
    "        ind1 = -1\n",
    "        ind2 = -1\n",
    "        for j in range(0,len(s)):\n",
    "            if s[j].__contains__('br1'):\n",
    "                if ind1 == -1:\n",
    "                    ind1 = j\n",
    "                else:\n",
    "                    ind2 = j\n",
    "        for j in range(0,len(s)):\n",
    "            if s[j].__contains__('br2'):\n",
    "                if j > ind2:\n",
    "                    ind2 = j\n",
    "\n",
    "        if ind1-3 < 0:\n",
    "            ind1 = 0\n",
    "        else: ind1 -= 3\n",
    "\n",
    "        if ind2+3 > len(s):\n",
    "            ind2 = len(s)\n",
    "        else: ind2 += 3\n",
    "\n",
    "        middleSen.append(' '.join(s[ind1:ind2]))\n",
    "    return middleSen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['divisions of the br1 br br and br2',\n",
       " 'areas of primate br1 such as the br2 where a',\n",
       " 'the br br br1 br br2 br and',\n",
       " 'suggest that the br1 input to the br may be directed toward specific subpopulation of br neurons and may influence not only cells in the br2 but also',\n",
       " 'implants in the br1 many retrogradely labeled cells were observed mainly in the br the br br2 br and']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMid = breakSen(trainFSen)\n",
    "testMid = breakSen(testFSen)\n",
    "trainMid[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15792"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainFSen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[5421  441]\n",
      " [ 614  293]]\n",
      "0.399182561308 0.323042998897 0.357099329677\n",
      "Training  RandomForestClassifier\n",
      "[[5779   83]\n",
      " [ 441  466]]\n",
      "0.848816029144 0.513781697905 0.64010989011\n",
      "Training  BaggingClassifier\n",
      "[[5686  176]\n",
      " [ 337  570]]\n",
      "0.764075067024 0.628445424476 0.689655172414\n",
      "Training  ExtraTreesClassifier\n",
      "[[5755  107]\n",
      " [ 411  496]]\n",
      "0.822553897181 0.546857772878 0.656953642384\n",
      "Training  DecisionTreeClassifier\n",
      "[[5538  324]\n",
      " [ 344  563]]\n",
      "0.63472378805 0.620727673649 0.627647714604\n",
      "Training  CalibratedClassifierCV\n",
      "[[5686  176]\n",
      " [ 284  623]]\n",
      "0.77972465582 0.686879823594 0.730363423212\n",
      "Training  SGDClassifier\n",
      "[[5782   80]\n",
      " [ 464  443]]\n",
      "0.847036328872 0.48842337376 0.61958041958\n",
      "Training  KNeighborsClassifier\n",
      "[[5655  207]\n",
      " [ 371  536]]\n",
      "0.721399730821 0.590959206174 0.649696969697\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.40705318\n",
      "Iteration 2, loss = 0.18446840\n",
      "Iteration 3, loss = 0.08510522\n",
      "Iteration 4, loss = 0.05434422\n",
      "Iteration 5, loss = 0.04010676\n",
      "Iteration 6, loss = 0.03435761\n",
      "Iteration 7, loss = 0.02922398\n",
      "Iteration 8, loss = 0.02770674\n",
      "Iteration 9, loss = 0.02647827\n",
      "Iteration 10, loss = 0.02478837\n",
      "Iteration 11, loss = 0.02419503\n",
      "Iteration 12, loss = 0.02331797\n",
      "Iteration 13, loss = 0.02305068\n",
      "Iteration 14, loss = 0.02323011\n",
      "Iteration 15, loss = 0.02252323\n",
      "Iteration 16, loss = 0.02223556\n",
      "Iteration 17, loss = 0.02199441\n",
      "Iteration 18, loss = 0.02133877\n",
      "Iteration 19, loss = 0.02118737\n",
      "Iteration 20, loss = 0.02182621\n",
      "Iteration 21, loss = 0.02128607\n",
      "Iteration 22, loss = 0.02158703\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5642  220]\n",
      " [ 256  651]]\n",
      "0.747416762342 0.717750826902 0.732283464567\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.399182561308 | 0.323042998897 | 0.357099329677 | 0.844142413946 |\n",
      "| RandomForestClassifier | 0.848816029144 | 0.513781697905 | 0.64010989011  | 0.922588270055 |\n",
      "|   BaggingClassifier    | 0.764075067024 | 0.628445424476 | 0.689655172414 | 0.924213325454 |\n",
      "|  ExtraTreesClassifier  | 0.822553897181 | 0.546857772878 | 0.656953642384 | 0.923474663909 |\n",
      "| DecisionTreeClassifier | 0.63472378805  | 0.620727673649 | 0.627647714604 | 0.901314817551 |\n",
      "| CalibratedClassifierCV | 0.77972465582  | 0.686879823594 | 0.730363423212 | 0.932043137834 |\n",
      "|     SGDClassifier      | 0.847036328872 | 0.48842337376  | 0.61958041958  | 0.919633623874 |\n",
      "|  KNeighborsClassifier  | 0.721399730821 | 0.590959206174 | 0.649696969697 | 0.914610725366 |\n",
      "|     MLPClassifier      | 0.747416762342 | 0.717750826902 | 0.732283464567 | 0.929679420889 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4768 1094]\n",
      " [ 440  467]]\n",
      "0.299167200512 0.514884233738 0.378444084279\n",
      "Training  RandomForestClassifier\n",
      "[[5785   77]\n",
      " [ 597  310]]\n",
      "0.801033591731 0.341786108049 0.47913446677\n",
      "Training  BaggingClassifier\n",
      "[[5743  119]\n",
      " [ 565  342]]\n",
      "0.741865509761 0.377067254686 0.5\n",
      "Training  ExtraTreesClassifier\n",
      "[[5743  119]\n",
      " [ 552  355]]\n",
      "0.748945147679 0.391400220507 0.514120202752\n",
      "Training  DecisionTreeClassifier\n",
      "[[5413  449]\n",
      " [ 413  494]]\n",
      "0.523860021209 0.544652701213 0.534054054054\n",
      "Training  CalibratedClassifierCV\n",
      "[[5764   98]\n",
      " [ 827   80]]\n",
      "0.449438202247 0.0882028665932 0.147465437788\n",
      "Training  SGDClassifier\n",
      "[[5670  192]\n",
      " [ 824   83]]\n",
      "0.301818181818 0.0915104740904 0.140439932318\n",
      "Training  KNeighborsClassifier\n",
      "[[5551  311]\n",
      " [ 353  554]]\n",
      "0.640462427746 0.610804851158 0.625282167043\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.39189568\n",
      "Iteration 2, loss = 0.32727486\n",
      "Iteration 3, loss = 0.30870581\n",
      "Iteration 4, loss = 0.29435820\n",
      "Iteration 5, loss = 0.28253965\n",
      "Iteration 6, loss = 0.27247549\n",
      "Iteration 7, loss = 0.26310105\n",
      "Iteration 8, loss = 0.25416246\n",
      "Iteration 9, loss = 0.24634689\n",
      "Iteration 10, loss = 0.23852073\n",
      "Iteration 11, loss = 0.23548159\n",
      "Iteration 12, loss = 0.22471648\n",
      "Iteration 13, loss = 0.21689031\n",
      "Iteration 14, loss = 0.21307980\n",
      "Iteration 15, loss = 0.20608974\n",
      "Iteration 16, loss = 0.19866085\n",
      "Iteration 17, loss = 0.19172327\n",
      "Iteration 18, loss = 0.18812343\n",
      "Iteration 19, loss = 0.18270182\n",
      "Iteration 20, loss = 0.17540279\n",
      "Iteration 21, loss = 0.17268854\n",
      "Iteration 22, loss = 0.16687618\n",
      "Iteration 23, loss = 0.16236531\n",
      "Iteration 24, loss = 0.15823922\n",
      "Iteration 25, loss = 0.15672247\n",
      "Iteration 26, loss = 0.15021101\n",
      "Iteration 27, loss = 0.14692027\n",
      "Iteration 28, loss = 0.14172142\n",
      "Iteration 29, loss = 0.13871164\n",
      "Iteration 30, loss = 0.13764093\n",
      "Iteration 31, loss = 0.13209025\n",
      "Iteration 32, loss = 0.13045500\n",
      "Iteration 33, loss = 0.12707427\n",
      "Iteration 34, loss = 0.12238279\n",
      "Iteration 35, loss = 0.12397758\n",
      "Iteration 36, loss = 0.11972821\n",
      "Iteration 37, loss = 0.11448422\n",
      "Iteration 38, loss = 0.11204250\n",
      "Iteration 39, loss = 0.11415199\n",
      "Iteration 40, loss = 0.11122574\n",
      "Iteration 41, loss = 0.10768412\n",
      "Iteration 42, loss = 0.10495406\n",
      "Iteration 43, loss = 0.10061510\n",
      "Iteration 44, loss = 0.10498745\n",
      "Iteration 45, loss = 0.10083818\n",
      "Iteration 46, loss = 0.09773871\n",
      "Iteration 47, loss = 0.09731327\n",
      "Iteration 48, loss = 0.09490027\n",
      "Iteration 49, loss = 0.09308700\n",
      "Iteration 50, loss = 0.09345144\n",
      "Iteration 51, loss = 0.09074583\n",
      "Iteration 52, loss = 0.09136051\n",
      "Iteration 53, loss = 0.09358591\n",
      "Iteration 54, loss = 0.08892187\n",
      "Iteration 55, loss = 0.08826442\n",
      "Iteration 56, loss = 0.08300650\n",
      "Iteration 57, loss = 0.08649750\n",
      "Iteration 58, loss = 0.08669317\n",
      "Iteration 59, loss = 0.08794328\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5571  291]\n",
      " [ 383  524]]\n",
      "0.642944785276 0.577728776185 0.608594657375\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.299167200512 |  0.514884233738 | 0.378444084279 | 0.773378637908 |\n",
      "| RandomForestClassifier | 0.801033591731 |  0.341786108049 | 0.47913446677  | 0.900428423696 |\n",
      "|   BaggingClassifier    | 0.741865509761 |  0.377067254686 |      0.5       | 0.898951100606 |\n",
      "|  ExtraTreesClassifier  | 0.748945147679 |  0.391400220507 | 0.514120202752 | 0.900871620623 |\n",
      "| DecisionTreeClassifier | 0.523860021209 |  0.544652701213 | 0.534054054054 | 0.872654749594 |\n",
      "| CalibratedClassifierCV | 0.449438202247 | 0.0882028665932 | 0.147465437788 | 0.863347614123 |\n",
      "|     SGDClassifier      | 0.301818181818 | 0.0915104740904 | 0.140439932318 | 0.849903973999 |\n",
      "|  KNeighborsClassifier  | 0.640462427746 |  0.610804851158 | 0.625282167043 | 0.901905746787 |\n",
      "|     MLPClassifier      | 0.642944785276 |  0.577728776185 | 0.608594657375 | 0.900428423696 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4951  911]\n",
      " [ 495  412]]\n",
      "0.311413454271 0.454244762955 0.369506726457\n",
      "Training  RandomForestClassifier\n",
      "[[5769   93]\n",
      " [ 560  347]]\n",
      "0.788636363636 0.382579933848 0.515219005197\n",
      "Training  BaggingClassifier\n",
      "[[5747  115]\n",
      " [ 530  377]]\n",
      "0.766260162602 0.41565600882 0.538956397427\n",
      "Training  ExtraTreesClassifier\n",
      "[[5755  107]\n",
      " [ 540  367]]\n",
      "0.774261603376 0.404630650496 0.531498913831\n",
      "Training  DecisionTreeClassifier\n",
      "[[5408  454]\n",
      " [ 467  440]]\n",
      "0.492170022371 0.485115766262 0.488617434758\n",
      "Training  CalibratedClassifierCV\n",
      "[[5784   78]\n",
      " [ 829   78]]\n",
      "0.5 0.0859977949283 0.146754468485\n",
      "Training  SGDClassifier\n",
      "[[5694  168]\n",
      " [ 840   67]]\n",
      "0.285106382979 0.0738699007718 0.117338003503\n",
      "Training  KNeighborsClassifier\n",
      "[[5545  317]\n",
      " [ 346  561]]\n",
      "0.638952164009 0.618522601985 0.628571428571\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.40962077\n",
      "Iteration 2, loss = 0.33494788\n",
      "Iteration 3, loss = 0.31454425\n",
      "Iteration 4, loss = 0.30239191\n",
      "Iteration 5, loss = 0.29334192\n",
      "Iteration 6, loss = 0.28560044\n",
      "Iteration 7, loss = 0.27717435\n",
      "Iteration 8, loss = 0.27121032\n",
      "Iteration 9, loss = 0.26712600\n",
      "Iteration 10, loss = 0.25923471\n",
      "Iteration 11, loss = 0.25443790\n",
      "Iteration 12, loss = 0.25044664\n",
      "Iteration 13, loss = 0.24254322\n",
      "Iteration 14, loss = 0.23672256\n",
      "Iteration 15, loss = 0.23283394\n",
      "Iteration 16, loss = 0.23000781\n",
      "Iteration 17, loss = 0.22540759\n",
      "Iteration 18, loss = 0.22214764\n",
      "Iteration 19, loss = 0.21463357\n",
      "Iteration 20, loss = 0.20973517\n",
      "Iteration 21, loss = 0.20749532\n",
      "Iteration 22, loss = 0.20163329\n",
      "Iteration 23, loss = 0.19688436\n",
      "Iteration 24, loss = 0.19276240\n",
      "Iteration 25, loss = 0.19051522\n",
      "Iteration 26, loss = 0.18603249\n",
      "Iteration 27, loss = 0.18190386\n",
      "Iteration 28, loss = 0.17887891\n",
      "Iteration 29, loss = 0.17503024\n",
      "Iteration 30, loss = 0.17108640\n",
      "Iteration 31, loss = 0.16628073\n",
      "Iteration 32, loss = 0.16553382\n",
      "Iteration 33, loss = 0.16061608\n",
      "Iteration 34, loss = 0.15854851\n",
      "Iteration 35, loss = 0.15637647\n",
      "Iteration 36, loss = 0.15313574\n",
      "Iteration 37, loss = 0.14819619\n",
      "Iteration 38, loss = 0.14600226\n",
      "Iteration 39, loss = 0.14335162\n",
      "Iteration 40, loss = 0.14335711\n",
      "Iteration 41, loss = 0.13948488\n",
      "Iteration 42, loss = 0.13527069\n",
      "Iteration 43, loss = 0.13539178\n",
      "Iteration 44, loss = 0.13273101\n",
      "Iteration 45, loss = 0.13020380\n",
      "Iteration 46, loss = 0.13131115\n",
      "Iteration 47, loss = 0.12574455\n",
      "Iteration 48, loss = 0.12374363\n",
      "Iteration 49, loss = 0.12366237\n",
      "Iteration 50, loss = 0.11954385\n",
      "Iteration 51, loss = 0.11814455\n",
      "Iteration 52, loss = 0.11839654\n",
      "Iteration 53, loss = 0.11461081\n",
      "Iteration 54, loss = 0.11147636\n",
      "Iteration 55, loss = 0.11374471\n",
      "Iteration 56, loss = 0.11065364\n",
      "Iteration 57, loss = 0.10808159\n",
      "Iteration 58, loss = 0.10779932\n",
      "Iteration 59, loss = 0.10555044\n",
      "Iteration 60, loss = 0.10469602\n",
      "Iteration 61, loss = 0.10246278\n",
      "Iteration 62, loss = 0.09949775\n",
      "Iteration 63, loss = 0.10195804\n",
      "Iteration 64, loss = 0.10114769\n",
      "Iteration 65, loss = 0.09834185\n",
      "Iteration 66, loss = 0.10100362\n",
      "Iteration 67, loss = 0.09600346\n",
      "Iteration 68, loss = 0.09342275\n",
      "Iteration 69, loss = 0.09446111\n",
      "Iteration 70, loss = 0.09172612\n",
      "Iteration 71, loss = 0.09271450\n",
      "Iteration 72, loss = 0.09220857\n",
      "Iteration 73, loss = 0.09039078\n",
      "Iteration 74, loss = 0.08947952\n",
      "Iteration 75, loss = 0.09519434\n",
      "Iteration 76, loss = 0.09160065\n",
      "Iteration 77, loss = 0.08794158\n",
      "Iteration 78, loss = 0.08784911\n",
      "Iteration 79, loss = 0.08584501\n",
      "Iteration 80, loss = 0.08537653\n",
      "Iteration 81, loss = 0.08619537\n",
      "Iteration 82, loss = 0.08154072\n",
      "Iteration 83, loss = 0.08394187\n",
      "Iteration 84, loss = 0.08475792\n",
      "Iteration 85, loss = 0.08329388\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5634  228]\n",
      " [ 479  428]]\n",
      "0.65243902439 0.471885336273 0.547664747281\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.311413454271 |  0.454244762955 | 0.369506726457 | 0.792288373467 |\n",
      "| RandomForestClassifier | 0.788636363636 |  0.382579933848 | 0.515219005197 | 0.903530802186 |\n",
      "|   BaggingClassifier    | 0.766260162602 |  0.41565600882  | 0.538956397427 | 0.904712660659 |\n",
      "|  ExtraTreesClassifier  | 0.774261603376 |  0.404630650496 | 0.531498913831 | 0.904417196041 |\n",
      "| DecisionTreeClassifier | 0.492170022371 |  0.485115766262 | 0.488617434758 | 0.863938543359 |\n",
      "| CalibratedClassifierCV |      0.5       | 0.0859977949283 | 0.146754468485 | 0.866006795686 |\n",
      "|     SGDClassifier      | 0.285106382979 | 0.0738699007718 | 0.117338003503 | 0.851085832472 |\n",
      "|  KNeighborsClassifier  | 0.638952164009 |  0.618522601985 | 0.628571428571 | 0.902053479096 |\n",
      "|     MLPClassifier      | 0.65243902439  |  0.471885336273 | 0.547664747281 | 0.895553257497 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4921  941]\n",
      " [ 474  433]]\n",
      "0.315138282387 0.477398015436 0.379658044717\n",
      "Training  RandomForestClassifier\n",
      "[[5775   87]\n",
      " [ 568  339]]\n",
      "0.795774647887 0.373759647189 0.508627156789\n",
      "Training  BaggingClassifier\n",
      "[[5759  103]\n",
      " [ 532  375]]\n",
      "0.784518828452 0.413450937155 0.541516245487\n",
      "Training  ExtraTreesClassifier\n",
      "[[5752  110]\n",
      " [ 554  353]]\n",
      "0.762419006479 0.389195148842 0.515328467153\n",
      "Training  DecisionTreeClassifier\n",
      "[[5369  493]\n",
      " [ 453  454]]\n",
      "0.479408658923 0.500551267916 0.48975188781\n",
      "Training  CalibratedClassifierCV\n",
      "[[5770   92]\n",
      " [ 816   91]]\n",
      "0.497267759563 0.10033076075 0.166972477064\n",
      "Training  SGDClassifier\n",
      "[[5471  391]\n",
      " [ 681  226]]\n",
      "0.366288492707 0.249173098126 0.296587926509\n",
      "Training  KNeighborsClassifier\n",
      "[[5523  339]\n",
      " [ 354  553]]\n",
      "0.619955156951 0.609702315325 0.614785992218\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.40676753\n",
      "Iteration 2, loss = 0.33243473\n",
      "Iteration 3, loss = 0.31347340\n",
      "Iteration 4, loss = 0.30124853\n",
      "Iteration 5, loss = 0.29190643\n",
      "Iteration 6, loss = 0.28427711\n",
      "Iteration 7, loss = 0.27735530\n",
      "Iteration 8, loss = 0.27128924\n",
      "Iteration 9, loss = 0.26314626\n",
      "Iteration 10, loss = 0.25657194\n",
      "Iteration 11, loss = 0.25273168\n",
      "Iteration 12, loss = 0.24532851\n",
      "Iteration 13, loss = 0.23980307\n",
      "Iteration 14, loss = 0.23567186\n",
      "Iteration 15, loss = 0.22813043\n",
      "Iteration 16, loss = 0.22373538\n",
      "Iteration 17, loss = 0.21920341\n",
      "Iteration 18, loss = 0.21355272\n",
      "Iteration 19, loss = 0.20730495\n",
      "Iteration 20, loss = 0.20467826\n",
      "Iteration 21, loss = 0.19980321\n",
      "Iteration 22, loss = 0.19348093\n",
      "Iteration 23, loss = 0.19220180\n",
      "Iteration 24, loss = 0.18829726\n",
      "Iteration 25, loss = 0.18449878\n",
      "Iteration 26, loss = 0.18178273\n",
      "Iteration 27, loss = 0.18277577\n",
      "Iteration 28, loss = 0.17187006\n",
      "Iteration 29, loss = 0.17208061\n",
      "Iteration 30, loss = 0.16284360\n",
      "Iteration 31, loss = 0.16316370\n",
      "Iteration 32, loss = 0.16413844\n",
      "Iteration 33, loss = 0.15529591\n",
      "Iteration 34, loss = 0.15435912\n",
      "Iteration 35, loss = 0.14881492\n",
      "Iteration 36, loss = 0.15176068\n",
      "Iteration 37, loss = 0.14485094\n",
      "Iteration 38, loss = 0.14722648\n",
      "Iteration 39, loss = 0.14113469\n",
      "Iteration 40, loss = 0.13745991\n",
      "Iteration 41, loss = 0.13440713\n",
      "Iteration 42, loss = 0.13531634\n",
      "Iteration 43, loss = 0.13052611\n",
      "Iteration 44, loss = 0.12670515\n",
      "Iteration 45, loss = 0.12887439\n",
      "Iteration 46, loss = 0.12511876\n",
      "Iteration 47, loss = 0.12526021\n",
      "Iteration 48, loss = 0.11981547\n",
      "Iteration 49, loss = 0.11831007\n",
      "Iteration 50, loss = 0.11825250\n",
      "Iteration 51, loss = 0.11340285\n",
      "Iteration 52, loss = 0.11278858\n",
      "Iteration 53, loss = 0.11360057\n",
      "Iteration 54, loss = 0.10946550\n",
      "Iteration 55, loss = 0.10947663\n",
      "Iteration 56, loss = 0.10677730\n",
      "Iteration 57, loss = 0.11067791\n",
      "Iteration 58, loss = 0.10414619\n",
      "Iteration 59, loss = 0.10405574\n",
      "Iteration 60, loss = 0.10216945\n",
      "Iteration 61, loss = 0.10244988\n",
      "Iteration 62, loss = 0.09763140\n",
      "Iteration 63, loss = 0.10002668\n",
      "Iteration 64, loss = 0.09509388\n",
      "Iteration 65, loss = 0.09939439\n",
      "Iteration 66, loss = 0.09828368\n",
      "Iteration 67, loss = 0.09545263\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5483  379]\n",
      " [ 380  527]]\n",
      "0.581677704194 0.581036383682 0.581356867071\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.315138282387 | 0.477398015436 | 0.379658044717 | 0.790958782686 |\n",
      "| RandomForestClassifier | 0.795774647887 | 0.373759647189 | 0.508627156789 | 0.903235337568 |\n",
      "|   BaggingClassifier    | 0.784518828452 | 0.413450937155 | 0.541516245487 | 0.906189983749 |\n",
      "|  ExtraTreesClassifier  | 0.762419006479 | 0.389195148842 | 0.515328467153 | 0.901905746787 |\n",
      "| DecisionTreeClassifier | 0.479408658923 | 0.500551267916 | 0.48975188781  | 0.860245235633 |\n",
      "| CalibratedClassifierCV | 0.497267759563 | 0.10033076075  | 0.166972477064 | 0.865859063377 |\n",
      "|     SGDClassifier      | 0.366288492707 | 0.249173098126 | 0.296587926509 | 0.841630964692 |\n",
      "|  KNeighborsClassifier  | 0.619955156951 | 0.609702315325 | 0.614785992218 | 0.897621509824 |\n",
      "|     MLPClassifier      | 0.581677704194 | 0.581036383682 | 0.581356867071 | 0.887871177427 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'csv_3_ReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "When we breaked the sentences to contain only the middle context it was observed that comma seperated BR's had a disadvantage as in some sentences that was taken as middle context, and no other words appeared. So to get more out the context of the surronding words around BR, BR's appearing together were grouped into a single BR entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSen(sentence):\n",
    "    sentence = re.sub(\"\\s(the|The)\\s\",\" \",sentence)\n",
    "    sentence = re.sub(\"^(the|The)\",\"\",sentence)\n",
    "    sentence = re.sub(\"(nucleus)\",\" \",sentence)\n",
    "    sentence = re.sub(r\",\",\" \", sentence)\n",
    "    sentence = re.sub(\"\\([0-9]\\)\",\".\",sentence)\n",
    "    sentence = re.sub(\"[, ]*(BR[^12])([, ]*(BR[^12]))+[, ]*\",\" BR \",sentence)\n",
    "    sentence = re.sub(\"[, ]*(BR[, ]+)*BR1([, ]+BR[^12])*[, ]*\",\" BR1 \",sentence)\n",
    "    sentence = re.sub(\"[, ]*(BR[, ]+)*BR2([, ]+BR[^12])*[, ]*\",\" BR2 \",sentence)\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFSen = []\n",
    "for i in range(0,trainLen):\n",
    "    trainFSen.append(formatSen(trainSen[i]))\n",
    "    \n",
    "testFSen = []\n",
    "for i in range(0,testLen):\n",
    "    testFSen.append(formatSen(testSen[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[') divisions of br1 ( mgc ) br ( sg ) br ( lim ) and br2 .',\n",
       " 'areas of primate br1 such as br2 where a',\n",
       " 'all br including br1 br2 and br',\n",
       " 'results suggest that br1 input to br may be directed toward specific subpopulation ( s ) of br neurons and may influence not only cells in br2 but also',\n",
       " '-gel implants in br1 many retrogradely labeled cells were observed mainly in br2 and br']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMid = breakSen(trainFSen)\n",
    "testMid = breakSen(testFSen)\n",
    "trainMid[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[5513  349]\n",
      " [ 609  298]]\n",
      "0.460587326121 0.32855567806 0.383526383526\n",
      "Training  RandomForestClassifier\n",
      "[[5783   79]\n",
      " [ 413  494]]\n",
      "0.862129144852 0.544652701213 0.667567567568\n",
      "Training  BaggingClassifier\n",
      "[[5697  165]\n",
      " [ 321  586]]\n",
      "0.780292942743 0.646085997795 0.70687575392\n",
      "Training  ExtraTreesClassifier\n",
      "[[5743  119]\n",
      " [ 373  534]]\n",
      "0.817764165391 0.588754134509 0.684615384615\n",
      "Training  DecisionTreeClassifier\n",
      "[[5589  273]\n",
      " [ 307  600]]\n",
      "0.687285223368 0.661521499449 0.674157303371\n",
      "Training  CalibratedClassifierCV\n",
      "[[5704  158]\n",
      " [ 272  635]]\n",
      "0.800756620429 0.700110253583 0.747058823529\n",
      "Training  SGDClassifier\n",
      "[[5794   68]\n",
      " [ 454  453]]\n",
      "0.869481765835 0.499448732084 0.634453781513\n",
      "Training  KNeighborsClassifier\n",
      "[[5542  320]\n",
      " [ 294  613]]\n",
      "0.657020364416 0.67585446527 0.666304347826\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.43017429\n",
      "Iteration 2, loss = 0.16907243\n",
      "Iteration 3, loss = 0.05609700\n",
      "Iteration 4, loss = 0.02700541\n",
      "Iteration 5, loss = 0.01663817\n",
      "Iteration 6, loss = 0.01175735\n",
      "Iteration 7, loss = 0.00856895\n",
      "Iteration 8, loss = 0.00670976\n",
      "Iteration 9, loss = 0.00610854\n",
      "Iteration 10, loss = 0.00513201\n",
      "Iteration 11, loss = 0.00562967\n",
      "Iteration 12, loss = 0.00467670\n",
      "Iteration 13, loss = 0.00443536\n",
      "Iteration 14, loss = 0.00420537\n",
      "Iteration 15, loss = 0.00440877\n",
      "Iteration 16, loss = 0.00427512\n",
      "Iteration 17, loss = 0.00432902\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5649  213]\n",
      " [ 252  655]]\n",
      "0.754608294931 0.722160970232 0.738028169014\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.460587326121 | 0.32855567806  | 0.383526383526 | 0.858472447924 |\n",
      "| RandomForestClassifier | 0.862129144852 | 0.544652701213 | 0.667567567568 | 0.927315703944 |\n",
      "|   BaggingClassifier    | 0.780292942743 | 0.646085997795 | 0.70687575392  | 0.928202097799 |\n",
      "|  ExtraTreesClassifier  | 0.817764165391 | 0.588754134509 | 0.684615384615 | 0.927315703944 |\n",
      "| DecisionTreeClassifier | 0.687285223368 | 0.661521499449 | 0.674157303371 | 0.914315260748 |\n",
      "| CalibratedClassifierCV | 0.800756620429 | 0.700110253583 | 0.747058823529 | 0.936475107106 |\n",
      "|     SGDClassifier      | 0.869481765835 | 0.499448732084 | 0.634453781513 | 0.922883734673 |\n",
      "|  KNeighborsClassifier  | 0.657020364416 | 0.67585446527  | 0.666304347826 | 0.90929236224  |\n",
      "|     MLPClassifier      | 0.754608294931 | 0.722160970232 | 0.738028169014 | 0.931304476289 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding... 15792\n",
      "0 15792\n",
      "Embedding... 6769\n",
      "0 6769\n",
      "Training  BernoulliNB\n",
      "[[4758 1104]\n",
      " [ 425  482]]\n",
      "0.303909205549 0.531422271224 0.386682711592\n",
      "Training  RandomForestClassifier\n",
      "[[5760  102]\n",
      " [ 629  278]]\n",
      "0.731578947368 0.306504961411 0.432012432012\n",
      "Training  BaggingClassifier\n",
      "[[5737  125]\n",
      " [ 582  325]]\n",
      "0.722222222222 0.358324145535 0.478997789241\n",
      "Training  ExtraTreesClassifier\n",
      "[[5723  139]\n",
      " [ 601  306]]\n",
      "0.687640449438 0.337375964719 0.452662721893\n",
      "Training  DecisionTreeClassifier\n",
      "[[5301  561]\n",
      " [ 476  431]]\n",
      "0.434475806452 0.475192943771 0.45392311743\n",
      "Training  CalibratedClassifierCV\n",
      "[[5754  108]\n",
      " [ 792  115]]\n",
      "0.515695067265 0.126791620728 0.203539823009\n",
      "Training  SGDClassifier\n",
      "[[5673  189]\n",
      " [ 845   62]]\n",
      "0.247011952191 0.0683572216097 0.107081174439\n",
      "Training  KNeighborsClassifier\n",
      "[[5512  350]\n",
      " [ 327  580]]\n",
      "0.623655913978 0.6394707828 0.631464344039\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37957125\n",
      "Iteration 2, loss = 0.32048802\n",
      "Iteration 3, loss = 0.30545818\n",
      "Iteration 4, loss = 0.29262732\n",
      "Iteration 5, loss = 0.28060159\n",
      "Iteration 6, loss = 0.27215265\n",
      "Iteration 7, loss = 0.25926288\n",
      "Iteration 8, loss = 0.25058910\n",
      "Iteration 9, loss = 0.24235772\n",
      "Iteration 10, loss = 0.23163304\n",
      "Iteration 11, loss = 0.22503816\n",
      "Iteration 12, loss = 0.21666397\n",
      "Iteration 13, loss = 0.20878695\n",
      "Iteration 14, loss = 0.20056353\n",
      "Iteration 15, loss = 0.19763243\n",
      "Iteration 16, loss = 0.18990587\n",
      "Iteration 17, loss = 0.18154148\n",
      "Iteration 18, loss = 0.17730530\n",
      "Iteration 19, loss = 0.17186642\n",
      "Iteration 20, loss = 0.16397962\n",
      "Iteration 21, loss = 0.15893839\n",
      "Iteration 22, loss = 0.15483928\n",
      "Iteration 23, loss = 0.14886667\n",
      "Iteration 24, loss = 0.14891797\n",
      "Iteration 25, loss = 0.14021583\n",
      "Iteration 26, loss = 0.13913137\n",
      "Iteration 27, loss = 0.13014483\n",
      "Iteration 28, loss = 0.12714499\n",
      "Iteration 29, loss = 0.12548037\n",
      "Iteration 30, loss = 0.12121310\n",
      "Iteration 31, loss = 0.12007800\n",
      "Iteration 32, loss = 0.11609731\n",
      "Iteration 33, loss = 0.10962540\n",
      "Iteration 34, loss = 0.10555018\n",
      "Iteration 35, loss = 0.10947009\n",
      "Iteration 36, loss = 0.10256162\n",
      "Iteration 37, loss = 0.09904796\n",
      "Iteration 38, loss = 0.09744466\n",
      "Iteration 39, loss = 0.09411063\n",
      "Iteration 40, loss = 0.09194829\n",
      "Iteration 41, loss = 0.08886357\n",
      "Iteration 42, loss = 0.09023319\n",
      "Iteration 43, loss = 0.08498280\n",
      "Iteration 44, loss = 0.08239017\n",
      "Iteration 45, loss = 0.08244579\n",
      "Iteration 46, loss = 0.08277223\n",
      "Iteration 47, loss = 0.07754573\n",
      "Iteration 48, loss = 0.07467556\n",
      "Iteration 49, loss = 0.07319679\n",
      "Iteration 50, loss = 0.07000456\n",
      "Iteration 51, loss = 0.07039506\n",
      "Iteration 52, loss = 0.07078803\n",
      "Iteration 53, loss = 0.06896959\n",
      "Iteration 54, loss = 0.06937230\n",
      "Iteration 55, loss = 0.06382289\n",
      "Iteration 56, loss = 0.06311183\n",
      "Iteration 57, loss = 0.06420348\n",
      "Iteration 58, loss = 0.06166845\n",
      "Iteration 59, loss = 0.06345669\n",
      "Iteration 60, loss = 0.06317949\n",
      "Iteration 61, loss = 0.05718554\n",
      "Iteration 62, loss = 0.05510450\n",
      "Iteration 63, loss = 0.05506589\n",
      "Iteration 64, loss = 0.05828751\n",
      "Iteration 65, loss = 0.05342851\n",
      "Iteration 66, loss = 0.05385809\n",
      "Iteration 67, loss = 0.05600797\n",
      "Iteration 68, loss = 0.05489924\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5512  350]\n",
      " [ 380  527]]\n",
      "0.600912200684 0.581036383682 0.590807174888\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.303909205549 |  0.531422271224 | 0.386682711592 | 0.774117299453 |\n",
      "| RandomForestClassifier | 0.731578947368 |  0.306504961411 | 0.432012432012 | 0.89200768208  |\n",
      "|   BaggingClassifier    | 0.722222222222 |  0.358324145535 | 0.478997789241 | 0.895553257497 |\n",
      "|  ExtraTreesClassifier  | 0.687640449438 |  0.337375964719 | 0.452662721893 | 0.890678091299 |\n",
      "| DecisionTreeClassifier | 0.434475806452 |  0.475192943771 | 0.45392311743  | 0.846801595509 |\n",
      "| CalibratedClassifierCV | 0.515695067265 |  0.126791620728 | 0.203539823009 | 0.86704092185  |\n",
      "|     SGDClassifier      | 0.247011952191 | 0.0683572216097 | 0.107081174439 | 0.847244792436 |\n",
      "|  KNeighborsClassifier  | 0.623655913978 |   0.6394707828  | 0.631464344039 | 0.899985226769 |\n",
      "|     MLPClassifier      | 0.600912200684 |  0.581036383682 | 0.590807174888 | 0.892155414389 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding... 15792\n",
      "6 15792\n",
      "Embedding... 6769\n",
      "1 6769\n",
      "Training  BernoulliNB\n",
      "[[4825 1037]\n",
      " [ 484  423]]\n",
      "0.289726027397 0.466372657111 0.357414448669\n",
      "Training  RandomForestClassifier\n",
      "[[5762  100]\n",
      " [ 600  307]]\n",
      "0.7542997543 0.338478500551 0.467275494673\n",
      "Training  BaggingClassifier\n",
      "[[5721  141]\n",
      " [ 558  349]]\n",
      "0.712244897959 0.384785005513 0.499642090193\n",
      "Training  ExtraTreesClassifier\n",
      "[[5725  137]\n",
      " [ 596  311]]\n",
      "0.694196428571 0.342888643881 0.459040590406\n",
      "Training  DecisionTreeClassifier\n",
      "[[5380  482]\n",
      " [ 477  430]]\n",
      "0.47149122807 0.474090407938 0.472787245739\n",
      "Training  CalibratedClassifierCV\n",
      "[[5750  112]\n",
      " [ 796  111]]\n",
      "0.497757847534 0.122381477398 0.196460176991\n",
      "Training  SGDClassifier\n",
      "[[5737  125]\n",
      " [ 794  113]]\n",
      "0.474789915966 0.124586549063 0.197379912664\n",
      "Training  KNeighborsClassifier\n",
      "[[5542  320]\n",
      " [ 341  566]]\n",
      "0.638826185102 0.624035281147 0.631344116007\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.36384746\n",
      "Iteration 2, loss = 0.32002731\n",
      "Iteration 3, loss = 0.30475602\n",
      "Iteration 4, loss = 0.29306465\n",
      "Iteration 5, loss = 0.28226612\n",
      "Iteration 6, loss = 0.27092991\n",
      "Iteration 7, loss = 0.26158978\n",
      "Iteration 8, loss = 0.25467608\n",
      "Iteration 9, loss = 0.24362756\n",
      "Iteration 10, loss = 0.23567293\n",
      "Iteration 11, loss = 0.22712397\n",
      "Iteration 12, loss = 0.21930554\n",
      "Iteration 13, loss = 0.21398281\n",
      "Iteration 14, loss = 0.20599985\n",
      "Iteration 15, loss = 0.19835869\n",
      "Iteration 16, loss = 0.19243547\n",
      "Iteration 17, loss = 0.19001150\n",
      "Iteration 18, loss = 0.18209859\n",
      "Iteration 19, loss = 0.17702284\n",
      "Iteration 20, loss = 0.17282047\n",
      "Iteration 21, loss = 0.16645299\n",
      "Iteration 22, loss = 0.16200992\n",
      "Iteration 23, loss = 0.15831207\n",
      "Iteration 24, loss = 0.15207158\n",
      "Iteration 25, loss = 0.15075997\n",
      "Iteration 26, loss = 0.14533688\n",
      "Iteration 27, loss = 0.14194543\n",
      "Iteration 28, loss = 0.13938689\n",
      "Iteration 29, loss = 0.13655072\n",
      "Iteration 30, loss = 0.13025095\n",
      "Iteration 31, loss = 0.13033286\n",
      "Iteration 32, loss = 0.12655887\n",
      "Iteration 33, loss = 0.12425865\n",
      "Iteration 34, loss = 0.12004366\n",
      "Iteration 35, loss = 0.11613699\n",
      "Iteration 36, loss = 0.11174848\n",
      "Iteration 37, loss = 0.11077851\n",
      "Iteration 38, loss = 0.10579772\n",
      "Iteration 39, loss = 0.10425922\n",
      "Iteration 40, loss = 0.10819302\n",
      "Iteration 41, loss = 0.10274066\n",
      "Iteration 42, loss = 0.09903587\n",
      "Iteration 43, loss = 0.09755582\n",
      "Iteration 44, loss = 0.09347406\n",
      "Iteration 45, loss = 0.08957919\n",
      "Iteration 46, loss = 0.08969970\n",
      "Iteration 47, loss = 0.08877024\n",
      "Iteration 48, loss = 0.08986052\n",
      "Iteration 49, loss = 0.08636493\n",
      "Iteration 50, loss = 0.08644629\n",
      "Iteration 51, loss = 0.08395123\n",
      "Iteration 52, loss = 0.08288010\n",
      "Iteration 53, loss = 0.08021521\n",
      "Iteration 54, loss = 0.08304813\n",
      "Iteration 55, loss = 0.08410386\n",
      "Iteration 56, loss = 0.07916972\n",
      "Iteration 57, loss = 0.07755477\n",
      "Iteration 58, loss = 0.07369402\n",
      "Iteration 59, loss = 0.07260136\n",
      "Iteration 60, loss = 0.07190764\n",
      "Iteration 61, loss = 0.07343427\n",
      "Iteration 62, loss = 0.06910942\n",
      "Iteration 63, loss = 0.06875654\n",
      "Iteration 64, loss = 0.06844158\n",
      "Iteration 65, loss = 0.07072439\n",
      "Iteration 66, loss = 0.06705422\n",
      "Iteration 67, loss = 0.07124866\n",
      "Iteration 68, loss = 0.06685401\n",
      "Iteration 69, loss = 0.06569533\n",
      "Iteration 70, loss = 0.06454046\n",
      "Iteration 71, loss = 0.06141229\n",
      "Iteration 72, loss = 0.06531928\n",
      "Iteration 73, loss = 0.06577096\n",
      "Iteration 74, loss = 0.06335751\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5468  394]\n",
      " [ 348  559]]\n",
      "0.586568730325 0.61631753032 0.601075268817\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.289726027397 | 0.466372657111 | 0.357414448669 | 0.775299157926 |\n",
      "| RandomForestClassifier |  0.7542997543  | 0.338478500551 | 0.467275494673 | 0.896587383661 |\n",
      "|   BaggingClassifier    | 0.712244897959 | 0.384785005513 | 0.499642090193 | 0.89673511597  |\n",
      "|  ExtraTreesClassifier  | 0.694196428571 | 0.342888643881 | 0.459040590406 | 0.891712217462 |\n",
      "| DecisionTreeClassifier | 0.47149122807  | 0.474090407938 | 0.472787245739 | 0.858324715615 |\n",
      "| CalibratedClassifierCV | 0.497757847534 | 0.122381477398 | 0.196460176991 | 0.865859063377 |\n",
      "|     SGDClassifier      | 0.474789915966 | 0.124586549063 | 0.197379912664 | 0.864234007978 |\n",
      "|  KNeighborsClassifier  | 0.638826185102 | 0.624035281147 | 0.631344116007 | 0.902348943714 |\n",
      "|     MLPClassifier      | 0.586568730325 | 0.61631753032  | 0.601075268817 | 0.89038262668  |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding... 15792\n",
      "0 15792\n",
      "Embedding... 6769\n",
      "0 6769\n",
      "Training  BernoulliNB\n",
      "[[4428 1434]\n",
      " [ 394  513]]\n",
      "0.263482280431 0.565600882029 0.359495444989\n",
      "Training  RandomForestClassifier\n",
      "[[5773   89]\n",
      " [ 627  280]]\n",
      "0.758807588076 0.308710033076 0.438871473354\n",
      "Training  BaggingClassifier\n",
      "[[5743  119]\n",
      " [ 595  312]]\n",
      "0.723897911833 0.343991179713 0.466367713004\n",
      "Training  ExtraTreesClassifier\n",
      "[[5751  111]\n",
      " [ 616  291]]\n",
      "0.723880597015 0.320837927233 0.44461420932\n",
      "Training  DecisionTreeClassifier\n",
      "[[5327  535]\n",
      " [ 491  416]]\n",
      "0.437434279706 0.458654906284 0.447793326157\n",
      "Training  CalibratedClassifierCV\n",
      "[[5737  125]\n",
      " [ 801  106]]\n",
      "0.458874458874 0.116868798236 0.186291739895\n",
      "Training  SGDClassifier\n",
      "[[3329 2533]\n",
      " [ 247  660]]\n",
      "0.206702160977 0.727673649394 0.321951219512\n",
      "Training  KNeighborsClassifier\n",
      "[[5519  343]\n",
      " [ 343  564]]\n",
      "0.621830209482 0.621830209482 0.621830209482\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.35413348\n",
      "Iteration 2, loss = 0.30921414\n",
      "Iteration 3, loss = 0.29319977\n",
      "Iteration 4, loss = 0.27711661\n",
      "Iteration 5, loss = 0.26415668\n",
      "Iteration 6, loss = 0.24970316\n",
      "Iteration 7, loss = 0.23728037\n",
      "Iteration 8, loss = 0.22541051\n",
      "Iteration 9, loss = 0.21430259\n",
      "Iteration 10, loss = 0.20360895\n",
      "Iteration 11, loss = 0.19429524\n",
      "Iteration 12, loss = 0.18440414\n",
      "Iteration 13, loss = 0.17303186\n",
      "Iteration 14, loss = 0.16504078\n",
      "Iteration 15, loss = 0.15613427\n",
      "Iteration 16, loss = 0.15281373\n",
      "Iteration 17, loss = 0.14340676\n",
      "Iteration 18, loss = 0.13694006\n",
      "Iteration 19, loss = 0.12793664\n",
      "Iteration 20, loss = 0.12293970\n",
      "Iteration 21, loss = 0.11819052\n",
      "Iteration 22, loss = 0.11329153\n",
      "Iteration 23, loss = 0.11342768\n",
      "Iteration 24, loss = 0.10290481\n",
      "Iteration 25, loss = 0.10196660\n",
      "Iteration 26, loss = 0.09377680\n",
      "Iteration 27, loss = 0.09094102\n",
      "Iteration 28, loss = 0.08894518\n",
      "Iteration 29, loss = 0.08248599\n",
      "Iteration 30, loss = 0.07735674\n",
      "Iteration 31, loss = 0.07976579\n",
      "Iteration 32, loss = 0.07633177\n",
      "Iteration 33, loss = 0.07462377\n",
      "Iteration 34, loss = 0.06974042\n",
      "Iteration 35, loss = 0.06543524\n",
      "Iteration 36, loss = 0.06408970\n",
      "Iteration 37, loss = 0.06306138\n",
      "Iteration 38, loss = 0.06013386\n",
      "Iteration 39, loss = 0.06527042\n",
      "Iteration 40, loss = 0.05847212\n",
      "Iteration 41, loss = 0.05657219\n",
      "Iteration 42, loss = 0.05454590\n",
      "Iteration 43, loss = 0.05472125\n",
      "Iteration 44, loss = 0.05437598\n",
      "Iteration 45, loss = 0.05017120\n",
      "Iteration 46, loss = 0.05113241\n",
      "Iteration 47, loss = 0.04915987\n",
      "Iteration 48, loss = 0.04685831\n",
      "Iteration 49, loss = 0.04972017\n",
      "Iteration 50, loss = 0.04536482\n",
      "Iteration 51, loss = 0.04617491\n",
      "Iteration 52, loss = 0.04276853\n",
      "Iteration 53, loss = 0.04584237\n",
      "Iteration 54, loss = 0.04433504\n",
      "Iteration 55, loss = 0.04605368\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5381  481]\n",
      " [ 281  626]]\n",
      "0.56549232159 0.690187431092 0.621648460775\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.263482280431 | 0.565600882029 | 0.359495444989 | 0.729945339046 |\n",
      "| RandomForestClassifier | 0.758807588076 | 0.308710033076 | 0.438871473354 | 0.894223666716 |\n",
      "|   BaggingClassifier    | 0.723897911833 | 0.343991179713 | 0.466367713004 | 0.894519131334 |\n",
      "|  ExtraTreesClassifier  | 0.723880597015 | 0.320837927233 | 0.44461420932  | 0.892598611316 |\n",
      "| DecisionTreeClassifier | 0.437434279706 | 0.458654906284 | 0.447793326157 | 0.848426650909 |\n",
      "| CalibratedClassifierCV | 0.458874458874 | 0.116868798236 | 0.186291739895 | 0.863199881814 |\n",
      "|     SGDClassifier      | 0.206702160977 | 0.727673649394 | 0.321951219512 | 0.589304180824 |\n",
      "|  KNeighborsClassifier  | 0.621830209482 | 0.621830209482 | 0.621830209482 | 0.898655635988 |\n",
      "|     MLPClassifier      | 0.56549232159  | 0.690187431092 | 0.621648460775 | 0.887427980499 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'csv_2_groupBR12'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding... 15792\n",
      "0 15792\n",
      "Embedding... 6769\n",
      "0 6769\n",
      "Training  BernoulliNB\n",
      "[[4502 1360]\n",
      " [ 450  457]]\n",
      "0.251513483764 0.503858875413 0.335535976505\n",
      "Training  RandomForestClassifier\n",
      "[[5788   74]\n",
      " [ 655  252]]\n",
      "0.773006134969 0.277839029768 0.408759124088\n",
      "Training  BaggingClassifier\n",
      "[[5744  118]\n",
      " [ 630  277]]\n",
      "0.701265822785 0.305402425579 0.425499231951\n",
      "Training  ExtraTreesClassifier\n",
      "[[5749  113]\n",
      " [ 612  295]]\n",
      "0.723039215686 0.325248070562 0.448669201521\n",
      "Training  DecisionTreeClassifier\n",
      "[[5324  538]\n",
      " [ 466  441]]\n",
      "0.450459652707 0.486218302095 0.467656415695\n",
      "Training  CalibratedClassifierCV\n",
      "[[5734  128]\n",
      " [ 802  105]]\n",
      "0.450643776824 0.115766262404 0.184210526316\n",
      "Training  SGDClassifier\n",
      "[[5810   52]\n",
      " [ 876   31]]\n",
      "0.373493975904 0.0341786108049 0.0626262626263\n",
      "Training  KNeighborsClassifier\n",
      "[[5504  358]\n",
      " [ 339  568]]\n",
      "0.613390928726 0.626240352811 0.619749045281\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37360274\n",
      "Iteration 2, loss = 0.31832403\n",
      "Iteration 3, loss = 0.30152261\n",
      "Iteration 4, loss = 0.28948533\n",
      "Iteration 5, loss = 0.27742726\n",
      "Iteration 6, loss = 0.26427246\n",
      "Iteration 7, loss = 0.25341717\n",
      "Iteration 8, loss = 0.24340593\n",
      "Iteration 9, loss = 0.23418646\n",
      "Iteration 10, loss = 0.22135972\n",
      "Iteration 11, loss = 0.21313059\n",
      "Iteration 12, loss = 0.20299756\n",
      "Iteration 13, loss = 0.19737148\n",
      "Iteration 14, loss = 0.18860270\n",
      "Iteration 15, loss = 0.18283508\n",
      "Iteration 16, loss = 0.17291741\n",
      "Iteration 17, loss = 0.16595639\n",
      "Iteration 18, loss = 0.16050262\n",
      "Iteration 19, loss = 0.15492090\n",
      "Iteration 20, loss = 0.14906303\n",
      "Iteration 21, loss = 0.13985012\n",
      "Iteration 22, loss = 0.13926633\n",
      "Iteration 23, loss = 0.13270985\n",
      "Iteration 24, loss = 0.12796907\n",
      "Iteration 25, loss = 0.12390822\n",
      "Iteration 26, loss = 0.12033825\n",
      "Iteration 27, loss = 0.11576888\n",
      "Iteration 28, loss = 0.11240764\n",
      "Iteration 29, loss = 0.10733959\n",
      "Iteration 30, loss = 0.10261892\n",
      "Iteration 31, loss = 0.10022070\n",
      "Iteration 32, loss = 0.10183232\n",
      "Iteration 33, loss = 0.09294420\n",
      "Iteration 34, loss = 0.09001774\n",
      "Iteration 35, loss = 0.08850378\n",
      "Iteration 36, loss = 0.08619955\n",
      "Iteration 37, loss = 0.08455877\n",
      "Iteration 38, loss = 0.08838843\n",
      "Iteration 39, loss = 0.07817328\n",
      "Iteration 40, loss = 0.07755286\n",
      "Iteration 41, loss = 0.07448738\n",
      "Iteration 42, loss = 0.07708786\n",
      "Iteration 43, loss = 0.07709025\n",
      "Iteration 44, loss = 0.07767486\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5587  275]\n",
      " [ 405  502]]\n",
      "0.646074646075 0.553472987872 0.596199524941\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.251513483764 |  0.503858875413 |  0.335535976505 | 0.732604520609 |\n",
      "| RandomForestClassifier | 0.773006134969 |  0.277839029768 |  0.408759124088 | 0.892303146698 |\n",
      "|   BaggingClassifier    | 0.701265822785 |  0.305402425579 |  0.425499231951 | 0.889496232826 |\n",
      "|  ExtraTreesClassifier  | 0.723039215686 |  0.325248070562 |  0.448669201521 | 0.892894075934 |\n",
      "| DecisionTreeClassifier | 0.450459652707 |  0.486218302095 |  0.467656415695 | 0.851676761708 |\n",
      "| CalibratedClassifierCV | 0.450643776824 |  0.115766262404 |  0.184210526316 | 0.862608952578 |\n",
      "|     SGDClassifier      | 0.373493975904 | 0.0341786108049 | 0.0626262626263 | 0.862904417196 |\n",
      "|  KNeighborsClassifier  | 0.613390928726 |  0.626240352811 |  0.619749045281 | 0.897030580588 |\n",
      "|     MLPClassifier      | 0.646074646075 |  0.553472987872 |  0.596199524941 | 0.899542029842 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_2_groupBR12_bigram'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainMid], bigram_trans[testMid])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Till now we were spliting the sentences using white space seperator. So the problem was the brackets were considered together with the words and not seperately. So before getting the vector we tokenize the sentence using nltk package function. This is only for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def convertW2V(data,w2v):\n",
    "    wholeM = []\n",
    "    print 'Embedding...'\n",
    "    for sentence in data:\n",
    "        arr = []    \n",
    "        for word in word_tokenize(sentence):\n",
    "            if word in w2v:\n",
    "                arr.append(np.array(w2v[word],copy=True))  \n",
    "                                #Each word is checked if it is there in the word2vec vocabulary. If there then\n",
    "                                #the vector space for the word is taken and then the mean is calculated.\n",
    "\n",
    "        mean = np.zeros(100)\n",
    "        for mat in arr:\n",
    "            for j in range(len(mat)):\n",
    "                mean[j] += mat[j]\n",
    "        if len(arr) != 0:\n",
    "            mean = np.array(mean/len(arr))\n",
    "        wholeM.append(mean)\n",
    "    return wholeM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4758 1104]\n",
      " [ 425  482]]\n",
      "0.303909205549 0.531422271224 0.386682711592\n",
      "Training  RandomForestClassifier\n",
      "[[5754  108]\n",
      " [ 626  281]]\n",
      "0.72236503856 0.309812568908 0.433641975309\n",
      "Training  BaggingClassifier\n",
      "[[5736  126]\n",
      " [ 566  341]]\n",
      "0.730192719486 0.375964718853 0.496360989811\n",
      "Training  ExtraTreesClassifier\n",
      "[[5718  144]\n",
      " [ 585  322]]\n",
      "0.690987124464 0.355016538037 0.469045884924\n",
      "Training  DecisionTreeClassifier\n",
      "[[5371  491]\n",
      " [ 480  427]]\n",
      "0.4651416122 0.470782800441 0.467945205479\n",
      "Training  CalibratedClassifierCV\n",
      "[[5754  108]\n",
      " [ 792  115]]\n",
      "0.515695067265 0.126791620728 0.203539823009\n",
      "Training  SGDClassifier\n",
      "[[5772   90]\n",
      " [ 829   78]]\n",
      "0.464285714286 0.0859977949283 0.14511627907\n",
      "Training  KNeighborsClassifier\n",
      "[[5512  350]\n",
      " [ 327  580]]\n",
      "0.623655913978 0.6394707828 0.631464344039\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.38301467\n",
      "Iteration 2, loss = 0.31924996\n",
      "Iteration 3, loss = 0.30405911\n",
      "Iteration 4, loss = 0.29076975\n",
      "Iteration 5, loss = 0.27934754\n",
      "Iteration 6, loss = 0.26864250\n",
      "Iteration 7, loss = 0.25866825\n",
      "Iteration 8, loss = 0.24969770\n",
      "Iteration 9, loss = 0.24144839\n",
      "Iteration 10, loss = 0.23306124\n",
      "Iteration 11, loss = 0.22499745\n",
      "Iteration 12, loss = 0.21882265\n",
      "Iteration 13, loss = 0.21050426\n",
      "Iteration 14, loss = 0.20396867\n",
      "Iteration 15, loss = 0.19526575\n",
      "Iteration 16, loss = 0.19175591\n",
      "Iteration 17, loss = 0.18464975\n",
      "Iteration 18, loss = 0.17629453\n",
      "Iteration 19, loss = 0.17280680\n",
      "Iteration 20, loss = 0.16470776\n",
      "Iteration 21, loss = 0.16011471\n",
      "Iteration 22, loss = 0.15731341\n",
      "Iteration 23, loss = 0.15110595\n",
      "Iteration 24, loss = 0.14715951\n",
      "Iteration 25, loss = 0.14047423\n",
      "Iteration 26, loss = 0.13775884\n",
      "Iteration 27, loss = 0.13126064\n",
      "Iteration 28, loss = 0.13178451\n",
      "Iteration 29, loss = 0.12355307\n",
      "Iteration 30, loss = 0.12171269\n",
      "Iteration 31, loss = 0.12289281\n",
      "Iteration 32, loss = 0.11316035\n",
      "Iteration 33, loss = 0.11116423\n",
      "Iteration 34, loss = 0.10594705\n",
      "Iteration 35, loss = 0.10426715\n",
      "Iteration 36, loss = 0.10294210\n",
      "Iteration 37, loss = 0.10009378\n",
      "Iteration 38, loss = 0.09848456\n",
      "Iteration 39, loss = 0.09258657\n",
      "Iteration 40, loss = 0.09148858\n",
      "Iteration 41, loss = 0.09207127\n",
      "Iteration 42, loss = 0.08720240\n",
      "Iteration 43, loss = 0.08274176\n",
      "Iteration 44, loss = 0.08074026\n",
      "Iteration 45, loss = 0.07920285\n",
      "Iteration 46, loss = 0.07697278\n",
      "Iteration 47, loss = 0.07487157\n",
      "Iteration 48, loss = 0.07679369\n",
      "Iteration 49, loss = 0.07128393\n",
      "Iteration 50, loss = 0.07475772\n",
      "Iteration 51, loss = 0.06943719\n",
      "Iteration 52, loss = 0.06758301\n",
      "Iteration 53, loss = 0.06565946\n",
      "Iteration 54, loss = 0.06681075\n",
      "Iteration 55, loss = 0.06543317\n",
      "Iteration 56, loss = 0.06299208\n",
      "Iteration 57, loss = 0.06526949\n",
      "Iteration 58, loss = 0.06200333\n",
      "Iteration 59, loss = 0.06189598\n",
      "Iteration 60, loss = 0.05671828\n",
      "Iteration 61, loss = 0.05560094\n",
      "Iteration 62, loss = 0.05757294\n",
      "Iteration 63, loss = 0.05976665\n",
      "Iteration 64, loss = 0.05712667\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5603  259]\n",
      " [ 421  486]]\n",
      "0.652348993289 0.535832414553 0.588377723971\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.303909205549 |  0.531422271224 | 0.386682711592 | 0.774117299453 |\n",
      "| RandomForestClassifier | 0.72236503856  |  0.309812568908 | 0.433641975309 | 0.891564485153 |\n",
      "|   BaggingClassifier    | 0.730192719486 |  0.375964718853 | 0.496360989811 | 0.897769242133 |\n",
      "|  ExtraTreesClassifier  | 0.690987124464 |  0.355016538037 | 0.469045884924 | 0.892303146698 |\n",
      "| DecisionTreeClassifier |  0.4651416122  |  0.470782800441 | 0.467945205479 | 0.856551927907 |\n",
      "| CalibratedClassifierCV | 0.515695067265 |  0.126791620728 | 0.203539823009 | 0.86704092185  |\n",
      "|     SGDClassifier      | 0.464285714286 | 0.0859977949283 | 0.14511627907  | 0.864234007978 |\n",
      "|  KNeighborsClassifier  | 0.623655913978 |   0.6394707828  | 0.631464344039 | 0.899985226769 |\n",
      "|     MLPClassifier      | 0.652348993289 |  0.535832414553 | 0.588377723971 | 0.899542029842 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4825 1037]\n",
      " [ 484  423]]\n",
      "0.289726027397 0.466372657111 0.357414448669\n",
      "Training  RandomForestClassifier\n",
      "[[5761  101]\n",
      " [ 598  309]]\n",
      "0.753658536585 0.340683572216 0.469248291572\n",
      "Training  BaggingClassifier\n",
      "[[5712  150]\n",
      " [ 563  344]]\n",
      "0.696356275304 0.379272326351 0.49107780157\n",
      "Training  ExtraTreesClassifier\n",
      "[[5741  121]\n",
      " [ 586  321]]\n",
      "0.726244343891 0.353914002205 0.475908080059\n",
      "Training  DecisionTreeClassifier\n",
      "[[5372  490]\n",
      " [ 470  437]]\n",
      "0.471413160734 0.481808158765 0.476553980371\n",
      "Training  CalibratedClassifierCV\n",
      "[[5750  112]\n",
      " [ 796  111]]\n",
      "0.497757847534 0.122381477398 0.196460176991\n",
      "Training  SGDClassifier\n",
      "[[4767 1095]\n",
      " [ 479  428]]\n",
      "0.281024294156 0.471885336273 0.352263374486\n",
      "Training  KNeighborsClassifier\n",
      "[[5542  320]\n",
      " [ 341  566]]\n",
      "0.638826185102 0.624035281147 0.631344116007\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37786374\n",
      "Iteration 2, loss = 0.32143615\n",
      "Iteration 3, loss = 0.30537608\n",
      "Iteration 4, loss = 0.29240312\n",
      "Iteration 5, loss = 0.28111249\n",
      "Iteration 6, loss = 0.27120912\n",
      "Iteration 7, loss = 0.26182841\n",
      "Iteration 8, loss = 0.25345983\n",
      "Iteration 9, loss = 0.24637203\n",
      "Iteration 10, loss = 0.23697870\n",
      "Iteration 11, loss = 0.22750255\n",
      "Iteration 12, loss = 0.22475798\n",
      "Iteration 13, loss = 0.21466286\n",
      "Iteration 14, loss = 0.20606914\n",
      "Iteration 15, loss = 0.20281989\n",
      "Iteration 16, loss = 0.19467181\n",
      "Iteration 17, loss = 0.18915592\n",
      "Iteration 18, loss = 0.18381539\n",
      "Iteration 19, loss = 0.17728483\n",
      "Iteration 20, loss = 0.17326280\n",
      "Iteration 21, loss = 0.16840077\n",
      "Iteration 22, loss = 0.16396993\n",
      "Iteration 23, loss = 0.15767394\n",
      "Iteration 24, loss = 0.15459607\n",
      "Iteration 25, loss = 0.14671164\n",
      "Iteration 26, loss = 0.14646306\n",
      "Iteration 27, loss = 0.14134313\n",
      "Iteration 28, loss = 0.13790167\n",
      "Iteration 29, loss = 0.13438932\n",
      "Iteration 30, loss = 0.13214963\n",
      "Iteration 31, loss = 0.12671708\n",
      "Iteration 32, loss = 0.12478768\n",
      "Iteration 33, loss = 0.12087299\n",
      "Iteration 34, loss = 0.11902830\n",
      "Iteration 35, loss = 0.11334853\n",
      "Iteration 36, loss = 0.11293654\n",
      "Iteration 37, loss = 0.10679519\n",
      "Iteration 38, loss = 0.11048005\n",
      "Iteration 39, loss = 0.10633826\n",
      "Iteration 40, loss = 0.10320614\n",
      "Iteration 41, loss = 0.09890796\n",
      "Iteration 42, loss = 0.09839944\n",
      "Iteration 43, loss = 0.09437948\n",
      "Iteration 44, loss = 0.09226204\n",
      "Iteration 45, loss = 0.09034332\n",
      "Iteration 46, loss = 0.08997972\n",
      "Iteration 47, loss = 0.08928316\n",
      "Iteration 48, loss = 0.08597964\n",
      "Iteration 49, loss = 0.08512498\n",
      "Iteration 50, loss = 0.08398354\n",
      "Iteration 51, loss = 0.07951155\n",
      "Iteration 52, loss = 0.07866582\n",
      "Iteration 53, loss = 0.07866353\n",
      "Iteration 54, loss = 0.07571038\n",
      "Iteration 55, loss = 0.07886775\n",
      "Iteration 56, loss = 0.07465398\n",
      "Iteration 57, loss = 0.07464039\n",
      "Iteration 58, loss = 0.07072389\n",
      "Iteration 59, loss = 0.07618841\n",
      "Iteration 60, loss = 0.07184630\n",
      "Iteration 61, loss = 0.07042135\n",
      "Iteration 62, loss = 0.06779501\n",
      "Iteration 63, loss = 0.07027134\n",
      "Iteration 64, loss = 0.06668086\n",
      "Iteration 65, loss = 0.06373062\n",
      "Iteration 66, loss = 0.06370590\n",
      "Iteration 67, loss = 0.06435115\n",
      "Iteration 68, loss = 0.06346107\n",
      "Iteration 69, loss = 0.06219374\n",
      "Iteration 70, loss = 0.06182742\n",
      "Iteration 71, loss = 0.05894745\n",
      "Iteration 72, loss = 0.06140045\n",
      "Iteration 73, loss = 0.05908946\n",
      "Iteration 74, loss = 0.05950967\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5596  266]\n",
      " [ 453  454]]\n",
      "0.630555555556 0.500551267916 0.558082360172\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.289726027397 | 0.466372657111 | 0.357414448669 | 0.775299157926 |\n",
      "| RandomForestClassifier | 0.753658536585 | 0.340683572216 | 0.469248291572 | 0.89673511597  |\n",
      "|   BaggingClassifier    | 0.696356275304 | 0.379272326351 | 0.49107780157  | 0.894666863643 |\n",
      "|  ExtraTreesClassifier  | 0.726244343891 | 0.353914002205 | 0.475908080059 | 0.895553257497 |\n",
      "| DecisionTreeClassifier | 0.471413160734 | 0.481808158765 | 0.476553980371 | 0.858176983306 |\n",
      "| CalibratedClassifierCV | 0.497757847534 | 0.122381477398 | 0.196460176991 | 0.865859063377 |\n",
      "|     SGDClassifier      | 0.281024294156 | 0.471885336273 | 0.352263374486 | 0.767469345546 |\n",
      "|  KNeighborsClassifier  | 0.638826185102 | 0.624035281147 | 0.631344116007 | 0.902348943714 |\n",
      "|     MLPClassifier      | 0.630555555556 | 0.500551267916 | 0.558082360172 | 0.893780469789 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[5138  724]\n",
      " [ 566  341]]\n",
      "0.320187793427 0.375964718853 0.34584178499\n",
      "Training  RandomForestClassifier\n",
      "[[5782   80]\n",
      " [ 622  285]]\n",
      "0.780821917808 0.314222712238 0.448113207547\n",
      "Training  BaggingClassifier\n",
      "[[5767   95]\n",
      " [ 589  318]]\n",
      "0.769975786925 0.350606394708 0.481818181818\n",
      "Training  ExtraTreesClassifier\n",
      "[[5746  116]\n",
      " [ 573  334]]\n",
      "0.742222222222 0.368246968026 0.492262343405\n",
      "Training  DecisionTreeClassifier\n",
      "[[5340  522]\n",
      " [ 440  467]]\n",
      "0.47219413549 0.514884233738 0.492616033755\n",
      "Training  CalibratedClassifierCV\n",
      "[[5751  111]\n",
      " [ 818   89]]\n",
      "0.445 0.0981256890849 0.160794941283\n",
      "Training  SGDClassifier\n",
      "[[5370  492]\n",
      " [ 677  230]]\n",
      "0.318559556787 0.253583241455 0.282381829343\n",
      "Training  KNeighborsClassifier\n",
      "[[5541  321]\n",
      " [ 332  575]]\n",
      "0.641741071429 0.633958103638 0.637825845813\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.37784889\n",
      "Iteration 2, loss = 0.31608462\n",
      "Iteration 3, loss = 0.29659850\n",
      "Iteration 4, loss = 0.28065110\n",
      "Iteration 5, loss = 0.26505479\n",
      "Iteration 6, loss = 0.25090209\n",
      "Iteration 7, loss = 0.23946056\n",
      "Iteration 8, loss = 0.22717594\n",
      "Iteration 9, loss = 0.21487071\n",
      "Iteration 10, loss = 0.20217632\n",
      "Iteration 11, loss = 0.19339305\n",
      "Iteration 12, loss = 0.18836191\n",
      "Iteration 13, loss = 0.17602148\n",
      "Iteration 14, loss = 0.16914390\n",
      "Iteration 15, loss = 0.16582621\n",
      "Iteration 16, loss = 0.15528215\n",
      "Iteration 17, loss = 0.14651097\n",
      "Iteration 18, loss = 0.14017830\n",
      "Iteration 19, loss = 0.13258509\n",
      "Iteration 20, loss = 0.12864203\n",
      "Iteration 21, loss = 0.12428954\n",
      "Iteration 22, loss = 0.11747726\n",
      "Iteration 23, loss = 0.11351055\n",
      "Iteration 24, loss = 0.10950385\n",
      "Iteration 25, loss = 0.10141554\n",
      "Iteration 26, loss = 0.10021414\n",
      "Iteration 27, loss = 0.09593770\n",
      "Iteration 28, loss = 0.09196466\n",
      "Iteration 29, loss = 0.09261336\n",
      "Iteration 30, loss = 0.08514713\n",
      "Iteration 31, loss = 0.08144052\n",
      "Iteration 32, loss = 0.08170444\n",
      "Iteration 33, loss = 0.07758563\n",
      "Iteration 34, loss = 0.07533500\n",
      "Iteration 35, loss = 0.07229987\n",
      "Iteration 36, loss = 0.07023735\n",
      "Iteration 37, loss = 0.07058647\n",
      "Iteration 38, loss = 0.06912259\n",
      "Iteration 39, loss = 0.06393092\n",
      "Iteration 40, loss = 0.06425364\n",
      "Iteration 41, loss = 0.06005449\n",
      "Iteration 42, loss = 0.06061583\n",
      "Iteration 43, loss = 0.06191382\n",
      "Iteration 44, loss = 0.06089980\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5492  370]\n",
      " [ 333  574]]\n",
      "0.608050847458 0.632855567806 0.620205294435\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.320187793427 |  0.375964718853 | 0.34584178499  | 0.809425321318 |\n",
      "| RandomForestClassifier | 0.780821917808 |  0.314222712238 | 0.448113207547 | 0.896291919043 |\n",
      "|   BaggingClassifier    | 0.769975786925 |  0.350606394708 | 0.481818181818 | 0.898951100606 |\n",
      "|  ExtraTreesClassifier  | 0.742222222222 |  0.368246968026 | 0.492262343405 | 0.89821243906  |\n",
      "| DecisionTreeClassifier | 0.47219413549  |  0.514884233738 | 0.492616033755 | 0.857881518688 |\n",
      "| CalibratedClassifierCV |     0.445      | 0.0981256890849 | 0.160794941283 | 0.862756684887 |\n",
      "|     SGDClassifier      | 0.318559556787 |  0.253583241455 | 0.282381829343 | 0.827300930714 |\n",
      "|  KNeighborsClassifier  | 0.641741071429 |  0.633958103638 | 0.637825845813 | 0.903530802186 |\n",
      "|     MLPClassifier      | 0.608050847458 |  0.632855567806 | 0.620205294435 | 0.896144186734 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'csv_2_groupBR12_token'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. next word2vec model is the one where BR1 and BR2 are marked and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[4469 1393]\n",
      " [ 450  457]]\n",
      "0.247027027027 0.503858875413 0.331519767864\n",
      "Training  RandomForestClassifier\n",
      "[[5776   86]\n",
      " [ 629  278]]\n",
      "0.763736263736 0.306504961411 0.437450826121\n",
      "Training  BaggingClassifier\n",
      "[[5744  118]\n",
      " [ 599  308]]\n",
      "0.723004694836 0.339581036384 0.462115528882\n",
      "Training  ExtraTreesClassifier\n",
      "[[5728  134]\n",
      " [ 582  325]]\n",
      "0.708061002179 0.358324145535 0.475841874085\n",
      "Training  DecisionTreeClassifier\n",
      "[[5303  559]\n",
      " [ 480  427]]\n",
      "0.433062880325 0.470782800441 0.451135763339\n",
      "Training  CalibratedClassifierCV\n",
      "[[5744  118]\n",
      " [ 820   87]]\n",
      "0.424390243902 0.0959206174201 0.156474820144\n",
      "Training  SGDClassifier\n",
      "[[3961 1901]\n",
      " [ 269  638]]\n",
      "0.251280031508 0.70341786108 0.370284387696\n",
      "Training  KNeighborsClassifier\n",
      "[[5503  359]\n",
      " [ 330  577]]\n",
      "0.616452991453 0.636163175303 0.626153011394\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.35300818\n",
      "Iteration 2, loss = 0.30916939\n",
      "Iteration 3, loss = 0.29196523\n",
      "Iteration 4, loss = 0.27825120\n",
      "Iteration 5, loss = 0.26445039\n",
      "Iteration 6, loss = 0.25150284\n",
      "Iteration 7, loss = 0.24040041\n",
      "Iteration 8, loss = 0.22682726\n",
      "Iteration 9, loss = 0.21583114\n",
      "Iteration 10, loss = 0.20513232\n",
      "Iteration 11, loss = 0.19860491\n",
      "Iteration 12, loss = 0.18810687\n",
      "Iteration 13, loss = 0.17852999\n",
      "Iteration 14, loss = 0.17103394\n",
      "Iteration 15, loss = 0.16503880\n",
      "Iteration 16, loss = 0.15776345\n",
      "Iteration 17, loss = 0.14978804\n",
      "Iteration 18, loss = 0.14231728\n",
      "Iteration 19, loss = 0.13482647\n",
      "Iteration 20, loss = 0.13296836\n",
      "Iteration 21, loss = 0.12927059\n",
      "Iteration 22, loss = 0.12179222\n",
      "Iteration 23, loss = 0.11868821\n",
      "Iteration 24, loss = 0.12058914\n",
      "Iteration 25, loss = 0.10745808\n",
      "Iteration 26, loss = 0.10542223\n",
      "Iteration 27, loss = 0.10170953\n",
      "Iteration 28, loss = 0.10051989\n",
      "Iteration 29, loss = 0.09706793\n",
      "Iteration 30, loss = 0.09313814\n",
      "Iteration 31, loss = 0.09137901\n",
      "Iteration 32, loss = 0.08571675\n",
      "Iteration 33, loss = 0.08549145\n",
      "Iteration 34, loss = 0.08091544\n",
      "Iteration 35, loss = 0.08401819\n",
      "Iteration 36, loss = 0.07700422\n",
      "Iteration 37, loss = 0.07475387\n",
      "Iteration 38, loss = 0.06972590\n",
      "Iteration 39, loss = 0.07287669\n",
      "Iteration 40, loss = 0.06753539\n",
      "Iteration 41, loss = 0.06482652\n",
      "Iteration 42, loss = 0.07166677\n",
      "Iteration 43, loss = 0.06362276\n",
      "Iteration 44, loss = 0.06248507\n",
      "Iteration 45, loss = 0.06033731\n",
      "Iteration 46, loss = 0.06229865\n",
      "Iteration 47, loss = 0.06057684\n",
      "Iteration 48, loss = 0.05586957\n",
      "Iteration 49, loss = 0.05500017\n",
      "Iteration 50, loss = 0.05629840\n",
      "Iteration 51, loss = 0.05611956\n",
      "Iteration 52, loss = 0.05414867\n",
      "Iteration 53, loss = 0.05212315\n",
      "Iteration 54, loss = 0.05237543\n",
      "Iteration 55, loss = 0.05316182\n",
      "Iteration 56, loss = 0.05207147\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[5446  416]\n",
      " [ 343  564]]\n",
      "0.575510204082 0.621830209482 0.597774244833\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.247027027027 |  0.503858875413 | 0.331519767864 | 0.72772935441  |\n",
      "| RandomForestClassifier | 0.763736263736 |  0.306504961411 | 0.437450826121 | 0.894371399025 |\n",
      "|   BaggingClassifier    | 0.723004694836 |  0.339581036384 | 0.462115528882 | 0.894075934407 |\n",
      "|  ExtraTreesClassifier  | 0.708061002179 |  0.358324145535 | 0.475841874085 | 0.894223666716 |\n",
      "| DecisionTreeClassifier | 0.433062880325 |  0.470782800441 | 0.451135763339 | 0.846506130891 |\n",
      "| CalibratedClassifierCV | 0.424390243902 | 0.0959206174201 | 0.156474820144 | 0.861427094105 |\n",
      "|     SGDClassifier      | 0.251280031508 |  0.70341786108  | 0.370284387696 | 0.679420889349 |\n",
      "|  KNeighborsClassifier  | 0.616452991453 |  0.636163175303 | 0.626153011394 | 0.89821243906  |\n",
      "|     MLPClassifier      | 0.575510204082 |  0.621830209482 | 0.597774244833 | 0.887871177427 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_2_groupBR12_bigramToken'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainMid], bigram_trans[testMid])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "# Fin\n",
    "For the final time we take another csv(4) file this time. We had duplicates after grouping of BR's. This file is without any duplicate. Senteces were preprocessed as per need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fileName = \"WhiteText_re(Fin).csv\"\n",
    "data = pd.read_csv('data/'+fileName,delimiter=\"|\")\n",
    "\n",
    "trainSet, testSet = train_test_split(data, test_size=0.3, random_state=3)\n",
    "\n",
    "trainSet.to_csv('Train(Fin)',sep=\"|\")\n",
    "testSet.to_csv('Test(Fin)',sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11578\n",
      "4963\n"
     ]
    }
   ],
   "source": [
    "trainData = pd.read_csv('Train(Fin)',delimiter='|')\n",
    "trainSen = trainData['sentence']\n",
    "trainLab = trainData['connection']\n",
    "trainLen = len(trainSen)\n",
    "print trainLen\n",
    "\n",
    "testData = pd.read_csv('Test(Fin)',delimiter='|')\n",
    "testSen = testData['sentence']\n",
    "testLab = testData['connection']\n",
    "testLen = len(testSen)\n",
    "print testLen\n",
    "\n",
    "\n",
    "def formatSen(sentence):\n",
    "    sentence = re.sub(\"\\s(the|The)\\s\",\" \",sentence)\n",
    "    sentence = re.sub(\"^(the|The)\",\"\",sentence)\n",
    "    sentence = re.sub(\"(nucleus)\",\" \",sentence)\n",
    "    sentence = re.sub(r\",\",\" \", sentence)\n",
    "    sentence = re.sub(\"\\([0-9]\\)\",\".\",sentence)\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFSen = []\n",
    "for i in range(0,trainLen):\n",
    "    trainFSen.append(formatSen(trainSen[i]))\n",
    "    \n",
    "testFSen = []\n",
    "for i in range(0,testLen):\n",
    "    testFSen.append(formatSen(testSen[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[3714  430]\n",
      " [ 616  203]]\n",
      "0.320695102686 0.247863247863 0.279614325069\n",
      "Training  RandomForestClassifier\n",
      "[[3998  146]\n",
      " [ 563  256]]\n",
      "0.636815920398 0.312576312576 0.419328419328\n",
      "Training  BaggingClassifier\n",
      "[[3888  256]\n",
      " [ 418  401]]\n",
      "0.610350076104 0.489621489621 0.543360433604\n",
      "Training  ExtraTreesClassifier\n",
      "[[3975  169]\n",
      " [ 529  290]]\n",
      "0.631808278867 0.35409035409 0.453834115806\n",
      "Training  DecisionTreeClassifier\n",
      "[[3765  379]\n",
      " [ 382  437]]\n",
      "0.535539215686 0.533577533578 0.534556574924\n",
      "Training  CalibratedClassifierCV\n",
      "[[4017  127]\n",
      " [ 484  335]]\n",
      "0.725108225108 0.409035409035 0.523028883685\n",
      "Training  SGDClassifier\n",
      "[[4040  104]\n",
      " [ 565  254]]\n",
      "0.709497206704 0.310134310134 0.4316057774\n",
      "Training  KNeighborsClassifier\n",
      "[[3730  414]\n",
      " [ 411  408]]\n",
      "0.496350364964 0.498168498168 0.497257769653\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.46197860\n",
      "Iteration 2, loss = 0.29437933\n",
      "Iteration 3, loss = 0.18331209\n",
      "Iteration 4, loss = 0.12009028\n",
      "Iteration 5, loss = 0.08769208\n",
      "Iteration 6, loss = 0.06975573\n",
      "Iteration 7, loss = 0.05287917\n",
      "Iteration 8, loss = 0.04850910\n",
      "Iteration 9, loss = 0.04049395\n",
      "Iteration 10, loss = 0.03425489\n",
      "Iteration 11, loss = 0.02991937\n",
      "Iteration 12, loss = 0.02632396\n",
      "Iteration 13, loss = 0.02553627\n",
      "Iteration 14, loss = 0.02595402\n",
      "Iteration 15, loss = 0.02466955\n",
      "Iteration 16, loss = 0.02253261\n",
      "Iteration 17, loss = 0.02040335\n",
      "Iteration 18, loss = 0.02311494\n",
      "Iteration 19, loss = 0.01725844\n",
      "Iteration 20, loss = 0.01757575\n",
      "Iteration 21, loss = 0.01636885\n",
      "Iteration 22, loss = 0.01564376\n",
      "Iteration 23, loss = 0.01549691\n",
      "Iteration 24, loss = 0.01486698\n",
      "Iteration 25, loss = 0.01333083\n",
      "Iteration 26, loss = 0.01426664\n",
      "Iteration 27, loss = 0.01397590\n",
      "Iteration 28, loss = 0.01285880\n",
      "Iteration 29, loss = 0.01357207\n",
      "Iteration 30, loss = 0.01477570\n",
      "Iteration 31, loss = 0.01303111\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3925  219]\n",
      " [ 383  436]]\n",
      "0.665648854962 0.532356532357 0.591587516961\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.320695102686 | 0.247863247863 | 0.279614325069 | 0.789240378803 |\n",
      "| RandomForestClassifier | 0.636815920398 | 0.312576312576 | 0.419328419328 | 0.857142857143 |\n",
      "|   BaggingClassifier    | 0.610350076104 | 0.489621489621 | 0.543360433604 | 0.864195043321 |\n",
      "|  ExtraTreesClassifier  | 0.631808278867 | 0.35409035409  | 0.453834115806 | 0.859359258513 |\n",
      "| DecisionTreeClassifier | 0.535539215686 | 0.533577533578 | 0.534556574924 | 0.846665323393 |\n",
      "| CalibratedClassifierCV | 0.725108225108 | 0.409035409035 | 0.523028883685 | 0.87688897844  |\n",
      "|     SGDClassifier      | 0.709497206704 | 0.310134310134 |  0.4316057774  | 0.865202498489 |\n",
      "|  KNeighborsClassifier  | 0.496350364964 | 0.498168498168 | 0.497257769653 | 0.83376989724  |\n",
      "|     MLPClassifier      | 0.665648854962 | 0.532356532357 | 0.591587516961 | 0.878702397743 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11578"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainFSen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[3263  881]\n",
      " [ 418  401]]\n",
      "0.3127925117 0.489621489621 0.381722989053\n",
      "Training  RandomForestClassifier\n",
      "[[3915  229]\n",
      " [ 700  119]]\n",
      "0.341954022989 0.145299145299 0.203941730934\n",
      "Training  BaggingClassifier\n",
      "[[3914  230]\n",
      " [ 681  138]]\n",
      "0.375 0.168498168498 0.23251895535\n",
      "Training  ExtraTreesClassifier\n",
      "[[3956  188]\n",
      " [ 732   87]]\n",
      "0.316363636364 0.106227106227 0.159049360146\n",
      "Training  DecisionTreeClassifier\n",
      "[[3889  255]\n",
      " [ 706  113]]\n",
      "0.307065217391 0.137973137973 0.190395956192\n",
      "Training  CalibratedClassifierCV\n",
      "[[4099   45]\n",
      " [ 764   55]]\n",
      "0.55 0.0671550671551 0.119695321001\n",
      "Training  SGDClassifier\n",
      "[[4105   39]\n",
      " [ 796   23]]\n",
      "0.370967741935 0.028083028083 0.0522133938706\n",
      "Training  KNeighborsClassifier\n",
      "[[3603  541]\n",
      " [ 568  251]]\n",
      "0.316919191919 0.306471306471 0.311607697083\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.43822278\n",
      "Iteration 2, loss = 0.40154866\n",
      "Iteration 3, loss = 0.39449492\n",
      "Iteration 4, loss = 0.38697838\n",
      "Iteration 5, loss = 0.37901194\n",
      "Iteration 6, loss = 0.37453724\n",
      "Iteration 7, loss = 0.36932048\n",
      "Iteration 8, loss = 0.36475109\n",
      "Iteration 9, loss = 0.35721658\n",
      "Iteration 10, loss = 0.35225006\n",
      "Iteration 11, loss = 0.34943889\n",
      "Iteration 12, loss = 0.34401725\n",
      "Iteration 13, loss = 0.34001422\n",
      "Iteration 14, loss = 0.33755429\n",
      "Iteration 15, loss = 0.33411530\n",
      "Iteration 16, loss = 0.33198834\n",
      "Iteration 17, loss = 0.32702182\n",
      "Iteration 18, loss = 0.32378140\n",
      "Iteration 19, loss = 0.32161405\n",
      "Iteration 20, loss = 0.31873599\n",
      "Iteration 21, loss = 0.31731715\n",
      "Iteration 22, loss = 0.31309967\n",
      "Iteration 23, loss = 0.31113407\n",
      "Iteration 24, loss = 0.31076715\n",
      "Iteration 25, loss = 0.30765324\n",
      "Iteration 26, loss = 0.30502134\n",
      "Iteration 27, loss = 0.30257880\n",
      "Iteration 28, loss = 0.30068635\n",
      "Iteration 29, loss = 0.30093608\n",
      "Iteration 30, loss = 0.29638120\n",
      "Iteration 31, loss = 0.29397383\n",
      "Iteration 32, loss = 0.29547433\n",
      "Iteration 33, loss = 0.29236504\n",
      "Iteration 34, loss = 0.29206241\n",
      "Iteration 35, loss = 0.28960771\n",
      "Iteration 36, loss = 0.28770793\n",
      "Iteration 37, loss = 0.28740867\n",
      "Iteration 38, loss = 0.28895314\n",
      "Iteration 39, loss = 0.28271659\n",
      "Iteration 40, loss = 0.28540268\n",
      "Iteration 41, loss = 0.28648621\n",
      "Iteration 42, loss = 0.27968760\n",
      "Iteration 43, loss = 0.28234254\n",
      "Iteration 44, loss = 0.27928308\n",
      "Iteration 45, loss = 0.27808384\n",
      "Iteration 46, loss = 0.27858500\n",
      "Iteration 47, loss = 0.27582993\n",
      "Iteration 48, loss = 0.27481423\n",
      "Iteration 49, loss = 0.27475351\n",
      "Iteration 50, loss = 0.27397228\n",
      "Iteration 51, loss = 0.27321273\n",
      "Iteration 52, loss = 0.27279614\n",
      "Iteration 53, loss = 0.27147065\n",
      "Iteration 54, loss = 0.27160857\n",
      "Iteration 55, loss = 0.27180189\n",
      "Iteration 56, loss = 0.26892705\n",
      "Iteration 57, loss = 0.26988621\n",
      "Iteration 58, loss = 0.26977244\n",
      "Iteration 59, loss = 0.27040786\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3873  271]\n",
      " [ 616  203]]\n",
      "0.428270042194 0.247863247863 0.31399845321\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       |  0.3127925117  |  0.489621489621 |  0.381722989053 | 0.73826314729  |\n",
      "| RandomForestClassifier | 0.341954022989 |  0.145299145299 |  0.203941730934 | 0.81281482974  |\n",
      "|   BaggingClassifier    |     0.375      |  0.168498168498 |  0.23251895535  | 0.816441668346 |\n",
      "|  ExtraTreesClassifier  | 0.316363636364 |  0.106227106227 |  0.159049360146 | 0.814628249043 |\n",
      "| DecisionTreeClassifier | 0.307065217391 |  0.137973137973 |  0.190395956192 | 0.806367116663 |\n",
      "| CalibratedClassifierCV |      0.55      | 0.0671550671551 |  0.119695321001 | 0.836993753778 |\n",
      "|     SGDClassifier      | 0.370967741935 |  0.028083028083 | 0.0522133938706 | 0.831754986903 |\n",
      "|  KNeighborsClassifier  | 0.316919191919 |  0.306471306471 |  0.311607697083 | 0.776546443683 |\n",
      "|     MLPClassifier      | 0.428270042194 |  0.247863247863 |  0.31399845321  | 0.821277453153 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[3355  789]\n",
      " [ 443  376]]\n",
      "0.322746781116 0.459096459096 0.379032258065\n",
      "Training  RandomForestClassifier\n",
      "[[3922  222]\n",
      " [ 697  122]]\n",
      "0.354651162791 0.148962148962 0.209802235598\n",
      "Training  BaggingClassifier\n",
      "[[3917  227]\n",
      " [ 694  125]]\n",
      "0.355113636364 0.152625152625 0.213492741247\n",
      "Training  ExtraTreesClassifier\n",
      "[[3954  190]\n",
      " [ 719  100]]\n",
      "0.344827586207 0.1221001221 0.180342651037\n",
      "Training  DecisionTreeClassifier\n",
      "[[3899  245]\n",
      " [ 699  120]]\n",
      "0.328767123288 0.14652014652 0.202702702703\n",
      "Training  CalibratedClassifierCV\n",
      "[[4098   46]\n",
      " [ 754   65]]\n",
      "0.585585585586 0.0793650793651 0.139784946237\n",
      "Training  SGDClassifier\n",
      "[[4122   22]\n",
      " [ 807   12]]\n",
      "0.352941176471 0.014652014652 0.0281359906213\n",
      "Training  KNeighborsClassifier\n",
      "[[3670  474]\n",
      " [ 577  242]]\n",
      "0.337988826816 0.295482295482 0.315309446254\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.46671889\n",
      "Iteration 2, loss = 0.40723854\n",
      "Iteration 3, loss = 0.39853633\n",
      "Iteration 4, loss = 0.39064242\n",
      "Iteration 5, loss = 0.38331352\n",
      "Iteration 6, loss = 0.37782442\n",
      "Iteration 7, loss = 0.37329838\n",
      "Iteration 8, loss = 0.36805603\n",
      "Iteration 9, loss = 0.36306145\n",
      "Iteration 10, loss = 0.35902666\n",
      "Iteration 11, loss = 0.35404458\n",
      "Iteration 12, loss = 0.34945108\n",
      "Iteration 13, loss = 0.34540436\n",
      "Iteration 14, loss = 0.34370207\n",
      "Iteration 15, loss = 0.33848443\n",
      "Iteration 16, loss = 0.33618460\n",
      "Iteration 17, loss = 0.33171411\n",
      "Iteration 18, loss = 0.32951175\n",
      "Iteration 19, loss = 0.32849632\n",
      "Iteration 20, loss = 0.32683856\n",
      "Iteration 21, loss = 0.31940225\n",
      "Iteration 22, loss = 0.32076536\n",
      "Iteration 23, loss = 0.31921675\n",
      "Iteration 24, loss = 0.31659323\n",
      "Iteration 25, loss = 0.31063442\n",
      "Iteration 26, loss = 0.30822461\n",
      "Iteration 27, loss = 0.30840930\n",
      "Iteration 28, loss = 0.30772017\n",
      "Iteration 29, loss = 0.30424126\n",
      "Iteration 30, loss = 0.30325286\n",
      "Iteration 31, loss = 0.30222746\n",
      "Iteration 32, loss = 0.30298312\n",
      "Iteration 33, loss = 0.29741926\n",
      "Iteration 34, loss = 0.30012057\n",
      "Iteration 35, loss = 0.29599687\n",
      "Iteration 36, loss = 0.29299673\n",
      "Iteration 37, loss = 0.29604311\n",
      "Iteration 38, loss = 0.29283293\n",
      "Iteration 39, loss = 0.29018064\n",
      "Iteration 40, loss = 0.28993075\n",
      "Iteration 41, loss = 0.29039785\n",
      "Iteration 42, loss = 0.28926969\n",
      "Iteration 43, loss = 0.28571974\n",
      "Iteration 44, loss = 0.28507673\n",
      "Iteration 45, loss = 0.28331559\n",
      "Iteration 46, loss = 0.28206318\n",
      "Iteration 47, loss = 0.28191725\n",
      "Iteration 48, loss = 0.28267728\n",
      "Iteration 49, loss = 0.28140132\n",
      "Iteration 50, loss = 0.27969290\n",
      "Iteration 51, loss = 0.28050427\n",
      "Iteration 52, loss = 0.27922491\n",
      "Iteration 53, loss = 0.27881641\n",
      "Iteration 54, loss = 0.27917447\n",
      "Iteration 55, loss = 0.27714445\n",
      "Iteration 56, loss = 0.27638432\n",
      "Iteration 57, loss = 0.27446324\n",
      "Iteration 58, loss = 0.27530766\n",
      "Iteration 59, loss = 0.27264271\n",
      "Iteration 60, loss = 0.27666949\n",
      "Iteration 61, loss = 0.27498675\n",
      "Iteration 62, loss = 0.27164164\n",
      "Iteration 63, loss = 0.27133122\n",
      "Iteration 64, loss = 0.26979648\n",
      "Iteration 65, loss = 0.27585268\n",
      "Iteration 66, loss = 0.27298016\n",
      "Iteration 67, loss = 0.26964774\n",
      "Iteration 68, loss = 0.27392997\n",
      "Iteration 69, loss = 0.26966538\n",
      "Iteration 70, loss = 0.26728690\n",
      "Iteration 71, loss = 0.26793267\n",
      "Iteration 72, loss = 0.26752302\n",
      "Iteration 73, loss = 0.26714393\n",
      "Iteration 74, loss = 0.26868911\n",
      "Iteration 75, loss = 0.26631534\n",
      "Iteration 76, loss = 0.26595099\n",
      "Iteration 77, loss = 0.26587837\n",
      "Iteration 78, loss = 0.26412966\n",
      "Iteration 79, loss = 0.26530855\n",
      "Iteration 80, loss = 0.26453185\n",
      "Iteration 81, loss = 0.26422295\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3884  260]\n",
      " [ 632  187]]\n",
      "0.418344519016 0.228327228327 0.29541864139\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |     F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n",
      "|      BernoulliNB       | 0.322746781116 |  0.459096459096 |  0.379032258065 | 0.751763046544 |\n",
      "| RandomForestClassifier | 0.354651162791 |  0.148962148962 |  0.209802235598 | 0.814829740077 |\n",
      "|   BaggingClassifier    | 0.355113636364 |  0.152625152625 |  0.213492741247 | 0.814426758009 |\n",
      "|  ExtraTreesClassifier  | 0.344827586207 |   0.1221001221  |  0.180342651037 | 0.816844650413 |\n",
      "| DecisionTreeClassifier | 0.328767123288 |  0.14652014652  |  0.202702702703 | 0.809792464235 |\n",
      "| CalibratedClassifierCV | 0.585585585586 | 0.0793650793651 |  0.139784946237 | 0.838807173081 |\n",
      "|     SGDClassifier      | 0.352941176471 |  0.014652014652 | 0.0281359906213 | 0.832963933105 |\n",
      "|  KNeighborsClassifier  | 0.337988826816 |  0.295482295482 |  0.315309446254 | 0.788232923635 |\n",
      "|     MLPClassifier      | 0.418344519016 |  0.228327228327 |  0.29541864139  | 0.820269997985 |\n",
      "+------------------------+----------------+-----------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainFSen, testFSen)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[3579  565]\n",
      " [ 535  284]]\n",
      "0.334511189635 0.346764346764 0.340527577938\n",
      "Training  RandomForestClassifier\n",
      "[[3912  232]\n",
      " [ 695  124]]\n",
      "0.348314606742 0.151404151404 0.211063829787\n",
      "Training  BaggingClassifier\n",
      "[[3914  230]\n",
      " [ 691  128]]\n",
      "0.357541899441 0.156288156288 0.217502124044\n",
      "Training  ExtraTreesClassifier\n",
      "[[3945  199]\n",
      " [ 726   93]]\n",
      "0.318493150685 0.113553113553 0.167416741674\n",
      "Training  DecisionTreeClassifier\n",
      "[[3865  279]\n",
      " [ 689  130]]\n",
      "0.317848410758 0.15873015873 0.211726384365\n",
      "Training  CalibratedClassifierCV\n",
      "[[4089   55]\n",
      " [ 736   83]]\n",
      "0.601449275362 0.101343101343 0.173458725183\n",
      "Training  SGDClassifier\n",
      "[[4094   50]\n",
      " [ 758   61]]\n",
      "0.54954954955 0.0744810744811 0.131182795699\n",
      "Training  KNeighborsClassifier\n",
      "[[3559  585]\n",
      " [ 560  259]]\n",
      "0.306872037915 0.316239316239 0.311485267589\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.44234723\n",
      "Iteration 2, loss = 0.40346794\n",
      "Iteration 3, loss = 0.39269022\n",
      "Iteration 4, loss = 0.38808562\n",
      "Iteration 5, loss = 0.38226045\n",
      "Iteration 6, loss = 0.38009173\n",
      "Iteration 7, loss = 0.37310577\n",
      "Iteration 8, loss = 0.36912981\n",
      "Iteration 9, loss = 0.36296051\n",
      "Iteration 10, loss = 0.35779699\n",
      "Iteration 11, loss = 0.35491344\n",
      "Iteration 12, loss = 0.34979680\n",
      "Iteration 13, loss = 0.34464465\n",
      "Iteration 14, loss = 0.34606901\n",
      "Iteration 15, loss = 0.33664230\n",
      "Iteration 16, loss = 0.33194078\n",
      "Iteration 17, loss = 0.32647531\n",
      "Iteration 18, loss = 0.32270614\n",
      "Iteration 19, loss = 0.31720554\n",
      "Iteration 20, loss = 0.31759210\n",
      "Iteration 21, loss = 0.31530988\n",
      "Iteration 22, loss = 0.31096126\n",
      "Iteration 23, loss = 0.30687248\n",
      "Iteration 24, loss = 0.30403250\n",
      "Iteration 25, loss = 0.30135073\n",
      "Iteration 26, loss = 0.29659460\n",
      "Iteration 27, loss = 0.29610839\n",
      "Iteration 28, loss = 0.29210427\n",
      "Iteration 29, loss = 0.29245540\n",
      "Iteration 30, loss = 0.29032251\n",
      "Iteration 31, loss = 0.28877615\n",
      "Iteration 32, loss = 0.28640815\n",
      "Iteration 33, loss = 0.28680049\n",
      "Iteration 34, loss = 0.28050445\n",
      "Iteration 35, loss = 0.28081335\n",
      "Iteration 36, loss = 0.27894142\n",
      "Iteration 37, loss = 0.28070294\n",
      "Iteration 38, loss = 0.27834408\n",
      "Iteration 39, loss = 0.27466480\n",
      "Iteration 40, loss = 0.27488066\n",
      "Iteration 41, loss = 0.27293837\n",
      "Iteration 42, loss = 0.27264856\n",
      "Iteration 43, loss = 0.27183348\n",
      "Iteration 44, loss = 0.26907525\n",
      "Iteration 45, loss = 0.26833973\n",
      "Iteration 46, loss = 0.26749245\n",
      "Iteration 47, loss = 0.26566154\n",
      "Iteration 48, loss = 0.26691284\n",
      "Iteration 49, loss = 0.26470400\n",
      "Iteration 50, loss = 0.26539784\n",
      "Iteration 51, loss = 0.26566604\n",
      "Iteration 52, loss = 0.26501400\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3805  339]\n",
      " [ 564  255]]\n",
      "0.429292929293 0.311355311355 0.36093418259\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |      Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.334511189635 |  0.346764346764 | 0.340527577938 | 0.778359862986 |\n",
      "| RandomForestClassifier | 0.348314606742 |  0.151404151404 | 0.211063829787 | 0.813217811807 |\n",
      "|   BaggingClassifier    | 0.357541899441 |  0.156288156288 | 0.217502124044 | 0.814426758009 |\n",
      "|  ExtraTreesClassifier  | 0.318493150685 |  0.113553113553 | 0.167416741674 | 0.813620793875 |\n",
      "| DecisionTreeClassifier | 0.317848410758 |  0.15873015873  | 0.211726384365 | 0.804956679428 |\n",
      "| CalibratedClassifierCV | 0.601449275362 |  0.101343101343 | 0.173458725183 | 0.840620592384 |\n",
      "|     SGDClassifier      | 0.54954954955  | 0.0744810744811 | 0.131182795699 | 0.837195244812 |\n",
      "|  KNeighborsClassifier  | 0.306872037915 |  0.316239316239 | 0.311485267589 | 0.769292766472 |\n",
      "|     MLPClassifier      | 0.429292929293 |  0.311355311355 | 0.36093418259  | 0.818053596615 |\n",
      "+------------------------+----------------+-----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_Fin_bigramToken'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainFSen], bigram_trans[testFSen])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle Sentences taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['than br ; br1 ; br other than br ; br ; br2 ; purkinje',\n",
       " 'to specification of br1 in mouse br2 .',\n",
       " 'influenced by sound-evoked br1 br2 activity .',\n",
       " ') located in br1 at about 1.2 mm from lateral edge of br ; br ( po ) projects to a zone ( br ) about 0.7 mm from lateral edge of br2 ; finally',\n",
       " '( 1 ) br1 ( ppb ) ( m ) region ( br and waist area ) diffusely projects to br ( br ( bst ) ) br ( including br and br ) and to a lesser extent br ; ( 2 ) br ( ppb ) ( 1 ) region [ br ( ppb ) cl ) and br ] densely projects to br2 ( bst']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMid = breakSen(trainFSen)\n",
    "testMid = breakSen(testFSen)\n",
    "trainMid[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  BernoulliNB\n",
      "[[3944  200]\n",
      " [ 618  201]]\n",
      "0.501246882793 0.245421245421 0.329508196721\n",
      "Training  RandomForestClassifier\n",
      "[[4076   68]\n",
      " [ 468  351]]\n",
      "0.837708830549 0.428571428571 0.56704361874\n",
      "Training  BaggingClassifier\n",
      "[[3972  172]\n",
      " [ 380  439]]\n",
      "0.718494271686 0.53601953602 0.613986013986\n",
      "Training  ExtraTreesClassifier\n",
      "[[4046   98]\n",
      " [ 425  394]]\n",
      "0.80081300813 0.481074481074 0.601067887109\n",
      "Training  DecisionTreeClassifier\n",
      "[[3832  312]\n",
      " [ 339  480]]\n",
      "0.606060606061 0.586080586081 0.595903165736\n",
      "Training  CalibratedClassifierCV\n",
      "[[3996  148]\n",
      " [ 315  504]]\n",
      "0.773006134969 0.615384615385 0.685248130523\n",
      "Training  SGDClassifier\n",
      "[[4058   86]\n",
      " [ 433  386]]\n",
      "0.817796610169 0.471306471306 0.59798605732\n",
      "Training  KNeighborsClassifier\n",
      "[[3858  286]\n",
      " [ 337  482]]\n",
      "0.627604166667 0.588522588523 0.607435412728\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.44715200\n",
      "Iteration 2, loss = 0.22163679\n",
      "Iteration 3, loss = 0.07758928\n",
      "Iteration 4, loss = 0.03701396\n",
      "Iteration 5, loss = 0.02253073\n",
      "Iteration 6, loss = 0.01454058\n",
      "Iteration 7, loss = 0.01041728\n",
      "Iteration 8, loss = 0.00807766\n",
      "Iteration 9, loss = 0.00642992\n",
      "Iteration 10, loss = 0.00578191\n",
      "Iteration 11, loss = 0.00428129\n",
      "Iteration 12, loss = 0.00363306\n",
      "Iteration 13, loss = 0.00335975\n",
      "Iteration 14, loss = 0.00315415\n",
      "Iteration 15, loss = 0.00320011\n",
      "Iteration 16, loss = 0.00335216\n",
      "Iteration 17, loss = 0.00257376\n",
      "Iteration 18, loss = 0.00242444\n",
      "Iteration 19, loss = 0.00235979\n",
      "Iteration 20, loss = 0.00208343\n",
      "Iteration 21, loss = 0.00267372\n",
      "Iteration 22, loss = 0.00207554\n",
      "Iteration 23, loss = 0.00183388\n",
      "Iteration 24, loss = 0.00233076\n",
      "Iteration 25, loss = 0.00272820\n",
      "Iteration 26, loss = 0.00286811\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3962  182]\n",
      " [ 272  547]]\n",
      "0.750342935528 0.667887667888 0.706718346253\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.501246882793 | 0.245421245421 | 0.329508196721 | 0.835180334475 |\n",
      "| RandomForestClassifier | 0.837708830549 | 0.428571428571 | 0.56704361874  | 0.892000805964 |\n",
      "|   BaggingClassifier    | 0.718494271686 | 0.53601953602  | 0.613986013986 | 0.888776949426 |\n",
      "|  ExtraTreesClassifier  | 0.80081300813  | 0.481074481074 | 0.601067887109 | 0.894620189402 |\n",
      "| DecisionTreeClassifier | 0.606060606061 | 0.586080586081 | 0.595903165736 | 0.868829337094 |\n",
      "| CalibratedClassifierCV | 0.773006134969 | 0.615384615385 | 0.685248130523 | 0.906709651421 |\n",
      "|     SGDClassifier      | 0.817796610169 | 0.471306471306 | 0.59798605732  | 0.895426153536 |\n",
      "|  KNeighborsClassifier  | 0.627604166667 | 0.588522588523 | 0.607435412728 | 0.874471086037 |\n",
      "|     MLPClassifier      | 0.750342935528 | 0.667887667888 | 0.706718346253 | 0.908523070723 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "train_vect, test_vect = convertTfidf(trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "#### a. For the first task we will be taking the initial model that was built from the xml file without any tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[3269  875]\n",
      " [ 386  433]]\n",
      "0.331039755352 0.528693528694 0.407146215327\n",
      "Training  RandomForestClassifier\n",
      "[[4082   62]\n",
      " [ 668  151]]\n",
      "0.708920187793 0.184371184371 0.292635658915\n",
      "Training  BaggingClassifier\n",
      "[[4069   75]\n",
      " [ 629  190]]\n",
      "0.716981132075 0.23199023199 0.350553505535\n",
      "Training  ExtraTreesClassifier\n",
      "[[4047   97]\n",
      " [ 642  177]]\n",
      "0.64598540146 0.216117216117 0.323879231473\n",
      "Training  DecisionTreeClassifier\n",
      "[[3626  518]\n",
      " [ 528  291]]\n",
      "0.359703337454 0.355311355311 0.357493857494\n",
      "Training  CalibratedClassifierCV\n",
      "[[4063   81]\n",
      " [ 711  108]]\n",
      "0.571428571429 0.131868131868 0.214285714286\n",
      "Training  SGDClassifier\n",
      "[[3642  502]\n",
      " [ 496  323]]\n",
      "0.391515151515 0.394383394383 0.392944038929\n",
      "Training  KNeighborsClassifier\n",
      "[[3844  300]\n",
      " [ 390  429]]\n",
      "0.588477366255 0.52380952381 0.554263565891\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.43545675\n",
      "Iteration 2, loss = 0.37700587\n",
      "Iteration 3, loss = 0.36014847\n",
      "Iteration 4, loss = 0.34741174\n",
      "Iteration 5, loss = 0.33571867\n",
      "Iteration 6, loss = 0.32440748\n",
      "Iteration 7, loss = 0.31514595\n",
      "Iteration 8, loss = 0.30377531\n",
      "Iteration 9, loss = 0.29518753\n",
      "Iteration 10, loss = 0.28409372\n",
      "Iteration 11, loss = 0.27631208\n",
      "Iteration 12, loss = 0.26579727\n",
      "Iteration 13, loss = 0.25807891\n",
      "Iteration 14, loss = 0.24944353\n",
      "Iteration 15, loss = 0.23933387\n",
      "Iteration 16, loss = 0.23190246\n",
      "Iteration 17, loss = 0.22508516\n",
      "Iteration 18, loss = 0.21783876\n",
      "Iteration 19, loss = 0.20952824\n",
      "Iteration 20, loss = 0.20315512\n",
      "Iteration 21, loss = 0.19612340\n",
      "Iteration 22, loss = 0.18854956\n",
      "Iteration 23, loss = 0.18494571\n",
      "Iteration 24, loss = 0.18182046\n",
      "Iteration 25, loss = 0.17431776\n",
      "Iteration 26, loss = 0.16710459\n",
      "Iteration 27, loss = 0.16031950\n",
      "Iteration 28, loss = 0.15836496\n",
      "Iteration 29, loss = 0.15595056\n",
      "Iteration 30, loss = 0.15025667\n",
      "Iteration 31, loss = 0.14695732\n",
      "Iteration 32, loss = 0.14792705\n",
      "Iteration 33, loss = 0.13603004\n",
      "Iteration 34, loss = 0.13509740\n",
      "Iteration 35, loss = 0.13044891\n",
      "Iteration 36, loss = 0.12918208\n",
      "Iteration 37, loss = 0.12667584\n",
      "Iteration 38, loss = 0.12111366\n",
      "Iteration 39, loss = 0.11403774\n",
      "Iteration 40, loss = 0.11422132\n",
      "Iteration 41, loss = 0.11033590\n",
      "Iteration 42, loss = 0.10645120\n",
      "Iteration 43, loss = 0.10649774\n",
      "Iteration 44, loss = 0.09960486\n",
      "Iteration 45, loss = 0.10238154\n",
      "Iteration 46, loss = 0.10143610\n",
      "Iteration 47, loss = 0.09596642\n",
      "Iteration 48, loss = 0.09399333\n",
      "Iteration 49, loss = 0.09408628\n",
      "Iteration 50, loss = 0.09271540\n",
      "Iteration 51, loss = 0.09097908\n",
      "Iteration 52, loss = 0.08966305\n",
      "Iteration 53, loss = 0.08382318\n",
      "Iteration 54, loss = 0.08533779\n",
      "Iteration 55, loss = 0.07862535\n",
      "Iteration 56, loss = 0.08199794\n",
      "Iteration 57, loss = 0.08041887\n",
      "Iteration 58, loss = 0.07817093\n",
      "Iteration 59, loss = 0.07442864\n",
      "Iteration 60, loss = 0.06998876\n",
      "Iteration 61, loss = 0.07146501\n",
      "Iteration 62, loss = 0.06966777\n",
      "Iteration 63, loss = 0.07304141\n",
      "Iteration 64, loss = 0.07363639\n",
      "Iteration 65, loss = 0.07226786\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3805  339]\n",
      " [ 388  431]]\n",
      "0.55974025974 0.526251526252 0.542479546885\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.331039755352 | 0.528693528694 | 0.407146215327 | 0.745919806569 |\n",
      "| RandomForestClassifier | 0.708920187793 | 0.184371184371 | 0.292635658915 | 0.852911545436 |\n",
      "|   BaggingClassifier    | 0.716981132075 | 0.23199023199  | 0.350553505535 | 0.858150312311 |\n",
      "|  ExtraTreesClassifier  | 0.64598540146  | 0.216117216117 | 0.323879231473 | 0.851098126133 |\n",
      "| DecisionTreeClassifier | 0.359703337454 | 0.355311355311 | 0.357493857494 | 0.789240378803 |\n",
      "| CalibratedClassifierCV | 0.571428571429 | 0.131868131868 | 0.214285714286 | 0.84041910135  |\n",
      "|     SGDClassifier      | 0.391515151515 | 0.394383394383 | 0.392944038929 | 0.798911948418 |\n",
      "|  KNeighborsClassifier  | 0.588477366255 | 0.52380952381  | 0.554263565891 | 0.860971186782 |\n",
      "|     MLPClassifier      | 0.55974025974  | 0.526251526252 | 0.542479546885 | 0.853516018537 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlOriginalSen'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Second we take the word2vec model that built after BR's are marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[3414  730]\n",
      " [ 429  390]]\n",
      "0.348214285714 0.47619047619 0.402269210933\n",
      "Training  RandomForestClassifier\n",
      "[[4066   78]\n",
      " [ 642  177]]\n",
      "0.694117647059 0.216117216117 0.329608938547\n",
      "Training  BaggingClassifier\n",
      "[[4035  109]\n",
      " [ 606  213]]\n",
      "0.66149068323 0.260073260073 0.373356704645\n",
      "Training  ExtraTreesClassifier\n",
      "[[4022  122]\n",
      " [ 633  186]]\n",
      "0.603896103896 0.227106227106 0.33007985803\n",
      "Training  DecisionTreeClassifier\n",
      "[[3649  495]\n",
      " [ 517  302]]\n",
      "0.378920953576 0.368742368742 0.373762376238\n",
      "Training  CalibratedClassifierCV\n",
      "[[4070   74]\n",
      " [ 721   98]]\n",
      "0.56976744186 0.119658119658 0.197780020182\n",
      "Training  SGDClassifier\n",
      "[[3692  452]\n",
      " [ 520  299]]\n",
      "0.398135818908 0.365079365079 0.380891719745\n",
      "Training  KNeighborsClassifier\n",
      "[[3843  301]\n",
      " [ 407  412]]\n",
      "0.577840112202 0.503052503053 0.537859007833\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.43734837\n",
      "Iteration 2, loss = 0.37979072\n",
      "Iteration 3, loss = 0.36600347\n",
      "Iteration 4, loss = 0.35585196\n",
      "Iteration 5, loss = 0.34625879\n",
      "Iteration 6, loss = 0.33674055\n",
      "Iteration 7, loss = 0.32682159\n",
      "Iteration 8, loss = 0.31827759\n",
      "Iteration 9, loss = 0.30924726\n",
      "Iteration 10, loss = 0.29813486\n",
      "Iteration 11, loss = 0.28848643\n",
      "Iteration 12, loss = 0.27945375\n",
      "Iteration 13, loss = 0.27221731\n",
      "Iteration 14, loss = 0.26508230\n",
      "Iteration 15, loss = 0.25462470\n",
      "Iteration 16, loss = 0.24789628\n",
      "Iteration 17, loss = 0.24037911\n",
      "Iteration 18, loss = 0.23898170\n",
      "Iteration 19, loss = 0.22746856\n",
      "Iteration 20, loss = 0.22347001\n",
      "Iteration 21, loss = 0.21477819\n",
      "Iteration 22, loss = 0.21437662\n",
      "Iteration 23, loss = 0.20741574\n",
      "Iteration 24, loss = 0.20477989\n",
      "Iteration 25, loss = 0.19880416\n",
      "Iteration 26, loss = 0.19149066\n",
      "Iteration 27, loss = 0.18720136\n",
      "Iteration 28, loss = 0.18395399\n",
      "Iteration 29, loss = 0.17641865\n",
      "Iteration 30, loss = 0.17511241\n",
      "Iteration 31, loss = 0.17090185\n",
      "Iteration 32, loss = 0.16593153\n",
      "Iteration 33, loss = 0.16357657\n",
      "Iteration 34, loss = 0.15747908\n",
      "Iteration 35, loss = 0.15467514\n",
      "Iteration 36, loss = 0.15234178\n",
      "Iteration 37, loss = 0.14731026\n",
      "Iteration 38, loss = 0.14413870\n",
      "Iteration 39, loss = 0.14112660\n",
      "Iteration 40, loss = 0.13977869\n",
      "Iteration 41, loss = 0.13796167\n",
      "Iteration 42, loss = 0.13641058\n",
      "Iteration 43, loss = 0.13035414\n",
      "Iteration 44, loss = 0.13041858\n",
      "Iteration 45, loss = 0.12506008\n",
      "Iteration 46, loss = 0.12177111\n",
      "Iteration 47, loss = 0.12141526\n",
      "Iteration 48, loss = 0.12119514\n",
      "Iteration 49, loss = 0.11360469\n",
      "Iteration 50, loss = 0.11469010\n",
      "Iteration 51, loss = 0.10859473\n",
      "Iteration 52, loss = 0.10624059\n",
      "Iteration 53, loss = 0.11010944\n",
      "Iteration 54, loss = 0.10418418\n",
      "Iteration 55, loss = 0.10406257\n",
      "Iteration 56, loss = 0.10547446\n",
      "Iteration 57, loss = 0.10130878\n",
      "Iteration 58, loss = 0.10093000\n",
      "Iteration 59, loss = 0.10504311\n",
      "Iteration 60, loss = 0.09250840\n",
      "Iteration 61, loss = 0.09227775\n",
      "Iteration 62, loss = 0.08777235\n",
      "Iteration 63, loss = 0.08794281\n",
      "Iteration 64, loss = 0.08707568\n",
      "Iteration 65, loss = 0.09165654\n",
      "Iteration 66, loss = 0.08351516\n",
      "Iteration 67, loss = 0.08582246\n",
      "Iteration 68, loss = 0.08166262\n",
      "Iteration 69, loss = 0.08228410\n",
      "Iteration 70, loss = 0.08034129\n",
      "Iteration 71, loss = 0.08211043\n",
      "Iteration 72, loss = 0.08208856\n",
      "Iteration 73, loss = 0.08220395\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3865  279]\n",
      " [ 431  388]]\n",
      "0.581709145427 0.473748473748 0.522207267833\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.348214285714 | 0.47619047619  | 0.402269210933 | 0.766471892001 |\n",
      "| RandomForestClassifier | 0.694117647059 | 0.216117216117 | 0.329608938547 | 0.854926455773 |\n",
      "|   BaggingClassifier    | 0.66149068323  | 0.260073260073 | 0.373356704645 | 0.855933910941 |\n",
      "|  ExtraTreesClassifier  | 0.603896103896 | 0.227106227106 | 0.33007985803  | 0.847874269595 |\n",
      "| DecisionTreeClassifier | 0.378920953576 | 0.368742368742 | 0.373762376238 | 0.796091073947 |\n",
      "| CalibratedClassifierCV | 0.56976744186  | 0.119658119658 | 0.197780020182 | 0.839814628249 |\n",
      "|     SGDClassifier      | 0.398135818908 | 0.365079365079 | 0.380891719745 | 0.804150715293 |\n",
      "|  KNeighborsClassifier  | 0.577840112202 | 0.503052503053 | 0.537859007833 | 0.857344348177 |\n",
      "|     MLPClassifier      | 0.581709145427 | 0.473748473748 | 0.522207267833 | 0.856941366109 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "modelName = 'xmlReplaceBR'\n",
    "train_vect, test_vect = buildW2V(modelName,trainMid, testMid)\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Embedding...\n",
      "Training  BernoulliNB\n",
      "[[3590  554]\n",
      " [ 506  313]]\n",
      "0.361014994233 0.382173382173 0.371293001186\n",
      "Training  RandomForestClassifier\n",
      "[[4094   50]\n",
      " [ 697  122]]\n",
      "0.709302325581 0.148962148962 0.246215943491\n",
      "Training  BaggingClassifier\n",
      "[[4080   64]\n",
      " [ 660  159]]\n",
      "0.713004484305 0.194139194139 0.305182341651\n",
      "Training  ExtraTreesClassifier\n",
      "[[4062   82]\n",
      " [ 633  186]]\n",
      "0.694029850746 0.227106227106 0.342226310948\n",
      "Training  DecisionTreeClassifier\n",
      "[[3605  539]\n",
      " [ 510  309]]\n",
      "0.364386792453 0.377289377289 0.370725854829\n",
      "Training  CalibratedClassifierCV\n",
      "[[4058   86]\n",
      " [ 714  105]]\n",
      "0.549738219895 0.128205128205 0.207920792079\n",
      "Training  SGDClassifier\n",
      "[[2349 1795]\n",
      " [ 160  659]]\n",
      "0.268541157294 0.80463980464 0.402688664833\n",
      "Training  KNeighborsClassifier\n",
      "[[3853  291]\n",
      " [ 362  457]]\n",
      "0.610962566845 0.557997557998 0.583280153159\n",
      "Training  MLPClassifier\n",
      "Iteration 1, loss = 0.42691503\n",
      "Iteration 2, loss = 0.38011916\n",
      "Iteration 3, loss = 0.36562674\n",
      "Iteration 4, loss = 0.35620714\n",
      "Iteration 5, loss = 0.34342448\n",
      "Iteration 6, loss = 0.33069952\n",
      "Iteration 7, loss = 0.32003321\n",
      "Iteration 8, loss = 0.30806018\n",
      "Iteration 9, loss = 0.29588093\n",
      "Iteration 10, loss = 0.28873591\n",
      "Iteration 11, loss = 0.27061717\n",
      "Iteration 12, loss = 0.26240233\n",
      "Iteration 13, loss = 0.25255484\n",
      "Iteration 14, loss = 0.24252241\n",
      "Iteration 15, loss = 0.23266575\n",
      "Iteration 16, loss = 0.22371585\n",
      "Iteration 17, loss = 0.21347698\n",
      "Iteration 18, loss = 0.20193831\n",
      "Iteration 19, loss = 0.20244364\n",
      "Iteration 20, loss = 0.18736829\n",
      "Iteration 21, loss = 0.17843189\n",
      "Iteration 22, loss = 0.17556524\n",
      "Iteration 23, loss = 0.16940053\n",
      "Iteration 24, loss = 0.15797100\n",
      "Iteration 25, loss = 0.15611826\n",
      "Iteration 26, loss = 0.14698928\n",
      "Iteration 27, loss = 0.14142540\n",
      "Iteration 28, loss = 0.13601378\n",
      "Iteration 29, loss = 0.13033366\n",
      "Iteration 30, loss = 0.12606236\n",
      "Iteration 31, loss = 0.12487691\n",
      "Iteration 32, loss = 0.11974812\n",
      "Iteration 33, loss = 0.11193175\n",
      "Iteration 34, loss = 0.10670776\n",
      "Iteration 35, loss = 0.10722747\n",
      "Iteration 36, loss = 0.10346885\n",
      "Iteration 37, loss = 0.10028293\n",
      "Iteration 38, loss = 0.09764744\n",
      "Iteration 39, loss = 0.09086083\n",
      "Iteration 40, loss = 0.08806873\n",
      "Iteration 41, loss = 0.08569629\n",
      "Iteration 42, loss = 0.08279358\n",
      "Iteration 43, loss = 0.07657156\n",
      "Iteration 44, loss = 0.07871508\n",
      "Iteration 45, loss = 0.08057531\n",
      "Iteration 46, loss = 0.07651331\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "[[3776  368]\n",
      " [ 354  465]]\n",
      "0.558223289316 0.567765567766 0.562953995157\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|          Name          |   Precision    |     Recall     |    F1 Score    |    Accuracy    |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n",
      "|      BernoulliNB       | 0.361014994233 | 0.382173382173 | 0.371293001186 | 0.786419504332 |\n",
      "| RandomForestClassifier | 0.709302325581 | 0.148962148962 | 0.246215943491 | 0.849486197864 |\n",
      "|   BaggingClassifier    | 0.713004484305 | 0.194139194139 | 0.305182341651 | 0.854120491638 |\n",
      "|  ExtraTreesClassifier  | 0.694029850746 | 0.227106227106 | 0.342226310948 | 0.855933910941 |\n",
      "| DecisionTreeClassifier | 0.364386792453 | 0.377289377289 | 0.370725854829 | 0.788635905702 |\n",
      "| CalibratedClassifierCV | 0.549738219895 | 0.128205128205 | 0.207920792079 | 0.838807173081 |\n",
      "|     SGDClassifier      | 0.268541157294 | 0.80463980464  | 0.402688664833 | 0.606085029216 |\n",
      "|  KNeighborsClassifier  | 0.610962566845 | 0.557997557998 | 0.583280153159 | 0.868426355027 |\n",
      "|     MLPClassifier      | 0.558223289316 | 0.567765567766 | 0.562953995157 | 0.854523473705 |\n",
      "+------------------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "bigram_trans = Phrases(trainFSen)\n",
    "\n",
    "modelName = 'csv_Fin_bigramToken'\n",
    "train_vect, test_vect = buildW2V(modelName,bigram_trans[trainMid], bigram_trans[testMid])\n",
    "print(classify(train_vect,trainLab,test_vect,testLab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
